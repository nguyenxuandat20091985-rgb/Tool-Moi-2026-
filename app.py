# ================= IMPORT TH∆Ø VI·ªÜN =================
import streamlit as st
import google.generativeai as genai
import re
import json
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from datetime import datetime
from itertools import combinations

# ================= C·∫§U H√åNH B·∫¢O M·∫¨T =================
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    st.error("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh API Key trong Secrets!")
    st.stop()

# ================= KH·ªûI T·∫†O H·ªÜ TH·ªêNG =================
st.set_page_config(page_title="TITAN v26.0 PRO", layout="wide", page_icon="üéØ")

@st.cache_resource
def setup_neural():
    try:
        genai.configure(api_key=API_KEY)
        return genai.GenerativeModel('gemini-1.5-flash-latest')
    except: 
        return None

neural_engine = setup_neural()

# ================= QU·∫¢N L√ù D·ªÆ LI·ªÜU =================
def load_data_from_json(uploaded_file):
    if uploaded_file is not None:
        try:
            return json.load(uploaded_file)
        except:
            return []
    return []

def convert_df_to_json(data):
    return json.dumps(data, ensure_ascii=False).encode('utf-8')

# Kh·ªüi t·∫°o session state
if "history" not in st.session_state:
    st.session_state.history = []
if "last_prediction" not in st.session_state:
    st.session_state.last_prediction = None

# ================= THU·∫¨T TO√ÅN 1: PH√ÇN T√çCH T·∫¶N SU·∫§T N√ÇNG CAO =================
def advanced_frequency_analysis(history, top_n=10):
    """Ph√¢n t√≠ch t·∫ßn su·∫•t v·ªõi tr·ªçng s·ªë th·ªùi gian"""
    if not history:
        return {}
    
    # T√°ch t·ª´ng v·ªã tr√≠
    positions = {'hang_chuc_ngan': [], 'hang_ngan': [], 'hang_tram': [], 'hang_chuc': [], 'hang_don_vi': []}
    
    for num in history[-50:]:
        if len(num) == 5:
            positions['hang_chuc_ngan'].append(int(num[0]))
            positions['hang_ngan'].append(int(num[1]))
            positions['hang_tram'].append(int(num[2]))
            positions['hang_chuc'].append(int(num[3]))
            positions['hang_don_vi'].append(int(num[4]))
    
    # T√≠nh t·∫ßn su·∫•t c√≥ tr·ªçng s·ªë (k·ª≥ g·∫ßn n·∫∑ng h∆°n)
    weighted_freq = {}
    for pos_name, pos_data in positions.items():
        freq = Counter(pos_data)
        # Tr·ªçng s·ªë gi·∫£m d·∫ßn
        weights = [i/len(pos_data) for i in range(1, len(pos_data)+1)]
        weighted = defaultdict(float)
        for i, num in enumerate(pos_data):
            weighted[num] += weights[i]
        
        weighted_freq[pos_name] = dict(sorted(weighted.items(), key=lambda x: x[1], reverse=True)[:top_n])
    
    return weighted_freq

# ================= THU·∫¨T TO√ÅN 2: NH·∫¨N DI·ªÜN C·∫¶U =================
def detect_patterns(history, window=20):
    """Nh·∫≠n di·ªán c√°c d·∫°ng c·∫ßu: b·ªát, ƒë·∫£o, nh·ªãp"""
    if len(history) < window:
        return {"cau_bet": [], "cau_dao": [], "cau_nhip": []}
    
    patterns = {
        "cau_bet": [],      # S·ªë ra li√™n ti·∫øp
        "cau_dao": [],      # S·ªë ra xen k·∫Ω
        "cau_nhip": [],     # S·ªë ra theo nh·ªãp 2-3 k·ª≥
        "cau_cham": []      # S·ªë l√¢u ch∆∞a ra
    }
    
    # L·∫•y 20 k·ª≥ g·∫ßn
    recent = history[-window:]
    all_nums = "".join(recent)
    
    # Ph√¢n t√≠ch t·ª´ng v·ªã tr√≠
    for pos in range(5):
        pos_sequence = [int(num[pos]) if len(num) > pos else 0 for num in recent]
        
        # C·∫ßu b·ªát (ra li√™n ti·∫øp 2-3 l·∫ßn)
        for i in range(len(pos_sequence)-1):
            if pos_sequence[i] == pos_sequence[i+1]:
                patterns["cau_bet"].append({
                    'so': pos_sequence[i],
                    'vi_tri': pos,
                    'lan': 2
                })
        
        # C·∫ßu nh·ªãp 2 (ra c√°ch 1 k·ª≥)
        for i in range(len(pos_sequence)-2):
            if pos_sequence[i] == pos_sequence[i+2] and pos_sequence[i] != pos_sequence[i+1]:
                patterns["cau_nhip"].append({
                    'so': pos_sequence[i],
                    'vi_tri': pos,
                    'nh·ªãp': 2
                })
        
        # C·∫ßu nh·ªãp 3
        for i in range(len(pos_sequence)-3):
            if pos_sequence[i] == pos_sequence[i+3]:
                patterns["cau_nhip"].append({
                    'so': pos_sequence[i],
                    'vi_tri': pos,
                    'nh·ªãp': 3
                })
    
    # S·ªë l√¢u ch∆∞a ra (cold numbers)
    all_digits = [0,1,2,3,4,5,6,7,8,9]
    recent_digits = set(int(d) for d in all_nums)
    cold = [d for d in all_digits if d not in recent_digits]
    patterns["cau_cham"] = cold
    
    return patterns

# ================= THU·∫¨T TO√ÅN 3: TH·ªêNG K√ä T·ªîNG - THI·ªÜP =================
def analyze_totals(history):
    """Ph√¢n t√≠ch t·ªïng c√°c s·ªë"""
    if not history:
        return {}
    
    totals = []
    for num in history[-30:]:
        if len(num) == 5:
            total = sum(int(d) for d in num)
            totals.append(total)
    
    total_freq = Counter(totals)
    avg_total = np.mean(totals) if totals else 0
    
    return {
        'total_freq': dict(total_freq.most_common(5)),
        'avg_total': round(avg_total, 1),
        'hot_totals': [t for t, c in total_freq.most_common(3)]
    }

# ================= THU·∫¨T TO√ÅN 4: D·ª∞ ƒêO√ÅN V·ªä TR√ç =================
def position_prediction(history):
    """D·ª± ƒëo√°n theo t·ª´ng v·ªã tr√≠ ri√™ng bi·ªát"""
    if len(history) < 10:
        return {}
    
    predictions = {}
    
    for pos in range(5):
        pos_name = ['Ch·ª•c ng√†n', 'Ng√†n', 'TrƒÉm', 'Ch·ª•c', 'ƒê∆°n v·ªã'][pos]
        pos_sequence = [int(num[pos]) if len(num) > pos else 0 for num in history[-30:]]
        
        # T·∫ßn su·∫•t v·ªã tr√≠
        freq = Counter(pos_sequence)
        top_3 = [num for num, count in freq.most_common(3)]
        
        # Xu h∆∞·ªõng g·∫ßn (5 k·ª≥ cu·ªëi)
        recent_trend = pos_sequence[-5:]
        recent_freq = Counter(recent_trend)
        trending = [num for num, count in recent_freq.most_common(2)]
        
        predictions[pos_name] = {
            'top_3': top_3,
            'trending': trending,
            'hot': freq.most_common(1)[0][0] if freq else 0
        }
    
    return predictions

# ================= GIAO DI·ªÜN & CSS =================
st.markdown("""
    <style>
    .stApp { background: #0d1117; color: #c9d1d9; }
    .main-card { background: #161b22; border: 1px solid #30363d; border-radius: 10px; padding: 20px; margin: 10px 0; }
    .big-number { font-size: 60px; font-weight: 800; color: #ff7b72; text-align: center; letter-spacing: 8px; }
    .sub-number { font-size: 40px; font-weight: 700; color: #58a6ff; text-align: center; letter-spacing: 5px; }
    .status-badge { padding: 5px 15px; border-radius: 20px; font-weight: bold; display: inline-block; }
    .bg-go { background: #238636; color: white; }
    .bg-stop { background: #da3633; color: white; }
    .algo-box { background: #1f2937; border-left: 4px solid #3b82f6; padding: 15px; margin: 10px 0; border-radius: 5px; }
    .stat-card { background: #1f2937; padding: 15px; border-radius: 8px; text-align: center; }
    </style>
""", unsafe_allow_html=True)

st.title("üéØ TITAN v26.0 - 4 THU·∫¨T TO√ÅN N√ÇNG CAO")
st.markdown("---")

# ================= SIDEBAR =================
with st.sidebar:
    st.header("üíæ Database")
    
    uploaded_db = st.file_uploader("üìÇ N·∫°p DB (JSON)", type="json")
    if uploaded_db:
        st.session_state.history = load_data_from_json(uploaded_db)
        st.success(f"ƒê√£ n·∫°p {len(st.session_state.history)} k·ª≥!")
        st.rerun()
    
    st.divider()
    
    if st.session_state.history:
        json_data = convert_df_to_json(st.session_state.history)
        st.download_button(
            label="üíæ T·∫£i DB v·ªÅ",
            data=json_data,
            file_name=f"titan_db_{datetime.now().strftime('%Y%m%d')}.json",
            mime="application/json"
        )
    
    st.divider()
    st.write(f"üìä **T·ªïng k·ª≥:** {len(st.session_state.history)}")
    if st.button("üóëÔ∏è X√≥a d·ªØ li·ªáu"):
        st.session_state.history = []
        st.rerun()

# ================= NH·∫¨P LI·ªÜU =================
col1, col2 = st.columns([3, 1])
with col1:
    raw_input = st.text_area("üì° D√°n k·∫øt qu·∫£ (M·ªói d√≤ng 5 s·ªë)", height=150, placeholder="32880\n21808...")
with col2:
    st.metric("K·ª≥ g·∫ßn nh·∫•t", len(st.session_state.history))
    if st.button("üöÄ L∆ØU D·ªÆ LI·ªÜU", type="primary", use_container_width=True):
        if raw_input:
            clean = re.findall(r"\d{5}", raw_input)
            if clean:
                new_data = list(dict.fromkeys(clean))
                st.session_state.history.extend(new_data)
                st.session_state.history = st.session_state.history[-1000:]
                st.success(f"‚úÖ ƒê√£ l∆∞u {len(new_data)} k·ª≥!")
                st.rerun()

# ================= PH√ÇN T√çCH 4 THU·∫¨T TO√ÅN =================
st.markdown("---")
st.subheader("üî¨ PH√ÇN T√çCH ƒêA THU·∫¨T TO√ÅN")

if st.session_state.history and len(st.session_state.history) >= 20:
    if st.button("üéØ CH·∫†Y 4 THU·∫¨T TO√ÅN", type="secondary", use_container_width=True):
        with st.spinner("üß† ƒêang ph√¢n t√≠ch..."):
            
            # Thu·∫≠t to√°n 1: T·∫ßn su·∫•t n√¢ng cao
            freq_analysis = advanced_frequency_analysis(st.session_state.history)
            
            # Thu·∫≠t to√°n 2: Nh·∫≠n di·ªán c·∫ßu
            patterns = detect_patterns(st.session_state.history)
            
            # Thu·∫≠t to√°n 3: Th·ªëng k√™ t·ªïng
            totals = analyze_totals(st.session_state.history)
            
            # Thu·∫≠t to√°n 4: D·ª± ƒëo√°n v·ªã tr√≠
            pos_pred = position_prediction(st.session_state.history)
            
            # T·ªïng h·ª£p k·∫øt qu·∫£
            all_digits = []
            for pos_data in freq_analysis.values():
                all_digits.extend(list(pos_data.keys())[:3])
            
            for pattern in patterns['cau_bet'] + patterns['cau_nhip']:
                all_digits.append(pattern['so'])
            
            # T√¨m s·ªë xu·∫•t hi·ªán nhi·ªÅu nh·∫•t
            final_freq = Counter(all_digits)
            top_7 = [str(x[0]) for x in final_freq.most_common(7)]
            
            # G·ª≠i AI ph√¢n t√≠ch t·ªïng h·ª£p
            prompt = f"""
            Role: Chuy√™n gia x·ªï s·ªë cao c·∫•p.
            
            D·ªÆ LI·ªÜU PH√ÇN T√çCH:
            1. L·ªãch s·ª≠ 50 k·ª≥: {st.session_state.history[-50:]}
            
            2. T·∫¶N SU·∫§T N√ÇNG CAO (theo v·ªã tr√≠):
            {json.dumps(freq_analysis, ensure_ascii=False)}
            
            3. M√î H√åNH C·∫¶U PH√ÅT HI·ªÜN:
            - C·∫ßu b·ªát: {patterns['cau_bet']}
            - C·∫ßu nh·ªãp: {patterns['cau_nhip']}
            - S·ªë l√¢u ch∆∞a ra: {patterns['cau_cham']}
            
            4. TH·ªêNG K√ä T·ªîNG:
            {json.dumps(totals, ensure_ascii=False)}
            
            5. D·ª∞ ƒêO√ÅN V·ªä TR√ç:
            {json.dumps(pos_pred, ensure_ascii=False)}
            
            6. TOP 7 S·ªê T·ª™ THU·∫¨T TO√ÅN: {top_7}
            
            NHI·ªÜM V·ª§:
            1. Ch·ªçn 3 s·ªë ch√≠nh (c√≥ x√°c su·∫•t cao nh·∫•t)
            2. Ch·ªçn 4 s·ªë l√≥t (b·ªï sung)
            3. Quy·∫øt ƒë·ªãnh ƒê√ÅNH ho·∫∑c CH·ªú
            4. Gi·∫£i th√≠ch logic r√µ r√†ng
            
            Output JSON:
            {{
                "main_3": "abc",
                "support_4": "defg",
                "decision": "ƒê√ÅNH",
                "confidence": 85,
                "reasoning": "Ph√¢n t√≠ch chi ti·∫øt...",
                "algorithm_weights": {{
                    "frequency": "30%",
                    "patterns": "40%",
                    "totals": "15%",
                    "positions": "15%"
                }}
            }}
            """
            
            try:
                response = neural_engine.generate_content(prompt)
                json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
                if json_match:
                    st.session_state.last_prediction = json.loads(json_match.group())
                    st.session_state.last_prediction['algorithms'] = {
                        'frequency': freq_analysis,
                        'patterns': patterns,
                        'totals': totals,
                        'positions': pos_pred
                    }
                    st.success("‚úÖ Ph√¢n t√≠ch ho√†n t·∫•t!")
                    st.rerun()
            except Exception as e:
                st.error(f"L·ªói AI: {e}")
                # Fallback
                st.session_state.last_prediction = {
                    "main_3": "".join(top_7[:3]),
                    "support_4": "".join(top_7[3:]),
                    "decision": "ƒê√ÅNH",
                    "confidence": 75,
                    "reasoning": "D√πng th·ªëng k√™ thu·∫ßn t√∫y"
                }
                st.rerun()

elif st.session_state.history:
    st.warning(f"‚ö†Ô∏è C·∫ßn √≠t nh·∫•t 20 k·ª≥ ƒë·ªÉ ph√¢n t√≠ch (hi·ªán c√≥ {len(st.session_state.history)})")

# ================= HI·ªÇN TH·ªä K·∫æT QU·∫¢ =================
if st.session_state.last_prediction:
    res = st.session_state.last_prediction
    is_go = res.get('decision', '').upper() == 'ƒê√ÅNH'
    badge_class = "bg-go" if is_go else "bg-stop"
    
    st.markdown("---")
    st.markdown(f"<div class='main-card'>", unsafe_allow_html=True)
    
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.markdown(f"<h2 style='text-align:center'>üì¢ K·∫æT LU·∫¨N: <span class='status-badge {badge_class}'>{res.get('decision', 'CH·ªú')}</span></h2>", unsafe_allow_html=True)
    
    st.divider()
    
    c_num1, c_num2 = st.columns(2)
    with c_num1:
        st.markdown("<p style='text-align:center;color:#8b949e'>üî• 3 S·ªê CH√çNH</p>", unsafe_allow_html=True)
        st.markdown(f"<div class='big-number'>{res.get('main_3', '???')}</div>", unsafe_allow_html=True)
    with c_num2:
        st.markdown("<p style='text-align:center;color:#8b949e'>üõ°Ô∏è 4 S·ªê L√ìT</p>", unsafe_allow_html=True)
        st.markdown(f"<div class='sub-number'>{res.get('support_4', '???')}</div>", unsafe_allow_html=True)
    
    st.divider()
    st.info(f"üí° **Logic:** {res.get('reasoning', 'N/A')}")
    st.success(f"üéØ **ƒê·ªô tin c·∫≠y:** {res.get('confidence', 0)}%")
    
    # D√†n s·ªë
    full_set = "".join(sorted(set(str(res.get('main_3', '')) + str(res.get('support_4', '')))))
    st.text_input("üìã D√†n s·ªë (Copy):", full_set)
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # ================= CHI TI·∫æT 4 THU·∫¨T TO√ÅN =================
    if 'algorithms' in res:
        algos = res['algorithms']
        
        st.markdown("### üìä CHI TI·∫æT PH√ÇN T√çCH")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown("##### 1Ô∏è‚É£ T·∫¶N SU·∫§T")
            for pos, data in algos['frequency'].items():
                if data:
                    top_num = list(data.keys())[0]
                    st.write(f"{pos}: **{top_num}**")
        
        with col2:
            st.markdown("##### 2Ô∏è‚É£ C·∫¶U")
            if algos['patterns']['cau_bet']:
                st.write(f" B·ªát: {[x['so'] for x in algos['patterns']['cau_bet'][:3]]}")
            if algos['patterns']['cau_nhip']:
                st.write(f"üîµ Nh·ªãp: {[x['so'] for x in algos['patterns']['cau_nhip'][:3]]}")
        
        with col3:
            st.markdown("##### 3Ô∏è‚É£ T·ªîNG")
            st.write(f"TB: {algos['totals'].get('avg_total', 'N/A')}")
            st.write(f"N√≥ng: {algos['totals'].get('hot_totals', [])}")
        
        with col4:
            st.markdown("##### 4Ô∏è‚É£ V·ªä TR√ç")
            for pos_name, data in list(algos['positions'].items())[:3]:
                st.write(f"{pos_name}: {data['trending']}")

# ================= BI·ªÇU ƒê·ªí =================
st.markdown("---")
with st.expander("üìà Bi·ªÉu ƒë·ªì t·∫ßn su·∫•t"):
    if st.session_state.history:
        all_d = "".join(st.session_state.history[-50:])
        df_freq = pd.Series(Counter(all_d)).sort_index()
        st.bar_chart(df_freq, color="#58a6ff")

# ================= FOOTER =================
st.markdown("---")
st.caption("‚ö†Ô∏è **C·∫£nh b√°o:** C√¥ng c·ª• tham kh·∫£o. Kh√¥ng ƒë·∫£m b·∫£o 100%.")
st.caption(f"üïê C·∫≠p nh·∫≠t: {datetime.now().strftime('%d/%m/%Y %H:%M')}")