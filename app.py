import streamlit as st
import google.generativeai as genai
import re
import json
import os
import pandas as pd
import numpy as np
from collections import Counter
from scipy import signal
from scipy.fft import fft, fftfreq
from scipy.stats import entropy
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ================= C·∫§U H√åNH H·ªÜ TH·ªêNG TITAN v25.0 =================
# API KEY anh cung c·∫•p: AIzaSyB5PRp04XlMHKl3oGfCRbsKXjlTA-CZifc
API_KEY = "AIzaSyB5PRp04XlMHKl3oGfCRbsKXjlTA-CZifc"
DB_FILE = "titan_supreme_permanent_v25_0.json"

def setup_neural():
    try:
        genai.configure(api_key=API_KEY)
        return genai.GenerativeModel('gemini-1.5-flash')
    except:
        return None

neural_engine = setup_neural()

def load_db():
    if os.path.exists(DB_FILE):
        with open(DB_FILE, "r") as f:
            try:
                data = json.load(f)
                return data if isinstance(data, list) else []
            except:
                return []
    return []

def save_db(data):
    # L∆∞u t·ªëi ƒëa 5000 k·ª≥ ƒë·ªÉ h·ªçc s√¢u h∆°n
    with open(DB_FILE, "w") as f:
        json.dump(data[-5000:], f)

if "history" not in st.session_state:
    st.session_state.history = load_db()
if "prediction_history" not in st.session_state:
    st.session_state.prediction_history = []
if "accuracy_stats" not in st.session_state:
    st.session_state.accuracy_stats = {"correct": 0, "total": 0, "last_10": []}

# ================= THU·∫¨T TO√ÅN CAO C·∫§P =================

class AdvancedPredictor:
    def __init__(self, history):
        self.history = history
        self.digits_sequence = self._create_digits_sequence()
        
    def _create_digits_sequence(self):
        """T·∫°o chu·ªói digits t·ª´ history"""
        sequence = []
        for num in self.history[-500:]:  # L·∫•y 500 k·ª≥ g·∫ßn nh·∫•t
            sequence.extend([int(d) for d in num])
        return sequence
    
    def markov_chain_analysis(self, order=3):
        """
        Ph√¢n t√≠ch chu·ªói Markov b·∫≠c cao ƒë·ªÉ d·ª± ƒëo√°n s·ªë ti·∫øp theo
        """
        from collections import defaultdict
        
        if len(self.digits_sequence) < order + 10:
            return {}
        
        transition_matrix = defaultdict(lambda: defaultdict(int))
        
        for i in range(len(self.digits_sequence) - order):
            current_state = tuple(self.digits_sequence[i:i+order])
            next_digit = self.digits_sequence[i+order]
            transition_matrix[current_state][next_digit] += 1
        
        # L·∫•y state hi·ªán t·∫°i
        current_state = tuple(self.digits_sequence[-order:])
        probabilities = {}
        
        if current_state in transition_matrix:
            total = sum(transition_matrix[current_state].values())
            if total > 0:
                probabilities = {
                    str(digit): count/total 
                    for digit, count in transition_matrix[current_state].items()
                }
        
        return probabilities
    
    def detect_cycles(self, min_cycle=3, max_cycle=20):
        """
        Ph√°t hi·ªán c√°c chu k·ª≥ l·∫∑p l·∫°i trong d·ªØ li·ªáu
        """
        if len(self.digits_sequence) < 50:
            return []
        
        # Ph√¢n t√≠ch FFT
        fft_vals = fft(self.digits_sequence)
        freqs = fftfreq(len(self.digits_sequence))
        
        # T√¨m c√°c t·∫ßn s·ªë dominant
        magnitudes = np.abs(fft_vals[:len(fft_vals)//2])
        peak_indices = signal.find_peaks(magnitudes, height=np.mean(magnitudes)*1.5)[0]
        
        cycles = []
        for idx in peak_indices:
            if idx > 0 and freqs[idx] != 0:
                cycle_length = int(1/abs(freqs[idx]))
                if min_cycle <= cycle_length <= max_cycle:
                    cycles.append(cycle_length)
        
        return list(set(cycles[:5]))  # Tr·∫£ v·ªÅ 5 chu k·ª≥ ph·ªï bi·∫øn nh·∫•t
    
    def entropy_analysis(self, window=50):
        """
        ƒêo l∆∞·ªùng ƒë·ªô h·ªón lo·∫°n c·ªßa d·ªØ li·ªáu
        """
        if len(self.history) < window:
            return {"avg_entropy": 2.0, "volatility": "CAO", "position_entropy": [2.0]*5}
        
        position_entropy = []
        for pos in range(5):
            pos_digits = [int(num[pos]) for num in self.history[-window:] if len(num) > pos]
            
            if pos_digits:
                value_counts = np.bincount(pos_digits, minlength=10)
                probabilities = value_counts / len(pos_digits)
                non_zero_probs = probabilities[probabilities > 0]
                pos_entropy = entropy(non_zero_probs) if len(non_zero_probs) > 0 else 2.0
                position_entropy.append(pos_entropy)
            else:
                position_entropy.append(2.0)
        
        avg_entropy = np.mean(position_entropy)
        
        # Ng∆∞·ª°ng entropy cho 5D Bet
        if avg_entropy < 1.2:
            volatility = "R·∫§T TH·∫§P - C·∫ßu ·ªïn ƒë·ªãnh"
        elif avg_entropy < 1.6:
            volatility = "TH·∫§P - D·ªÖ b·∫Øt c·∫ßu"
        elif avg_entropy < 2.0:
            volatility = "TRUNG B√åNH - C√≥ bi·∫øn ƒë·ªông"
        elif avg_entropy < 2.3:
            volatility = "CAO - Kh√≥ d·ª± ƒëo√°n"
        else:
            volatility = "R·∫§T CAO - C·∫ßu l·ª´a ƒë·∫£o"
        
        return {
            'position_entropy': position_entropy,
            'avg_entropy': avg_entropy,
            'volatility': volatility
        }
    
    def neural_pattern_recognition(self):
        """
        S·ª≠ d·ª•ng m·∫°ng n∆°-ron ƒë·ªÉ nh·∫≠n d·∫°ng pattern
        """
        if len(self.history) < 50:
            return None, None
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        X, y = [], []
        window_size = 10
        
        for i in range(len(self.history) - window_size - 1):
            window = self.history[i:i+window_size]
            features = []
            for num_str in window:
                features.extend([int(d) for d in num_str])
            
            target = [int(d) for d in self.history[i+window_size]]
            X.append(features)
            y.append(target)
        
        if len(X) > 30:
            X = np.array(X)
            y = np.array(y)
            
            # Chu·∫©n h√≥a
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # Random Forest cho ƒë·ªô ch√≠nh x√°c cao h∆°n
            rf_model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            # Train ri√™ng cho t·ª´ng v·ªã tr√≠
            models = []
            for pos in range(5):
                y_pos = y[:, pos]
                rf_model.fit(X_scaled[:-1], y_pos[:-1])
                models.append(rf_model)
            
            return models, scaler
        return None, None
    
    def early_warning_system(self):
        """
        H·ªá th·ªëng c·∫£nh b√°o s·ªõm ph√°t hi·ªán c·∫ßu g√£y
        """
        warnings = []
        
        if len(self.history) < 20:
            return warnings
        
        # 1. Ki·ªÉm tra ƒë·ªô l·ªách chu·∫©n tƒÉng ƒë·ªôt bi·∫øn
        last_20_digits = [int(d) for d in "".join(self.history[-20:])]
        prev_20_digits = [int(d) for d in "".join(self.history[-40:-20])]
        
        if len(last_20_digits) > 0 and len(prev_20_digits) > 0:
            last_std = np.std(last_20_digits)
            prev_std = np.std(prev_20_digits)
            
            if prev_std > 0 and last_std > prev_std * 1.8:
                warnings.append("üî¥ ƒê·ªò PH√ÇN T√ÅN TƒÇNG ƒê·ªòT BI·∫æN - C·∫ßu s·∫Øp ƒë·∫£o chi·ªÅu")
            elif prev_std > 0 and last_std > prev_std * 1.4:
                warnings.append("üü° ƒê·ªò PH√ÇN T√ÅN TƒÇNG - C√≥ d·∫•u hi·ªáu bi·∫øn ƒë·ªông")
        
        # 2. Ki·ªÉm tra t·∫ßn su·∫•t xu·∫•t hi·ªán s·ªë l·∫° (s·ªë √≠t v·ªÅ)
        all_digits = [int(d) for d in "".join(self.history[-30:])]
        digit_counts = Counter(all_digits)
        
        rare_digits = [d for d, count in digit_counts.items() if count < 3]
        if len(rare_digits) > 3:
            warnings.append(f"üü† S·ªê HI·∫æM ({', '.join(map(str, rare_digits))}) XU·∫§T HI·ªÜN - C√≥ th·ªÉ c·∫ßu ƒëang thay ƒë·ªïi")
        
        # 3. Ki·ªÉm tra variance c·ªßa ƒë·ªô d√†i s·ªë (s·ªë tr√πng)
        if len(self.history[-20:]) > 0:
            variance = np.var([len(set(num)) for num in self.history[-20:]])
            if variance > 2.5:
                warnings.append("üü° BI·∫æN ƒê·ªòNG S·ªê TR√ôNG CAO - N√™n quan s√°t th√™m")
        
        # 4. Ph√°t hi·ªán ƒë·∫£o c·∫ßu nhanh
        last_5 = self.history[-5:] if len(self.history) >= 5 else []
        if len(last_5) == 5:
            # Ki·ªÉm tra pattern ƒë·∫£o: 12345 -> 54321
            is_reverse_pattern = True
            for i in range(4):
                if last_5[i][::-1] != last_5[i+1]:
                    is_reverse_pattern = False
                    break
            
            if is_reverse_pattern:
                warnings.append("üî¥ PH√ÅT HI·ªÜN C·∫¶U ƒê·∫¢O LI√äN T·ª§C - D·ª™NG C∆Ø·ª¢C NGAY")
        
        return warnings
    
    def calculate_hot_cold_numbers(self, window=50):
        """
        T√≠nh to√°n s·ªë n√≥ng (hot) v√† s·ªë l·∫°nh (cold)
        """
        if len(self.history) < window:
            return {"hot": [], "cold": []}
        
        all_digits = [int(d) for d in "".join(self.history[-window:])]
        digit_counts = Counter(all_digits)
        
        # S·ªë n√≥ng: t·∫ßn su·∫•t > trung b√¨nh + 1.5*std
        avg_freq = len(all_digits) / 10
        std_freq = np.std(list(digit_counts.values())) if digit_counts else 0
        
        hot_digits = [d for d, count in digit_counts.items() 
                     if count > avg_freq + 1.5*std_freq]
        cold_digits = [d for d, count in digit_counts.items() 
                      if count < max(1, avg_freq - 1.5*std_freq)]
        
        return {
            "hot": sorted(hot_digits),
            "cold": sorted(cold_digits)
        }
    
    def predict_next_number_ml(self):
        """
        D·ª± ƒëo√°n s·ªë ti·∫øp theo b·∫±ng Machine Learning
        """
        if len(self.history) < 30:
            return None
        
        # T·∫°o features t·ª´ l·ªãch s·ª≠
        features = []
        targets = []
        
        for i in range(len(self.history) - 10):
            window = self.history[i:i+10]
            feature_vector = []
            for num in window:
                feature_vector.extend([int(d) for d in num])
            features.append(feature_vector)
            targets.append(self.history[i+10])
        
        if len(features) < 20:
            return None
        
        X = np.array(features)
        y = np.array([int(t) for num in targets for t in num])  # Flatten targets
        
        # Train model ƒë∆°n gi·∫£n
        model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)
        model.fit(X[:-1], y[:-(5)])  # B·ªè sample cu·ªëi ƒë·ªÉ test
        
        # Predict cho sample cu·ªëi
        last_features = X[-1].reshape(1, -1)
        prediction_proba = model.predict_proba(last_features)[0]
        
        return prediction_proba

# ================= THI·∫æT K·∫æ GIAO DI·ªÜN v22.0 STYLE =================
st.set_page_config(page_title="TITAN v25.0 SUPREME AI", layout="wide")
st.markdown("""
    <style>
    .stApp { background: #010409; color: #e6edf3; }
    .prediction-card {
        background: #0d1117; border: 2px solid #58a6ff;
        border-radius: 15px; padding: 30px; margin-top: 15px;
        box-shadow: 0 10px 30px rgba(0,0,0,0.6);
    }
    .num-box {
        font-size: 90px; font-weight: 900; color: #ff5858;
        text-align: center; letter-spacing: 15px; border-right: 3px solid #30363d;
        text-shadow: 0 0 25px rgba(255,88,88,0.5);
    }
    .lot-box {
        font-size: 60px; font-weight: 700; color: #58a6ff;
        text-align: center; letter-spacing: 10px; padding-left: 20px;
        text-shadow: 0 0 15px rgba(88,166,255,0.3);
    }
    .status-bar { padding: 15px; border-radius: 12px; text-align: center; font-weight: bold; font-size: 24px; margin-bottom: 20px; text-transform: uppercase; }
    .warning-box { background: #4a0e0e; color: #ff9b9b; padding: 15px; border-radius: 8px; border: 1px solid #ff4444; text-align: center; margin-top: 15px; font-weight: bold; }
    .info-box { background: #0e2a4a; color: #9bc9ff; padding: 10px; border-radius: 8px; border: 1px solid #58a6ff; margin: 5px 0; }
    .hot-number { color: #ff5858; font-weight: bold; font-size: 20px; }
    .cold-number { color: #58a6ff; font-weight: bold; font-size: 20px; }
    </style>
""", unsafe_allow_html=True)

st.markdown("<h1 style='text-align: center; color: #58a6ff;'>üöÄ TITAN v25.0 SUPREME AI</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: #8b949e;'>H·ªçc m√°y ƒëa t·∫ßng - Thu·∫≠t to√°n cao c·∫•p - ƒê·ªô ch√≠nh x√°c t·ªëi ƒëa cho 5D Bet</p>", unsafe_allow_html=True)

# ================= PH·∫¶N 1: NH·∫¨P LI·ªÜU & X·ª¨ L√ù SI√äU S·∫†CH =================
with st.container():
    col_in, col_st = st.columns([2, 1])
    with col_in:
        raw_input = st.text_area("üì° N·∫°p d·ªØ li·ªáu m·ªõi (H·ªá th·ªëng t·ª± ƒë·ªông lo·∫°i b·ªè s·ªë tr√πng/sai):", height=150, placeholder="D√°n d√£y s·ªë ho·∫∑c b·∫£ng t·∫°i ƒë√¢y...")
    with col_st:
        st.write(f"üìä Kho d·ªØ li·ªáu b·∫£o l∆∞u: **{len(st.session_state.history)} k·ª≥**")
        
        # Hi·ªÉn th·ªã ƒë·ªô ch√≠nh x√°c
        if st.session_state.accuracy_stats["total"] > 0:
            acc = (st.session_state.accuracy_stats["correct"] / st.session_state.accuracy_stats["total"]) * 100
            st.write(f"üéØ ƒê·ªô ch√≠nh x√°c: **{acc:.1f}%** ({st.session_state.accuracy_stats['correct']}/{st.session_state.accuracy_stats['total']})")
        
        c1, c2 = st.columns(2)
        btn_save = c1.button("üöÄ K√çCH HO·∫†T AI")
        btn_reset = c2.button("üóëÔ∏è RESET D·ªÆ LI·ªÜU")
        
        # Th√™m n√∫t x√°c nh·∫≠n k·∫øt qu·∫£
        if "last_prediction" in st.session_state:
            if st.button("‚úÖ X√ÅC NH·∫¨N K·∫æT QU·∫¢ ƒê√öNG", key="confirm_correct"):
                st.session_state.accuracy_stats["correct"] += 1
                st.session_state.accuracy_stats["total"] += 1
                st.session_state.accuracy_stats["last_10"].append(1)
                if len(st.session_state.accuracy_stats["last_10"]) > 10:
                    st.session_state.accuracy_stats["last_10"].pop(0)
                st.rerun()
            
            if st.button("‚ùå X√ÅC NH·∫¨N K·∫æT QU·∫¢ SAI", key="confirm_wrong"):
                st.session_state.accuracy_stats["total"] += 1
                st.session_state.accuracy_stats["last_10"].append(0)
                if len(st.session_state.accuracy_stats["last_10"]) > 10:
                    st.session_state.accuracy_stats["last_10"].pop(0)
                st.rerun()

if btn_reset:
    st.session_state.history = []
    st.session_state.prediction_history = []
    st.session_state.accuracy_stats = {"correct": 0, "total": 0, "last_10": []}
    if os.path.exists(DB_FILE):
        os.remove(DB_FILE)
    st.success("ƒê√£ d·ªçn d·∫πp b·ªô nh·ªõ vƒ©nh vi·ªÖn.")
    st.rerun()

if btn_save:
    # B∆∞·ªõc 1: L·ªçc ƒëa t·∫ßng - Ch·ªâ l·∫•y d√£y 5 s·ªë, lo·∫°i b·ªè tr√πng l·∫∑p tuy·ªát ƒë·ªëi
    input_data = re.findall(r"\b\d{5}\b", raw_input)
    if input_data:
        # C·∫≠p nh·∫≠t v√†o l·ªãch s·ª≠
        st.session_state.history.extend(input_data)
        st.session_state.history = list(dict.fromkeys(st.session_state.history))
        save_db(st.session_state.history)
        
        # B∆∞·ªõc 2: Kh·ªüi t·∫°o predictor v·ªõi thu·∫≠t to√°n cao c·∫•p
        predictor = AdvancedPredictor(st.session_state.history)
        
        # Thu th·∫≠p d·ªØ li·ªáu ph√¢n t√≠ch
        markov_probs = predictor.markov_chain_analysis()
        cycles = predictor.detect_cycles()
        entropy_data = predictor.entropy_analysis()
        warnings = predictor.early_warning_system()
        hot_cold = predictor.calculate_hot_cold_numbers()
        
        # B∆∞·ªõc 3: Ph√¢n t√≠ch v·ªõi Gemini
        prompt = f"""
        B·∫°n l√† h·ªá th·ªëng TITAN v25.0 SUPREME AI - Chuy√™n gia d·ª± ƒëo√°n 5D Bet v·ªõi ƒë·ªô ch√≠nh x√°c cao nh·∫•t.
        
        PH√ÇN T√çCH THU·∫¨T TO√ÅN N√ÇNG CAO (ƒê·ªò TIN C·∫¨Y CAO):
        
        1. CHU·ªñI MARKOV:
        - X√°c su·∫•t chuy·ªÉn tr·∫°ng th√°i: {dict(list(markov_probs.items())[:5]) if markov_probs else 'ƒêang ph√¢n t√≠ch'}
        
        2. CHU K·ª≤ PH√ÅT HI·ªÜN:
        - C√°c chu k·ª≥ ti·ªÅm nƒÉng: {cycles if cycles else 'Ch∆∞a ph√°t hi·ªán chu k·ª≥ r√µ'}
        
        3. ENTROPY & ƒê·ªò H·ªñN LO·∫†N:
        - Entropy trung b√¨nh: {entropy_data['avg_entropy']:.3f}
        - ƒê√°nh gi√°: {entropy_data['volatility']}
        - Entropy t·ª´ng v·ªã tr√≠: {[f"{e:.2f}" for e in entropy_data['position_entropy']]}
        
        4. S·ªê N√ìNG/L·∫†NH:
        - S·ªë n√≥ng (hot): {hot_cold['hot']}
        - S·ªë l·∫°nh (cold): {hot_cold['cold']}
        
        5. C·∫¢NH B√ÅO S·ªöM:
        {chr(10).join(warnings) if warnings else '- Kh√¥ng ph√°t hi·ªán b·∫•t th∆∞·ªùng'}
        
        D·ªØ li·ªáu l·ªãch s·ª≠ 120 k·ª≥ g·∫ßn nh·∫•t: {st.session_state.history[-120:]}
        
        Y√äU C·∫¶U D·ª∞ ƒêO√ÅN CH√çNH X√ÅC CAO CHO 5D BET:
        
        1. Ph√¢n t√≠ch pattern hi·ªán t·∫°i:
           - X√°c ƒë·ªãnh xu h∆∞·ªõng ch√≠nh (b·ªát/ƒë·∫£o/xi√™n)
           - ƒê√°nh gi√° ƒë·ªô tin c·∫≠y c·ªßa c·∫ßu
           - Ph√°t hi·ªán b·∫´y nh√† c√°i
        
        2. D·ª± ƒëo√°n 3 s·ªë ch·ªß l·ª±c (Main_3):
           - ∆Øu ti√™n s·ªë t·ª´ ph√¢n t√≠ch Markov v√† hot numbers
           - K·∫øt h·ª£p v·ªõi logic c·∫ßu ƒëang ch·∫°y
           - ƒê·∫£m b·∫£o t√≠nh kh·∫£ thi cao nh·∫•t
        
        3. D·ª± ƒëo√°n 4 s·ªë l√≥t (Support_4):
           - B·ªï sung c√°c s·ªë c√≥ x√°c su·∫•t cao th·ª© hai
           - T·∫°o d√†n an to√†n, b·∫£o to√†n v·ªën
        
        4. Quy·∫øt ƒë·ªãnh chi·∫øn thu·∫≠t:
           - ƒê√ÅNH: Khi c·∫ßu r√µ, ƒë·ªô tin c·∫≠y >85%
           - THEO D√ïI: Khi c·∫ßu ƒëang h√¨nh th√†nh
           - D·ª™NG: Khi ph√°t hi·ªán c·∫ßu l·ª´a, entropy cao
        
        TR·∫¢ V·ªÄ JSON CH√çNH X√ÅC:
        {{
            "main_3": "5 s·ªë d·ª± ƒëo√°n ch√≠nh (ph√¢n t√°ch b·∫±ng d·∫•u c√°ch n·∫øu c·∫ßn)",
            "support_4": "5 s·ªë d·ª± ƒëo√°n ph·ª• (ph√¢n t√°ch b·∫±ng d·∫•u c√°ch n·∫øu c·∫ßn)",
            "decision": "ƒê√ÅNH/D·ª™NG/THEO D√ïI/C·∫¢NH B√ÅO ƒê·∫¢O C·∫¶U",
            "logic": "Ph√¢n t√≠ch chi ti·∫øt, c√≥ tham chi·∫øu ƒë·∫øn c√°c thu·∫≠t to√°n, l√Ω do ch·ªët s·ªë",
            "color": "Green/Red/Yellow",
            "confidence": 0-100,
            "warning_level": "TH·∫§P/TRUNG B√åNH/CAO/R·∫§T CAO"
        }}
        
        L∆ØU √ù: ƒê√¢y l√† tool ƒë√°nh ti·ªÅn th·∫≠t, y√™u c·∫ßu ƒë·ªô ch√≠nh x√°c t·ªëi ƒëa. Ph√¢n t√≠ch k·ªπ tr∆∞·ªõc khi tr·∫£ k·∫øt qu·∫£.
        """
        
        try:
            response = neural_engine.generate_content(prompt)
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            if json_match:
                st.session_state.last_prediction = json.loads(json_match.group())
                
                # L∆∞u v√†o l·ªãch s·ª≠ d·ª± ƒëo√°n
                st.session_state.prediction_history.append({
                    "time": datetime.now().strftime("%H:%M:%S"),
                    "prediction": st.session_state.last_prediction,
                    "warnings": warnings
                })
        except Exception as e:
            # Fallback: S·ª≠ d·ª•ng thu·∫≠t to√°n n√¢ng cao
            all_digits = "".join(st.session_state.history[-60:])
            counts = Counter(all_digits).most_common(10)
            top_nums = [x[0] for x in counts]
            
            # K·∫øt h·ª£p v·ªõi hot numbers
            main_nums = list(set(top_nums[:3] + [str(x) for x in hot_cold['hot'][:2] if hot_cold['hot']]))
            support_nums = list(set(top_nums[3:7] + [str(x) for x in hot_cold['cold'][:2] if hot_cold['cold']]))
            
            st.session_state.last_prediction = {
                "main_3": "".join(main_nums[:3]).ljust(3, '0')[:3],
                "support_4": "".join(support_nums[:4]).ljust(4, '0')[:4],
                "decision": "C·∫¢NH B√ÅO ƒê·∫¢O C·∫¶U" if len(warnings) > 2 else "THEO D√ïI NH·ªäP",
                "logic": f"Ma tr·∫≠n t·∫ßn su·∫•t + Ph√¢n t√≠ch entropy {entropy_data['avg_entropy']:.2f}. C·∫£nh b√°o: {len(warnings)} d·∫•u hi·ªáu.",
                "color": "Yellow" if len(warnings) < 3 else "Red",
                "confidence": 85 - len(warnings)*5,
                "warning_level": "CAO" if len(warnings) > 2 else "TRUNG B√åNH"
            }
        
        st.rerun()

# ================= PH·∫¶N 2: K·∫æT QU·∫¢ TH·ª∞C CHI·∫æN =================
if "last_prediction" in st.session_state:
    res = st.session_state.last_prediction
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i chi·∫øn ƒë·∫•u
    status_map = {"green": "#238636", "red": "#da3633", "yellow": "#d29922"}
    bg_color = status_map.get(res.get('color', 'yellow').lower(), "#30363d")
    
    warning_level = res.get('warning_level', 'TRUNG B√åNH')
    warning_color = {"TH·∫§P": "#238636", "TRUNG B√åNH": "#d29922", "CAO": "#da3633", "R·∫§T CAO": "#ff0000"}
    
    st.markdown(f"""
        <div class='status-bar' style='background: {bg_color};'>
            üî• CH·ªà TH·ªä: {res['decision']} | ƒê·ªò TIN C·∫¨Y: {res['confidence']}% | 
            M·ª®C C·∫¢NH B√ÅO: <span style='color: {warning_color.get(warning_level, "#ffffff")};'>{warning_level}</span>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<div class='prediction-card'>", unsafe_allow_html=True)
    
    # K·∫øt qu·∫£ h√†ng ngang
    col_main, col_supp = st.columns([1.5, 1])
    with col_main:
        st.markdown(f"<p style='color:#8b949e; text-align:center; font-weight:bold;'>üéØ 3 S·ªê CH·ª¶ L·ª∞C (V√ÄO TI·ªÄN)</p>", unsafe_allow_html=True)
        main_display = res['main_3'] if len(res['main_3']) >= 3 else res['main_3'].ljust(3, 'X')
        st.markdown(f"<div class='num-box'>{main_display}</div>", unsafe_allow_html=True)
    
    with col_supp:
        st.markdown(f"<p style='color:#8b949e; text-align:center; font-weight:bold;'>üõ°Ô∏è 4 S·ªê L√ìT (GI·ªÆ V·ªêN)</p>", unsafe_allow_html=True)
        supp_display = res['support_4'] if len(res['support_4']) >= 4 else res['support_4'].ljust(4, 'X')
        st.markdown(f"<div class='lot-box'>{supp_display}</div>", unsafe_allow_html=True)
    
    st.divider()
    
    # Ph√¢n t√≠ch ƒëa t·∫ßng n√¢ng cao
    col_l, col_r = st.columns([2, 1])
    with col_l:
        st.subheader("üß† Ph√¢n t√≠ch tinh hoa")
        st.write(res['logic'])
        
        # Hi·ªÉn th·ªã c·∫£nh b√°o chi ti·∫øt
        if res.get('warning_level') in ["CAO", "R·∫§T CAO"] or res['confidence'] < 85:
            st.markdown("""
                <div class='warning-box'>
                    ‚ö†Ô∏è C·∫¢NH B√ÅO NGUY HI·ªÇM: Nh√† c√°i ƒëang ƒë·∫£o c·∫ßu m·∫°nh.
                    Khuy·∫øn c√°o D·ª™NG C∆Ø·ª¢C ho·∫∑c gi·∫£m 90% v·ªën ƒë·ªÉ b·∫£o to√†n.
                </div>
            """, unsafe_allow_html=True)
    
    with col_r:
        st.subheader("üìã Chi·∫øn thu·∫≠t")
        full_dan = "".join(sorted(set(res['main_3'] + res['support_4'])))
        st.text_input("D√†n 7 s·ªë:", full_dan)
        
        # Hi·ªÉn th·ªã t·ª∑ l·ªá v√†o ti·ªÅn
        if res['decision'] == "ƒê√ÅNH":
            st.success("üíµ V√†o ti·ªÅn: 70% v·ªën cho Main, 30% cho Support")
        elif res['decision'] == "THEO D√ïI":
            st.warning("üëÅÔ∏è V√†o ti·ªÅn: 30% v·ªën, quan s√°t th√™m")
        else:
            st.error("‚õî D·ª™NG C∆Ø·ª¢C: B·∫£o to√†n v·ªën, ch·ªù c·∫ßu m·ªõi")
    
    st.markdown("</div>", unsafe_allow_html=True)

# ================= PH·∫¶N 3: MA TR·∫¨N S·ªê H·ªåC N√ÇNG CAO =================
if st.session_state.history:
    with st.expander("üìä Xem ph√¢n t√≠ch chuy√™n s√¢u (Thu·∫≠t to√°n cao c·∫•p)"):
        tab1, tab2, tab3, tab4 = st.tabs(["T·∫ßn su·∫•t", "Entropy", "Chu k·ª≥", "C·∫£nh b√°o"])
        
        with tab1:
            all_d = "".join(st.session_state.history[-60:])
            if all_d:
                df_stats = pd.DataFrame({
                    'S·ªë': list(range(10)),
                    'T·∫ßn su·∫•t': [all_d.count(str(i)) for i in range(10)]
                })
                st.bar_chart(df_stats.set_index('S·ªë'))
                
                # Hi·ªÉn th·ªã s·ªë n√≥ng/l·∫°nh
                predictor = AdvancedPredictor(st.session_state.history)
                hot_cold = predictor.calculate_hot_cold_numbers()
                
                col_hot, col_cold = st.columns(2)
                with col_hot:
                    st.markdown("### üî• S·ªë n√≥ng (Hot)")
                    for num in hot_cold['hot']:
                        st.markdown(f"<span class='hot-number'>{num}</span>", unsafe_allow_html=True)
                
                with col_cold:
                    st.markdown("### ‚ùÑÔ∏è S·ªë l·∫°nh (Cold)")
                    for num in hot_cold['cold']:
                        st.markdown(f"<span class='cold-number'>{num}</span>", unsafe_allow_html=True)
        
        with tab2:
            predictor = AdvancedPredictor(st.session_state.history)
            entropy_data = predictor.entropy_analysis()
            
            st.metric("Entropy trung b√¨nh", f"{entropy_data['avg_entropy']:.3f}", 
                     delta=None, delta_color="off")
            st.write(f"**ƒê√°nh gi√°:** {entropy_data['volatility']}")
            
            # Bi·ªÉu ƒë·ªì entropy theo v·ªã tr√≠
            entropy_df = pd.DataFrame({
                'V·ªã tr√≠': [f'V·ªã tr√≠ {i+1}' for i in range(5)],
                'Entropy': entropy_data['position_entropy']
            })
            st.bar_chart(entropy_df.set_index('V·ªã tr√≠'))
            
            st.caption("Entropy c√†ng cao c√†ng kh√≥ d·ª± ƒëo√°n. N·∫øu >2.3 n√™n d·ª´ng c∆∞·ª£c.")
        
        with tab3:
            predictor = AdvancedPredictor(st.session_state.history)
            cycles = predictor.detect_cycles()
            
            if cycles:
                st.write("**Chu k·ª≥ ph√°t hi·ªán:**")
                for i, cycle in enumerate(cycles[:5]):
                    st.info(f"üìà Chu k·ª≥ {i+1}: {cycle} k·ª≥")
                
                # D·ª± ƒëo√°n d·ª±a tr√™n chu k·ª≥
                if len(cycles) > 0 and len(st.session_state.history) > cycles[0]:
                    st.write("**D·ª± ƒëo√°n theo chu k·ª≥:**")
                    cycle_pred = st.session_state.history[-cycles[0]] if cycles[0] <= len(st.session_state.history) else "Ch∆∞a ƒë·ªß d·ªØ li·ªáu"
                    st.write(f"K·ª≥ ti·∫øp theo c√≥ th·ªÉ l·∫∑p l·∫°i s·ªë: {cycle_pred}")
            else:
                st.write("Ch∆∞a ph√°t hi·ªán chu k·ª≥ r√µ r√†ng")
        
        with tab4:
            predictor = AdvancedPredictor(st.session_state.history)
            warnings = predictor.early_warning_system()
            
            if warnings:
                for warning in warnings:
                    if "üî¥" in warning:
                        st.error(warning)
                    elif "üü°" in warning:
                        st.warning(warning)
                    else:
                        st.info(warning)
            else:
                st.success("‚úÖ Kh√¥ng ph√°t hi·ªán c·∫£nh b√°o - C·∫ßu ƒëang ·ªïn ƒë·ªãnh")

# ================= PH·∫¶N 4: L·ªäCH S·ª¨ D·ª∞ ƒêO√ÅN =================
if st.session_state.prediction_history:
    with st.expander("üìú L·ªãch s·ª≠ d·ª± ƒëo√°n"):
        for pred in st.session_state.prediction_history[-10:]:
            st.write(f"**{pred['time']}** - D·ª± ƒëo√°n: {pred['prediction']['main_3']} | {pred['prediction']['decision']} | ƒê·ªô tin c·∫≠y: {pred['prediction']['confidence']}%")