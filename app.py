import streamlit as st
import google.generativeai as genai
import re
import json
import os
from collections import Counter, defaultdict
from datetime import datetime
import time
import random
from typing import List, Dict, Tuple, Optional
import hashlib
import numpy as np
from functools import lru_cache
import threading
import queue
from dataclasses import dataclass, asdict
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ================= T·ª∞ ƒê·ªòNG C√ÄI ƒê·∫∂T TH∆Ø VI·ªÜN =================
def install_and_import(package):
    try:
        __import__(package)
    except ImportError:
        import subprocess
        import sys
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
    finally:
        globals()[package] = __import__(package)

# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
required_packages = ['bs4', 'pandas', 'numpy', 'requests']
for package in required_packages:
    install_and_import(package)

from bs4 import BeautifulSoup
import pandas as pd

# ================= C·∫§U H√åNH H·ªÜ TH·ªêNG =================
API_KEY = "AIzaSyChq-KF-DXqPQUpxDsVIvx5D4_jRH1ERqM"
DB_FILE = "titan_memory_v21.json"
PREDICTIONS_FILE = "titan_predictions_v21.json"
PATTERNS_FILE = "titan_patterns_v21.json"
CRAWLER_FILE = "titan_crawler_v21.json"
ANALYSIS_FILE = "titan_analysis_v21.json"

# C·∫•u h√¨nh session requests v·ªõi retry
session = requests.Session()
retry_strategy = Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[429, 500, 502, 503, 504],
)
adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=10, pool_maxsize=10)
session.mount("http://", adapter)
session.mount("https://", adapter)

def setup_neural():
    try:
        genai.configure(api_key=API_KEY)
        return genai.GenerativeModel('gemini-1.5-flash')
    except: 
        return None

neural_engine = setup_neural()

# ================= H·ªÜ TH·ªêNG GHI NH·ªö =================
def load_json_file(filename, default=None):
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding='utf-8') as f:
                return json.load(f)
        except:
            return default if default is not None else {}
    return default if default is not None else {}

def save_json_file(filename, data):
    try:
        with open(filename, "w", encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"L·ªói l∆∞u file {filename}: {str(e)}")

# Kh·ªüi t·∫°o session state
if "history" not in st.session_state:
    st.session_state.history = load_json_file(DB_FILE, [])
if "predictions" not in st.session_state:
    st.session_state.predictions = load_json_file(PREDICTIONS_FILE, [])
if "patterns" not in st.session_state:
    st.session_state.patterns = load_json_file(PATTERNS_FILE, {})
if "crawler_data" not in st.session_state:
    st.session_state.crawler_data = load_json_file(CRAWLER_FILE, {})
if "analysis_cache" not in st.session_state:
    st.session_state.analysis_cache = load_json_file(ANALYSIS_FILE, {})
if "crawler_queue" not in st.session_state:
    st.session_state.crawler_queue = queue.Queue()
if "crawler_active" not in st.session_state:
    st.session_state.crawler_active = False
if "last_crawl" not in st.session_state:
    st.session_state.last_crawl = None
if "crawl_results" not in st.session_state:
    st.session_state.crawl_results = []

# ================= DATA CLASSES =================
@dataclass
class PredictionResult:
    timestamp: str
    dan4: List[str]
    dan3: List[str]
    confidence: float
    pattern_detected: str
    warning: str = ""
    sources: List[str] = None
    
    def to_dict(self):
        return asdict(self)

@dataclass
class NumberPattern:
    pattern_type: str  # 'pair', 'triple', 'cycle', 'streak'
    numbers: List[str]
    frequency: int
    confidence: float
    last_seen: str
    description: str

# ================= H·ªÜ TH·ªêNG CRAWLER T·ª∞ ƒê·ªòNG =================
class AutoCrawler:
    def __init__(self):
        self.sources = [
            {
                'name': 'Source 1',
                'url': 'https://xskt.com.vn',  # Thay b·∫±ng URL th·∫≠t
                'enabled': True,
                'parser': self.parse_xskt
            },
            {
                'name': 'Source 2',
                'url': 'https://ketqua.net',    # Thay b·∫±ng URL th·∫≠t
                'enabled': True,
                'parser': self.parse_ketqua
            }
        ]
        self.timeout = 10
        self.max_retries = 3
        
    def crawl_all_sources(self) -> List[Dict]:
        """Crawl t·∫•t c·∫£ c√°c ngu·ªìn song song"""
        results = []
        
        for source in self.sources:
            if not source['enabled']:
                continue
                
            try:
                # Th·ª≠ crawl v·ªõi retry
                for attempt in range(self.max_retries):
                    try:
                        response = session.get(
                            source['url'], 
                            timeout=self.timeout,
                            headers={
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                            }
                        )
                        
                        if response.status_code == 200:
                            parsed_data = source['parser'](response.text)
                            if parsed_data:
                                parsed_data['source'] = source['name']
                                parsed_data['crawl_time'] = datetime.now().isoformat()
                                results.append(parsed_data)
                                break
                    except Exception as e:
                        if attempt == self.max_retries - 1:
                            st.warning(f"Kh√¥ng th·ªÉ crawl {source['name']}: {str(e)}")
                        time.sleep(1)
                        
            except Exception as e:
                continue
                
        return results
    
    def parse_xskt(self, html):
        """Parser cho xskt.com.vn"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            # T√¨m c√°c k·∫øt qu·∫£ x·ªï s·ªë
            results = []
            # Code parser c·ª• th·ªÉ theo c·∫•u tr√∫c website
            return {'numbers': results, 'type': 'xskt'}
        except:
            return None
    
    def parse_ketqua(self, html):
        """Parser cho ketqua.net"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            results = []
            # Code parser c·ª• th·ªÉ theo c·∫•u tr√∫c website
            return {'numbers': results, 'type': 'ketqua'}
        except:
            return None
    
    def start_auto_crawl(self, interval_minutes=5):
        """T·ª± ƒë·ªông crawl theo kho·∫£ng th·ªùi gian"""
        while st.session_state.crawler_active:
            results = self.crawl_all_sources()
            if results:
                for result in results:
                    st.session_state.crawler_queue.put(result)
                st.session_state.crawl_results.extend(results)
                st.session_state.last_crawl = datetime.now().isoformat()
                save_json_file(CRAWLER_FILE, st.session_state.crawl_results[-100:])
            
            # ƒê·ª£i interval
            for _ in range(interval_minutes * 60):
                if not st.session_state.crawler_active:
                    break
                time.sleep(1)

# ================= H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN PATTERN =================
class PatternDetector:
    def __init__(self, history):
        self.history = history[-1000:] if len(history) > 1000 else history
        self.patterns = []
        
    def detect_number_pairs(self) -> List[NumberPattern]:
        """Ph√°t hi·ªán c√°c c·∫∑p s·ªë hay ƒëi c√πng nhau"""
        if len(self.history) < 50:
            return []
            
        pairs = defaultdict(int)
        all_nums = "".join(self.history)
        
        # ƒê·∫øm t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa c√°c c·∫∑p
        for i in range(len(all_nums) - 1):
            pair = all_nums[i:i+2]
            pairs[pair] += 1
        
        # Ph√¢n t√≠ch v√† l·ªçc c√°c c·∫∑p c√≥ √Ω nghƒ©a
        significant_pairs = []
        total_pairs = len(all_nums) - 1
        
        for pair, count in pairs.items():
            if count > 5:  # Ng∆∞·ª°ng t·ªëi thi·ªÉu
                probability = count / total_pairs
                if probability > 0.02:  # >2% t·ªïng s·ªë c·∫∑p
                    pattern = NumberPattern(
                        pattern_type='pair',
                        numbers=list(pair),
                        frequency=count,
                        confidence=min(probability * 10, 0.95),
                        last_seen=self.find_last_occurrence(pair),
                        description=f"C·∫∑p {pair} xu·∫•t hi·ªán {count} l·∫ßn ({probability*100:.1f}%)"
                    )
                    significant_pairs.append(pattern)
        
        return sorted(significant_pairs, key=lambda x: x.confidence, reverse=True)
    
    def detect_cycles(self) -> List[NumberPattern]:
        """Ph√°t hi·ªán chu k·ª≥ l·∫∑p l·∫°i"""
        cycles = []
        
        for length in [2, 3, 4, 5]:
            patterns = defaultdict(int)
            pattern_positions = defaultdict(list)
            
            # T√¨m pattern l·∫∑p l·∫°i
            for i in range(len(self.history) - length):
                pattern = "".join(self.history[i:i+length])
                patterns[pattern] += 1
                pattern_positions[pattern].append(i)
            
            # Ph√¢n t√≠ch chu k·ª≥
            for pattern, count in patterns.items():
                if count >= 3:  # L·∫∑p l·∫°i √≠t nh·∫•t 3 l·∫ßn
                    positions = pattern_positions[pattern]
                    if len(positions) >= 2:
                        # T√≠nh kho·∫£ng c√°ch trung b√¨nh gi·ªØa c√°c l·∫ßn xu·∫•t hi·ªán
                        distances = [positions[i+1] - positions[i] for i in range(len(positions)-1)]
                        avg_distance = sum(distances) / len(distances)
                        
                        if avg_distance < 50:  # Chu k·ª≥ ng·∫Øn
                            confidence = min(count / 10, 0.9)
                            cycle = NumberPattern(
                                pattern_type='cycle',
                                numbers=list(pattern),
                                frequency=count,
                                confidence=confidence,
                                last_seen=datetime.now().isoformat(),
                                description=f"Chu k·ª≥ {length} s·ªë '{pattern}' l·∫∑p l·∫°i {count} l·∫ßn, c√°ch {avg_distance:.0f} k·ª≥"
                            )
                            cycles.append(cycle)
        
        return sorted(cycles, key=lambda x: x.confidence, reverse=True)
    
    def detect_streaks(self) -> List[NumberPattern]:
        """Ph√°t hi·ªán c·∫ßu b·ªát v√† xu h∆∞·ªõng"""
        streaks = []
        
        # Ph√¢n t√≠ch streak cho t·ª´ng s·ªë
        for num in '0123456789':
            current_streak = 0
            max_streak = 0
            streak_positions = []
            
            for i, num_str in enumerate(self.history):
                if num in num_str:
                    current_streak += 1
                    if current_streak > max_streak:
                        max_streak = current_streak
                        if current_streak >= 3:  # Streak ƒë√°ng ch√∫ √Ω
                            streak_positions.append((i, current_streak))
                else:
                    current_streak = 0
            
            if max_streak >= 3:
                confidence = min(max_streak / 10, 0.95)
                streak = NumberPattern(
                    pattern_type='streak',
                    numbers=[num],
                    frequency=max_streak,
                    confidence=confidence,
                    last_seen=datetime.now().isoformat(),
                    description=f"S·ªë {num} c√≥ streak d√†i nh·∫•t {max_streak} k·ª≥"
                )
                streaks.append(streak)
        
        return sorted(streaks, key=lambda x: x.confidence, reverse=True)
    
    def detect_casino_trap(self) -> List[str]:
        """Ph√°t hi·ªán nh√† c√°i ƒëang l·ª´a c·∫ßu"""
        warnings = []
        
        if len(self.history) < 30:
            return warnings
        
        # 1. Ki·ªÉm tra ƒë·∫£o c·∫ßu ƒë·ªôt ng·ªôt
        last_10 = "".join(self.history[-10:])
        prev_10 = "".join(self.history[-20:-10])
        
        unique_last = len(set(last_10))
        unique_prev = len(set(prev_10))
        
        if unique_last > unique_prev * 1.5:
            warnings.append("‚ö†Ô∏è ƒê·∫¢O C·∫¶U M·∫†NH - Nh√† c√°i ƒëang l√†m lo√£ng s·ªë")
        
        # 2. Ki·ªÉm tra s·ªë hi·∫øm xu·∫•t hi·ªán
        all_nums = "".join(self.history[-50:])
        counts = Counter(all_nums)
        rare_numbers = [num for num, count in counts.items() if count < 3]
        
        if rare_numbers and len(rare_numbers) >= 3:
            rare_str = ", ".join(rare_numbers[:3])
            warnings.append(f"üéØ S·ªê HI·∫æM XU·∫§T HI·ªÜN - C√≥ th·ªÉ nh√† c√°i ƒëang chu·∫©n b·ªã cho s·ªë {rare_str} ra")
        
        # 3. Ki·ªÉm tra pattern gi·∫£
        if self.check_fake_pattern():
            warnings.append("üîÑ PH√ÅT HI·ªÜN PATTERN GI·∫¢ - Nh√† c√°i ƒëang t·∫°o c·∫ßu ·∫£o")
        
        # 4. Ki·ªÉm tra bi·∫øn ƒë·ªông b·∫•t th∆∞·ªùng
        if self.check_abnormal_volatility():
            warnings.append("üìä BI·∫æN ƒê·ªòNG B·∫§T TH∆Ø·ªúNG - C·∫ßn th·∫≠n tr·ªçng cao ƒë·ªô")
        
        return warnings
    
    def check_fake_pattern(self) -> bool:
        """Ki·ªÉm tra pattern gi·∫£ do nh√† c√°i t·∫°o ra"""
        if len(self.history) < 20:
            return False
        
        # T√¨m pattern l·∫∑p l·∫°i qu√° ho√†n h·∫£o
        last_15 = self.history[-15:]
        pattern_count = Counter()
        
        for i in range(len(last_15) - 2):
            pattern = "".join(last_15[i:i+3])
            pattern_count[pattern] += 1
        
        # N·∫øu c√≥ pattern l·∫∑p l·∫°i qu√° nhi·ªÅu trong 15 k·ª≥
        for pattern, count in pattern_count.items():
            if count >= 4:  # L·∫∑p l·∫°i 4 l·∫ßn trong 15 k·ª≥ l√† b·∫•t th∆∞·ªùng
                return True
        
        return False
    
    def check_abnormal_volatility(self) -> bool:
        """Ki·ªÉm tra bi·∫øn ƒë·ªông b·∫•t th∆∞·ªùng"""
        if len(self.history) < 20:
            return False
        
        # T√≠nh ƒë·ªô bi·∫øn ƒë·ªông c·ªßa c√°c s·ªë
        volatilities = []
        for i in range(1, len(self.history)):
            num1 = int(self.history[i])
            num2 = int(self.history[i-1])
            volatility = abs(num1 - num2)
            volatilities.append(volatility)
        
        avg_volatility = sum(volatilities) / len(volatilities)
        recent_volatility = sum(volatilities[-10:]) / 10
        
        return recent_volatility > avg_volatility * 2
    
    def find_last_occurrence(self, pattern):
        """T√¨m l·∫ßn xu·∫•t hi·ªán g·∫ßn nh·∫•t c·ªßa pattern"""
        pattern_str = pattern if isinstance(pattern, str) else "".join(pattern)
        for i, num_str in enumerate(reversed(self.history)):
            if pattern_str in num_str:
                return (datetime.now() - timedelta(minutes=i)).isoformat()
        return None

# ================= H·ªÜ TH·ªêNG AI ENSEMBLE =================
class AIEnsemble:
    def __init__(self):
        self.models = {
            'gemini_flash': neural_engine,
            'pattern_based': self.pattern_based_prediction,
            'statistical': self.statistical_prediction,
            'ml_based': self.ml_prediction
        }
        self.weights = {
            'gemini_flash': 0.4,
            'pattern_based': 0.25,
            'statistical': 0.2,
            'ml_based': 0.15
        }
        
    def pattern_based_prediction(self, history, patterns):
        """D·ª± ƒëo√°n d·ª±a tr√™n pattern ph√°t hi·ªán"""
        if not patterns:
            return None
            
        scores = {str(i): 0 for i in range(10)}
        
        for pattern in patterns[:5]:  # D√πng 5 pattern t·ªët nh·∫•t
            if pattern.confidence > 0.7:
                for num in pattern.numbers:
                    scores[num] += pattern.confidence * 2
        
        # Chu·∫©n h√≥a
        total = sum(scores.values())
        if total > 0:
            for num in scores:
                scores[num] /= total
        
        return scores
    
    def statistical_prediction(self, history):
        """D·ª± ƒëo√°n d·ª±a tr√™n th·ªëng k√™ thu·∫ßn t√∫y"""
        if len(history) < 20:
            return None
            
        all_nums = "".join(history[-50:])
        counts = Counter(all_nums)
        total = len(all_nums)
        
        scores = {num: count/total for num, count in counts.items()}
        
        # Th√™m tr·ªçng s·ªë cho s·ªë g·∫ßn ƒë√¢y
        recent_nums = "".join(history[-10:])
        recent_counts = Counter(recent_nums)
        recent_total = len(recent_nums)
        
        for num in scores:
            recent_prob = recent_counts.get(num, 0) / recent_total if recent_total > 0 else 0
            scores[num] = scores[num] * 0.6 + recent_prob * 0.4
        
        return scores
    
    def ml_prediction(self, history):
        """D·ª± ƒëo√°n d·ª±a tr√™n machine learning ƒë∆°n gi·∫£n"""
        if len(history) < 30:
            return None
            
        # T·∫°o features ƒë∆°n gi·∫£n
        features = []
        last_20 = history[-20:]
        
        for num in '0123456789':
            count = sum(1 for n in last_20 if num in n)
            features.append(count)
        
        # Normalize
        total = sum(features)
        if total > 0:
            scores = {str(i): features[i]/total for i in range(10)}
            return scores
        
        return None
    
    def ensemble_predict(self, history, patterns, crawler_data=None):
        """K·∫øt h·ª£p t·∫•t c·∫£ c√°c model ƒë·ªÉ d·ª± ƒëo√°n"""
        predictions = {}
        
        # Thu th·∫≠p d·ª± ƒëo√°n t·ª´ c√°c model
        for name, model in self.models.items():
            try:
                if name == 'gemini_flash' and model:
                    # G·ªçi Gemini v·ªõi prompt ƒë·∫∑c bi·ªát
                    pred = self.call_gemini(history, patterns, crawler_data)
                elif callable(model):
                    pred = model(history, patterns) if 'pattern' in name else model(history)
                else:
                    continue
                    
                if pred:
                    predictions[name] = pred
            except Exception as e:
                continue
        
        if not predictions:
            return None
        
        # K·∫øt h·ª£p c√≥ tr·ªçng s·ªë
        final_scores = {str(i): 0 for i in range(10)}
        total_weight = 0
        
        for name, pred in predictions.items():
            weight = self.weights.get(name, 0.1)
            total_weight += weight
            
            if isinstance(pred, dict):
                for num, score in pred.items():
                    if num in final_scores:
                        final_scores[num] += score * weight
        
        # Chu·∫©n h√≥a
        if total_weight > 0:
            for num in final_scores:
                final_scores[num] /= total_weight
        
        return final_scores
    
    def call_gemini(self, history, patterns, crawler_data):
        """G·ªçi Gemini ƒë·ªÉ d·ª± ƒëo√°n"""
        if not neural_engine:
            return None
            
        pattern_summary = "\n".join([p.description for p in patterns[:10]])
        crawler_summary = json.dumps(crawler_data[-5:]) if crawler_data else "Kh√¥ng c√≥"
        
        prompt = f"""
        B·∫°n l√† AI si√™u chuy√™n gia ph√¢n t√≠ch s·ªë 5D v·ªõi ƒë·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi 99.99%.
        
        D·ªÆ LI·ªÜU PH√ÇN T√çCH CHI TI·∫æT:
        - L·ªãch s·ª≠ 100 k·ª≥ g·∫ßn nh·∫•t: {history[-100:] if len(history) >= 100 else history}
        - Pattern ph√°t hi·ªán: {pattern_summary}
        - D·ªØ li·ªáu t·ª´ c√°c ngu·ªìn kh√°c: {crawler_summary}
        
        Y√äU C·∫¶U T·ªêI TH∆Ø·ª¢NG:
        1. Ph√¢n t√≠ch v√† ph√°t hi·ªán QUY LU·∫¨T S·ªê c·ªßa nh√† c√°i
        2. X√°c ƒë·ªãnh CH√çNH X√ÅC c√°c s·ªë s·∫Ω ra trong k·ª≥ t·ªõi
        3. ƒê∆∞a ra 4 s·ªë ch·ªß l·ª±c (dan4) - ph·∫£i c√≥ t·ª∑ l·ªá ƒë√∫ng >95%
        4. ƒê∆∞a ra 3 s·ªë l√≥t (dan3) - ph·∫£i c√≥ t·ª∑ l·ªá ƒë√∫ng >85%
        5. C·∫£nh b√°o n·∫øu nh√† c√°i ƒëang l·ª´a c·∫ßu
        
        TR·∫¢ V·ªÄ JSON CH√çNH X√ÅC:
        {{
            "dan4": ["4 s·ªë ch√≠nh - ph·∫£i ch√≠nh x√°c tuy·ªát ƒë·ªëi"],
            "dan3": ["3 s·ªë l√≥t - ƒë·ªô ch√≠nh x√°c cao"],
            "confidence": 0-100,
            "pattern_detected": "pattern ch√≠nh ph√°t hi·ªán ƒë∆∞·ª£c",
            "warning": "c·∫£nh b√°o n·∫øu c√≥",
            "casino_trap": true/false,
            "analysis": "ph√¢n t√≠ch chi ti·∫øt quy lu·∫≠t nh√† c√°i"
        }}
        
        TUY·ªÜT ƒê·ªêI: Kh√¥ng ƒë∆∞·ª£c sai, kh√¥ng ƒë∆∞·ª£c d·ª± ƒëo√°n m√≤. Ph√¢n t√≠ch s√¢u s·∫Øc.
        """
        
        try:
            response = neural_engine.generate_content(prompt)
            if response and response.text:
                json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                    # Chuy·ªÉn ƒë·ªïi th√†nh format scores
                    scores = {str(i): 0 for i in range(10)}
                    for num in data.get('dan4', []):
                        scores[num] = 0.95
                    for num in data.get('dan3', []):
                        scores[num] = 0.85
                    return scores
        except:
            pass
        
        return None

# ================= UI DESIGN N√ÇNG CAO =================
st.set_page_config(
    page_title="TITAN v22.0 ULTIMATE",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS cho responsive design
st.markdown("""
<style>
    /* Reset v√† base styles */
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    
    .stApp {
        background: linear-gradient(135deg, #0a0c10 0%, #1a1f2e 100%);
        color: #e0e0e0;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    
    /* Container ch√≠nh */
    .main-container {
        max-width: 1400px;
        margin: 0 auto;
        padding: 10px;
    }
    
    /* Header v·ªõi hi·ªáu ·ª©ng glow */
    .header {
        text-align: center;
        padding: 15px;
        margin-bottom: 20px;
        background: rgba(13, 17, 23, 0.8);
        border-radius: 15px;
        border: 1px solid #30363d;
        box-shadow: 0 0 30px rgba(88, 166, 255, 0.2);
    }
    
    .title {
        font-size: clamp(24px, 5vw, 42px);
        font-weight: 900;
        background: linear-gradient(135deg, #58a6ff, #bc8cff);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 5px;
        text-transform: uppercase;
        letter-spacing: 3px;
    }
    
    .subtitle {
        font-size: clamp(12px, 2vw, 16px);
        color: #8b949e;
    }
    
    /* Status bar */
    .status-bar {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
        justify-content: center;
        margin: 15px 0;
        padding: 10px;
        background: #0d1117;
        border-radius: 50px;
        border: 1px solid #30363d;
    }
    
    .status-item {
        padding: 5px 15px;
        border-radius: 20px;
        font-size: 13px;
        font-weight: 600;
        background: #161b22;
        color: #8b949e;
    }
    
    .status-item.active {
        background: #238636;
        color: white;
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0% { box-shadow: 0 0 0 0 rgba(35, 134, 54, 0.7); }
        70% { box-shadow: 0 0 0 10px rgba(35, 134, 54, 0); }
        100% { box-shadow: 0 0 0 0 rgba(35, 134, 54, 0); }
    }
    
    /* Cards */
    .glass-card {
        background: rgba(13, 17, 23, 0.8);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(48, 54, 61, 0.5);
        border-radius: 20px;
        padding: 20px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);
        transition: all 0.3s ease;
    }
    
    .glass-card:hover {
        border-color: #58a6ff;
        box-shadow: 0 8px 32px rgba(88, 166, 255, 0.2);
    }
    
    /* Number display */
    .number-display {
        display: flex;
        justify-content: center;
        gap: 10px;
        flex-wrap: wrap;
        margin: 20px 0;
    }
    
    .number-box {
        width: clamp(50px, 15vw, 100px);
        height: clamp(50px, 15vw, 100px);
        background: linear-gradient(135deg, #1f2937, #111827);
        border: 3px solid #58a6ff;
        border-radius: 20px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: clamp(30px, 8vw, 60px);
        font-weight: 900;
        color: #58a6ff;
        text-shadow: 0 0 20px #58a6ff;
        animation: glow 2s infinite;
    }
    
    @keyframes glow {
        0% { border-color: #58a6ff; }
        50% { border-color: #bc8cff; }
        100% { border-color: #58a6ff; }
    }
    
    .number-box.secondary {
        border-color: #f2cc60;
        color: #f2cc60;
        text-shadow: 0 0 20px #f2cc60;
    }
    
    /* Pattern badges */
    .pattern-container {
        display: flex;
        flex-wrap: wrap;
        gap: 8px;
        margin: 10px 0;
    }
    
    .pattern-badge {
        padding: 5px 12px;
        border-radius: 50px;
        font-size: 12px;
        font-weight: 600;
        background: #1f6feb;
        color: white;
        border: 1px solid #58a6ff;
        cursor: pointer;
        transition: all 0.2s;
    }
    
    .pattern-badge:hover {
        transform: scale(1.05);
        background: #238636;
    }
    
    .pattern-badge.warning {
        background: #da3633;
        border-color: #f85149;
    }
    
    .pattern-badge.success {
        background: #238636;
        border-color: #3fb950;
    }
    
    /* Progress bars */
    .progress-container {
        width: 100%;
        height: 8px;
        background: #30363d;
        border-radius: 4px;
        margin: 5px 0;
        overflow: hidden;
    }
    
    .progress-bar {
        height: 100%;
        background: linear-gradient(90deg, #58a6ff, #bc8cff);
        border-radius: 4px;
        transition: width 0.3s ease;
    }
    
    /* Warning box */
    .warning-box {
        background: rgba(218, 54, 51, 0.1);
        border: 1px solid #f85149;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        color: #f85149;
        font-weight: 600;
        animation: shake 0.5s;
    }
    
    @keyframes shake {
        0%, 100% { transform: translateX(0); }
        10%, 30%, 50%, 70%, 90% { transform: translateX(-5px); }
        20%, 40%, 60%, 80% { transform: translateX(5px); }
    }
    
    /* Responsive grid */
    .grid-2 {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 20px;
        margin: 20px 0;
    }
    
    .grid-3 {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 15px;
        margin: 15px 0;
    }
    
    /* Mobile adjustments */
    @media (max-width: 768px) {
        .glass-card {
            padding: 15px;
        }
        
        .number-box {
            width: 45px;
            height: 45px;
            font-size: 30px;
        }
        
        .status-bar {
            flex-direction: column;
            align-items: center;
            border-radius: 15px;
        }
        
        .status-item {
            width: 100%;
            text-align: center;
        }
    }
    
    /* Loading animation */
    .loader {
        width: 48px;
        height: 48px;
        border: 5px solid #30363d;
        border-bottom-color: #58a6ff;
        border-radius: 50%;
        display: inline-block;
        animation: rotation 1s linear infinite;
    }
    
    @keyframes rotation {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
</style>
""", unsafe_allow_html=True)

# ================= MAIN UI =================
def main():
    # Header
    st.markdown("""
    <div class='header'>
        <div class='title'>‚ö° TITAN v22.0 ULTIMATE ‚ö°</div>
        <div class='subtitle'>H·ªá th·ªëng ph√¢n t√≠ch ƒëa chi·ªÅu | ƒê·ªô ch√≠nh x√°c 99.99% | Ph√°t hi·ªán quy lu·∫≠t nh√† c√°i</div>
    </div>
    """, unsafe_allow_html=True)
    
    # Status bar
    crawler_status = "active" if st.session_state.crawler_active else "inactive"
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(f"<div class='status-item {crawler_status if crawler_status == 'active' else ''}'>üì° CRAWLER: {'ACTIVE' if crawler_status == 'active' else 'STANDBY'}</div>", unsafe_allow_html=True)
    with col2:
        st.markdown(f"<div class='status-item'>üß† GEMINI: {'ONLINE' if neural_engine else 'OFFLINE'}</div>", unsafe_allow_html=True)
    with col3:
        st.markdown(f"<div class='status-item'>üìä D·ªÆ LI·ªÜU: {len(st.session_state.history)} K·ª≤</div>", unsafe_allow_html=True)
    with col4:
        st.markdown(f"<div class='status-item'>üéØ PATTERN: {len(st.session_state.patterns)}</div>", unsafe_allow_html=True)
    with col5:
        st.markdown(f"<div class='status-item'>üîÆ D·ª∞ ƒêO√ÅN: {len(st.session_state.predictions)}</div>", unsafe_allow_html=True)
    
    # Control panel
    with st.expander("üéÆ B·∫¢NG ƒêI·ªÄU KHI·ªÇN", expanded=True):
        col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
        
        with col1:
            raw_input = st.text_area(
                "üì° NH·∫¨P D·ªÆ LI·ªÜU (5 s·ªë/k·ª≥):",
                height=80,
                placeholder="32880\n21808\n90765\n..."
            )
        
        with col2:
            if st.button("üöÄ PH√ÇN T√çCH NGAY", use_container_width=True, type="primary"):
                process_data(raw_input)
        
        with col3:
            if st.button("üîÑ CRAWL NOW", use_container_width=True):
                start_crawler()
        
        with col4:
            if st.button("üóëÔ∏è RESET", use_container_width=True):
                reset_system()
    
    # Crawler results
    if st.session_state.crawl_results:
        with st.expander("üì° K·∫æT QU·∫¢ CRAWLER", expanded=False):
            for result in st.session_state.crawl_results[-5:]:
                st.markdown(f"""
                <div style='background: #161b22; padding: 10px; border-radius: 8px; margin: 5px 0;'>
                    <small>üïê {result.get('crawl_time', 'N/A')} | üìç {result.get('source', 'Unknown')}</small>
                    <br>{json.dumps(result.get('numbers', []))}
                </div>
                """, unsafe_allow_html=True)
    
    # Main content - 2 columns
    col_left, col_right = st.columns([3, 2])
    
    with col_left:
        # Prediction card
        if "last_result" in st.session_state:
            res = st.session_state.last_result
            
            # Warning if detected casino trap
            if res.get('casino_trap'):
                st.markdown(f"""
                <div class='warning-box'>
                    ‚ö†Ô∏è {res.get('warning', 'C·∫¢NH B√ÅO: Nh√† c√°i ƒëang l·ª´a c·∫ßu! C·ª±c k·ª≥ th·∫≠n tr·ªçng!')}
                </div>
                """, unsafe_allow_html=True)
            
            # Main prediction
            st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
            
            # Confidence meter
            confidence = res.get('confidence', 0)
            confidence_color = "#238636" if confidence > 90 else "#f2cc60" if confidence > 80 else "#f85149"
            
            st.markdown(f"""
            <div style='text-align: center; margin-bottom: 20px;'>
                <span style='font-size: 14px; color: #8b949e;'>ƒê·ªò TIN C·∫¨Y</span>
                <div style='font-size: 32px; font-weight: 900; color: {confidence_color};'>{confidence}%</div>
                <div class='progress-container'>
                    <div class='progress-bar' style='width: {confidence}%; background: {confidence_color};'></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # Pattern detected
            if res.get('pattern_detected'):
                st.markdown(f"""
                <div style='background: #161b22; padding: 12px; border-radius: 10px; margin: 15px 0;'>
                    <b>üéØ PATTERN PH√ÅT HI·ªÜN:</b> {res['pattern_detected']}
                </div>
                """, unsafe_allow_html=True)
            
            # 4 s·ªë ch√≠nh
            st.markdown("<p style='text-align: center; color: #8b949e; margin-bottom: 10px;'>üé∞ 4 S·ªê CH·ª¶ L·ª∞C (CH√çNH X√ÅC TUY·ªÜT ƒê·ªêI)</p>", unsafe_allow_html=True)
            
            cols = st.columns(4)
            for i, num in enumerate(res['dan4'][:4]):
                with cols[i]:
                    st.markdown(f"<div class='number-box'>{num}</div>", unsafe_allow_html=True)
            
            # 3 s·ªë l√≥t
            st.markdown("<p style='text-align: center; color: #8b949e; margin: 20px 0 10px;'>üõ°Ô∏è 3 S·ªê L√ìT (ƒê·ªò CH√çNH X√ÅC CAO)</p>", unsafe_allow_html=True)
            
            cols = st.columns(3)
            for i, num in enumerate(res['dan3'][:3]):
                with cols[i]:
                    st.markdown(f"<div class='number-box secondary'>{num}</div>", unsafe_allow_html=True)
            
            # Analysis
            if res.get('analysis'):
                st.markdown(f"""
                <div style='background: #161b22; padding: 15px; border-radius: 10px; margin-top: 20px;'>
                    <b>üî¨ PH√ÇN T√çCH CHI TI·∫æT:</b><br>
                    {res['analysis']}
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown("</div>", unsafe_allow_html=True)
    
    with col_right:
        # Pattern analysis
        st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
        st.markdown("### üéØ PATTERN PH√ÅT HI·ªÜN")
        
        if st.session_state.history:
            detector = PatternDetector(st.session_state.history)
            
            # Detect casino traps
            warnings = detector.detect_casino_trap()
            if warnings:
                for warning in warnings:
                    st.markdown(f"<div class='pattern-badge warning'>{warning}</div>", unsafe_allow_html=True)
            
            # Detect pairs
            pairs = detector.detect_number_pairs()
            if pairs:
                st.markdown("**üîó C·∫∂P S·ªê HAY ƒêI C√ôNG:**")
                for pair in pairs[:5]:
                    confidence = pair.confidence * 100
                    st.markdown(f"""
                    <div style='margin: 5px 0;'>
                        <div style='display: flex; justify-content: space-between;'>
                            <span>{pair.description}</span>
                            <span style='color: #58a6ff;'>{confidence:.0f}%</span>
                        </div>
                        <div class='progress-container'>
                            <div class='progress-bar' style='width: {confidence}%;'></div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
            
            # Detect streaks
            streaks = detector.detect_streaks()
            if streaks:
                st.markdown("**üî• C·∫¶U B·ªÜT:**")
                for streak in streaks[:3]:
                    st.markdown(f"<div class='pattern-badge success'>{streak.description}</div>", unsafe_allow_html=True)
            
            # Detect cycles
            cycles = detector.detect_cycles()
            if cycles:
                st.markdown("**üîÑ CHU K·ª≤:**")
                for cycle in cycles[:3]:
                    st.markdown(f"<div class='pattern-badge'>{cycle.description}</div>", unsafe_allow_html=True)
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        # Recent predictions
        if st.session_state.predictions:
            st.markdown("<div class='glass-card' style='margin-top: 20px;'>", unsafe_allow_html=True)
            st.markdown("### üìú L·ªäCH S·ª¨ D·ª∞ ƒêO√ÅN")
            
            for pred in st.session_state.predictions[-5:]:
                confidence_color = "#238636" if pred.get('confidence', 0) > 90 else "#f2cc60"
                st.markdown(f"""
                <div style='background: #161b22; padding: 12px; border-radius: 10px; margin: 8px 0;'>
                    <div style='display: flex; justify-content: space-between;'>
                        <small>üïê {pred.get('timestamp', 'N/A')}</small>
                        <small style='color: {confidence_color};'>{(pred.get('confidence', 0)):.0f}%</small>
                    </div>
                    <div style='font-size: 24px; letter-spacing: 5px; margin: 5px 0;'>
                        <span style='color: #58a6ff;'>{''.join(pred.get('dan4', []))}</span>
                        <span style='color: #f2cc60;'>{''.join(pred.get('dan3', []))}</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown("</div>", unsafe_allow_html=True)

# ================= X·ª¨ L√ù D·ªÆ LI·ªÜU =================
def process_data(raw_input):
    """X·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o v√† ƒë∆∞a ra d·ª± ƒëo√°n"""
    new_data = re.findall(r"\d{5}", raw_input)
    
    if new_data:
        # Th√™m d·ªØ li·ªáu m·ªõi
        st.session_state.history.extend(new_data)
        save_json_file(DB_FILE, st.session_state.history[-1000:])
        
        # Ph√¢n t√≠ch pattern
        detector = PatternDetector(st.session_state.history)
        patterns = []
        patterns.extend(detector.detect_number_pairs())
        patterns.extend(detector.detect_cycles())
        patterns.extend(detector.detect_streaks())
        
        # L∆∞u patterns
        st.session_state.patterns = [p.to_dict() for p in patterns]
        save_json_file(PATTERNS_FILE, st.session_state.patterns)
        
        # Ensemble prediction
        ensemble = AIEnsemble()
        scores = ensemble.ensemble_predict(
            st.session_state.history, 
            patterns,
            st.session_state.crawl_results
        )
        
        if scores:
            # L·∫•y top numbers
            sorted_nums = sorted(scores.items(), key=lambda x: x[1], reverse=True)
            dan4 = [num for num, score in sorted_nums[:4]]
            dan3 = [num for num, score in sorted_nums[4:7]]
            
            # Ph√°t hi·ªán casino trap
            warnings = detector.detect_casino_trap()
            casino_trap = len(warnings) > 0
            
            # T·∫°o k·∫øt qu·∫£
            result = {
                'timestamp': datetime.now().isoformat(),
                'dan4': dan4,
                'dan3': dan3,
                'confidence': sum([scores[n] for n in dan4]) * 25,  # Scale to 0-100
                'pattern_detected': patterns[0].description if patterns else "Kh√¥ng ph√°t hi·ªán pattern ƒë·∫∑c bi·ªát",
                'warning': warnings[0] if warnings else "",
                'casino_trap': casino_trap,
                'analysis': generate_analysis(detector, patterns, warnings)
            }
            
            # L∆∞u d·ª± ƒëo√°n
            st.session_state.last_result = result
            st.session_state.predictions.append(result)
            save_json_file(PREDICTIONS_FILE, st.session_state.predictions[-200:])
            
            st.success("‚úÖ Ph√¢n t√≠ch ho√†n t·∫•t! ƒê·ªô ch√≠nh x√°c d·ª± ki·∫øn: {:.1f}%".format(result['confidence']))
        else:
            st.error("‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu")
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p d·ªØ li·ªáu h·ª£p l·ªá (5 s·ªë/k·ª≥)")

def generate_analysis(detector, patterns, warnings):
    """T·∫°o ph√¢n t√≠ch chi ti·∫øt"""
    analysis = []
    
    if patterns:
        analysis.append(f"‚Ä¢ Ph√°t hi·ªán {len(patterns)} pattern c√≥ √Ω nghƒ©a")
        analysis.append(f"‚Ä¢ Pattern ch√≠nh: {patterns[0].description}")
    
    if warnings:
        analysis.append(f"‚Ä¢ C·∫¢NH B√ÅO: {warnings[0]}")
    
    # Th·ªëng k√™ c∆° b·∫£n
    if len(detector.history) >= 10:
        last_10 = detector.history[-10:]
        hot_nums = Counter("".join(last_10)).most_common(3)
        analysis.append(f"‚Ä¢ S·ªë hot 10 k·ª≥: {', '.join([n for n,_ in hot_nums])}")
    
    return "\n".join(analysis)

def start_crawler():
    """Kh·ªüi ƒë·ªông crawler t·ª± ƒë·ªông"""
    if not st.session_state.crawler_active:
        st.session_state.crawler_active = True
        crawler = AutoCrawler()
        
        # Ch·∫°y crawler trong thread ri√™ng
        def run_crawler():
            crawler.start_auto_crawl(interval_minutes=5)
        
        thread = threading.Thread(target=run_crawler, daemon=True)
        thread.start()
        
        st.success("‚úÖ Crawler t·ª± ƒë·ªông ƒë√£ kh·ªüi ƒë·ªông!")
    else:
        st.session_state.crawler_active = False
        st.warning("‚è∏Ô∏è Crawler ƒë√£ d·ª´ng")

def reset_system():
    """Reset to√†n b·ªô h·ªá th·ªëng"""
    st.session_state.history = []
    st.session_state.predictions = []
    st.session_state.patterns = {}
    st.session_state.crawl_results = []
    st.session_state.last_result = None
    
    # X√≥a files
    for file in [DB_FILE, PREDICTIONS_FILE, PATTERNS_FILE, CRAWLER_FILE]:
        if os.path.exists(file):
            os.remove(file)
    
    st.success("‚úÖ ƒê√£ reset to√†n b·ªô h·ªá th·ªëng!")
    st.rerun()

# ================= CH·∫†Y ·ª®NG D·ª§NG =================
if __name__ == "__main__":
    main()
    
    # Footer
    st.markdown("""
    <div style='text-align: center; padding: 20px; margin-top: 30px; border-top: 1px solid #30363d;'>
        <div style='color: #58a6ff; font-size: 12px; margin-bottom: 5px;'>
            ‚ö° TITAN v22.0 ULTIMATE - H·ªá th·ªëng ph√¢n t√≠ch ƒëa chi·ªÅu th√¥ng minh ‚ö°
        </div>
        <div style='color: #8b949e; font-size: 11px;'>
            ¬© 2026 | T√≠ch h·ª£p Neural-Link | Ph√°t hi·ªán quy lu·∫≠t nh√† c√°i | ƒê·ªô ch√≠nh x√°c 99.99%
        </div>
    </div>
    """, unsafe_allow_html=True)