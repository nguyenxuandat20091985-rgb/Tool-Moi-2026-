import streamlit as st
import google.generativeai as genai
import re
import json
import os
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
import time

# ================= C·∫§U H√åNH H·ªÜ TH·ªêNG TITAN v25.0 QUANTUM =================
# L∆∞u √Ω: API Key n√™n ƒë∆∞·ª£c ƒë·∫∑t trong bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c Secrets c·ªßa Streamlit ƒë·ªÉ b·∫£o m·∫≠t
API_KEY = "AIzaSyB5PRp04XlMHKl3oGfCRbsKXjlTA-CZifc" 
DB_FILE = "titan_quantum_v25.json"

# C·∫•u h√¨nh Gemini
def setup_neural():
    try:
        genai.configure(api_key=API_KEY)
        return genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi Neural Engine: {e}")
        return None

neural_engine = setup_neural()

# ================= THU·∫¨T TO√ÅN X·ª¨ L√ù D·ªÆ LI·ªÜU N√ÇNG CAO =================

class QuantumAnalyzer:
    def __init__(self, history):
        self.history = history
        self.digits_history = []
        self._preprocess()

    def _preprocess(self):
        """T√°ch chu·ªói 5 s·ªë th√†nh t·ª´ng digit ri√™ng l·∫ª ƒë·ªÉ ph√¢n t√≠ch s√¢u"""
        for num in self.history:
            if len(num) == 5:
                self.digits_history.extend([int(d) for d in num])

    def get_frequency_analysis(self, limit=100):
        """Ph√¢n t√≠ch t·∫ßn su·∫•t xu·∫•t hi·ªán trong N k·ª≥ g·∫ßn nh·∫•t"""
        recent_data = "".join(self.history[-limit:])
        counts = Counter(recent_data)
        total = sum(counts.values())
        return {k: round(v/total * 100, 2) for k, v in counts.items()}

    def get_gap_analysis(self):
        """Ph√¢n t√≠ch kho·∫£ng c√°ch (Gap) - S·ªë n√†o l√¢u ch∆∞a v·ªÅ"""
        last_indices = {}
        for i, num in enumerate(self.history):
            for d in num:
                last_indices[d] = i
        
        current_idx = len(self.history)
        gaps = {d: current_idx - idx for d, idx in last_indices.items()}
        # Sort by gap descending (s·ªë l√¢u ch∆∞a v·ªÅ nh·∫•t)
        return sorted(gaps.items(), key=lambda x: x[1], reverse=True)

    def get_markov_transition(self):
        """X√°c su·∫•t chuy·ªÉn tr·∫°ng th√°i (N·∫øu h√¥m nay ra s·ªë X, ng√†y mai th∆∞·ªùng ra s·ªë Y)"""
        transitions = defaultdict(Counter)
        full_str = "".join(self.history)
        
        for i in range(len(full_str) - 1):
            curr = full_str[i]
            next_d = full_str[i+1]
            transitions[curr][next_d] += 1
            
        probs = {}
        for k, v in transitions.items():
            total = sum(v.values())
            probs[k] = {nk: round(nv/total, 2) for nk, nv in v.most_common(3)}
        return probs

    def calculate_weighted_score(self):
        """Thu·∫≠t to√°n ch·∫•m ƒëi·ªÉm t·ªïng h·ª£p: T·∫ßn su·∫•t + ƒê·ªô n√≥ng + Gap"""
        freq = self.get_frequency_analysis(200)
        gaps = dict(self.get_gap_analysis())
        
        scores = {}
        for d in "0123456789":
            f_score = freq.get(d, 0) * 1.5  # Tr·ªçng s·ªë t·∫ßn su·∫•t
            g_score = min(gaps.get(d, 0), 20) * 2 # Tr·ªçng s·ªë gap (max 20 k·ª≥)
            scores[d] = f_score + g_score
            
        return sorted(scores.items(), key=lambda x: x[1], reverse=True)

# ================= QU·∫¢N L√ù D·ªÆ LI·ªÜU =================

def load_db():
    if os.path.exists(DB_FILE):
        with open(DB_FILE, "r", encoding="utf-8") as f:
            try: 
                data = json.load(f)
                return data if isinstance(data, list) else []
            except: return []
    return []

def save_db(data):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(data[-5000:], f)

if "history" not in st.session_state:
    st.session_state.history = load_db()

# ================= GIAO DI·ªÜN TITAN v25.0 =================

st.set_page_config(page_title="TITAN v25.0 QUANTUM", layout="wide", page_icon="üîÆ")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap');
    
    body { font-family: 'JetBrains Mono', monospace; }
    .stApp { background: #050505; color: #c9d1d9; }
    
    .main-card {
        background: linear-gradient(145deg, #0d1117, #161b22);
        border: 1px solid #30363d;
        border-radius: 16px;
        padding: 30px;
        box-shadow: 0 0 30px rgba(88, 166, 255, 0.1);
        margin-bottom: 20px;
    }
    
    .digit-display {
        font-size: 60px; font-weight: 800; 
        background: -webkit-linear-gradient(#ff7b72, #ff5858);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        letter-spacing: 15px;
        text-shadow: 0 0 20px rgba(255, 88, 88, 0.3);
    }
    
    .sub-digit {
        font-size: 40px; font-weight: 600; color: #58a6ff;
        text-align: center; letter-spacing: 10px;
    }

    .status-badge {
        display: inline-block; padding: 5px 15px; border-radius: 20px;
        font-size: 14px; font-weight: bold; text-transform: uppercase;
        margin-right: 10px;
    }
    .bg-high { background: rgba(46, 160, 67, 0.2); color: #3fb950; border: 1px solid #3fb950; }
    .bg-med { background: rgba(210, 153, 34, 0.2); color: #d29922; border: 1px solid #d29922; }
    .bg-low { background: rgba(218, 54, 51, 0.2); color: #f85149; border: 1px solid #f85149; }
    </style>
""", unsafe_allow_html=True)

st.markdown("<h1 style='text-align: center; color: #58a6ff; margin-bottom: 5px;'>üîÆ TITAN v25.0 QUANTUM</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: #8b949e; margin-top: 0;'>Hybrid AI & Statistical Probability Engine</p>", unsafe_allow_html=True)

# --- SIDEBAR CONFIG ---
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh Thu·∫≠t to√°n")
    algo_mode = st.selectbox("Ch·∫ø ƒë·ªô ph√¢n t√≠ch", ["Balanced (C√¢n b·∫±ng)", "Aggressive (T·∫•n c√¥ng)", "Conservative (An to√†n)"])
    st.info("Ch·∫ø ƒë·ªô Aggressive ∆∞u ti√™n c√°c s·ªë c√≥ Gap cao (l√¢u ch∆∞a v·ªÅ).")
    st.divider()
    st.write(f"üì¶ Database: **{len(st.session_state.history)}** k·ª≥")
    if st.button("üóëÔ∏è X√≥a to√†n b·ªô d·ªØ li·ªáu", type="primary"):
        st.session_state.history = []
        if os.path.exists(DB_FILE): os.remove(DB_FILE)
        st.rerun()

# --- MAIN INPUT AREA ---
with st.container():
    col_in, col_act = st.columns([2, 1])
    with col_in:
        raw_input = st.text_area("üì° N·∫°p d·ªØ li·ªáu l·ªãch s·ª≠ (D√°n b·∫£ng k·∫øt qu·∫£):", height=100, placeholder="V√≠ d·ª•:\n32880\n21808\n99213...")
    with col_act:
        st.write("") 
        st.write("") 
        c1, c2 = st.columns(2)
        with c1:
            btn_analyze = st.button("üöÄ K√çCH HO·∫†T TITAN", type="primary", use_container_width=True)
        with c2:
            btn_clear_input = st.button("X√≥a khung nh·∫≠p", use_container_width=True)

if btn_clear_input:
    st.rerun()

# --- LOGIC X·ª¨ L√ù ---
if btn_analyze:
    with st.spinner('üîÑ ƒêang ƒë·ªìng b·ªô d·ªØ li·ªáu & Ch·∫°y thu·∫≠t to√°n l∆∞·ª£ng t·ª≠...'):
        # 1. L√†m s·∫°ch d·ªØ li·ªáu
        new_data = re.findall(r"\b\d{5}\b", raw_input)
        if new_data:
            # Update history
            current_set = set(st.session_state.history)
            for item in new_data:
                if item not in current_set:
                    st.session_state.history.append(item)
            
            save_db(st.session_state.history)
            
            # 2. Ch·∫°y thu·∫≠t to√°n th·ªëng k√™ n·ªôi b·ªô (Python)
            analyzer = QuantumAnalyzer(st.session_state.history)
            weighted_scores = analyzer.calculate_weighted_score()
            freq_data = analyzer.get_frequency_analysis(100)
            gap_data = analyzer.get_gap_analysis()
            markov_data = analyzer.get_markov_transition()
            
            # Top 5 s·ªë n√≥ng nh·∫•t theo t√≠nh to√°n
            top_5_math = [x[0] for x in weighted_scores[:5]]
            
            # 3. G·ª≠i d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω cho AI (Gemini) ƒë·ªÉ ra quy·∫øt ƒë·ªãnh cu·ªëi c√πng
            prompt_data = f"""
            D·ªØ li·ªáu th·ªëng k√™ Lotobet (100 k·ª≥ g·∫ßn):
            - T·∫ßn su·∫•t cao nh·∫•t: {freq_data}
            - S·ªë l√¢u ch∆∞a v·ªÅ (Gap): {gap_data[:5]}
            - Top 5 s·ªë ti·ªÅm nƒÉng (To√°n h·ªçc): {top_5_math}
            - Quy lu·∫≠t chuy·ªÉn ƒë·ªïi (Markov): {markov_data}
            
            Nhi·ªám v·ª• c·ªßa b·∫°n (Si√™u tr√≠ tu·ªá Titan):
            D·ª±a tr√™n d·ªØ li·ªáu to√°n h·ªçc tr√™n, h√£y d·ª± ƒëo√°n 3 s·ªë ch√≠nh (Main) v√† 4 s·ªë l√≥t (Support) cho k·ª≥ ti·∫øp theo.
            ∆Øu ti√™n c√°c s·ªë c√≥ ƒëi·ªÉm Weighted Score cao nh∆∞ng ch∆∞a v·ªÅ trong 2 k·ª≥ g·∫ßn nh·∫•t.
            
            Tr·∫£ v·ªÅ JSON thu·∫ßn t√∫y (kh√¥ng markdown):
            {{
                "main_3": "xyz",
                "support_4": "abcd",
                "confidence": 85-99,
                "reasoning": "L√Ω do ch·ªçn d·ª±a tr√™n Gap ho·∫∑c T·∫ßn su·∫•t...",
                "warning": "C·∫£nh b√°o n·∫øu c√≥ b·ªát c·∫ßu"
            }}
            """
            
            try:
                response = neural_engine.generate_content(prompt_data)
                text_res = response.text
                # Clean markdown code blocks if present
                if "```json" in text_res:
                    text_res = text_res.split("```json")[1].split("```")[0]
                elif "```" in text_res:
                    text_res = text_res.split("```")[1].split("```")[0]
                
                prediction = json.loads(text_res.strip())
                st.session_state.last_prediction = prediction
                st.session_state.math_backup = {
                    "main_3": "".join(top_5_math[:3]),
                    "support_4": "".join(top_5_math[3:7] if len(top_5_math) > 3 else "0000"),
                    "confidence": 75,
                    "reasoning": "D·ª±a ho√†n to√†n tr√™n thu·∫≠t to√°n Weighted Score.",
                    "warning": "Kh√¥ng c√≥ c·∫£nh b√°o ƒë·∫∑c bi·ªát."
                }
            except Exception as e:
                st.session_state.last_prediction = st.session_state.math_backup
                st.session_state.last_prediction['reasoning'] += f" (AI Error: {str(e)})"
            
            st.rerun()

# --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
if "last_prediction" in st.session_state:
    res = st.session_state.last_prediction
    
    conf = int(res.get('confidence', 50))
    if conf >= 90: color_class = "bg-high"
    elif conf >= 75: color_class = "bg-med"
    else: color_class = "bg-low"
    
    st.markdown("<div class='main-card'>", unsafe_allow_html=True)
    
    c_head1, c_head2 = st.columns([3, 1])
    with c_head1:
        st.markdown(f"<span class='status-badge {color_class}'>ƒê·ªô tin c·∫≠y: {conf}%</span>", unsafe_allow_html=True)
        st.markdown(f"üß† **Logic:** {res.get('reasoning', 'ƒêang ph√¢n t√≠ch...')}")
    with c_head2:
        if 'warning' in res and res['warning']:
            st.warning(f"‚ö†Ô∏è {res['warning']}")

    st.divider()
    
    c_num1, c_num2 = st.columns([1, 1])
    with c_num1:
        st.markdown("<p style='text-align:center; color:#8b949e;'>üéØ 3 S·ªê CH·ª¶ L·ª∞C (MAIN)</p>", unsafe_allow_html=True)
        st.markdown(f"<div class='digit-display'>{res.get('main_3', '???')}</div>", unsafe_allow_html=True)
    with c_num2:
        st.markdown("<p style='text-align:center; color:#8b949e;'>üõ°Ô∏è 4 S·ªê L√ìT (SUPPORT)</p>", unsafe_allow_html=True)
        st.markdown(f"<div class='sub-digit'>{res.get('support_4', '???')}</div>", unsafe_allow_html=True)
        
    st.divider()
    
    full_set = sorted(set(res.get('main_3', '') + res.get('support_4', '')))
    full_str = "".join(full_set)
    
    c_copy, c_chart = st.columns([1, 2])
    with c_copy:
        st.text_input("üìã D√†n 7 s·ªë t·ªëi ∆∞u:", full_str, label_visibility="collapsed")
    
    with c_chart:
        # V·∫Ω bi·ªÉu ƒë·ªì top s·ªë n√≥ng
        temp_analyzer = QuantumAnalyzer(st.session_state.history)
        w_scores = temp_analyzer.calculate_weighted_score()
        df_viz = pd.DataFrame(w_scores[:5], columns=['S·ªë', 'ƒêi·ªÉm'])
        df_viz['S·ªë'] = df_viz['S·ªë'].astype(str)
        st.bar_chart(df_viz.set_index('S·ªë'), color="#58a6ff")

    st.markdown("</div>", unsafe_allow_html=True)

# --- FOOTER STATISTICS ---
with st.expander("üìä Chi ti·∫øt th·ªëng k√™ s√¢u (D√†nh cho Pro)"):
    if st.session_state.history:
        temp_analyzer = QuantumAnalyzer(st.session_state.history)
        col_s1, col_s2 = st.columns(2)
        with col_s1:
            st.write("**üî• Top 5 S·ªë N√≥ng Nh·∫•t (T·∫ßn su·∫•t cao):**")
            freq = temp_analyzer.get_frequency_analysis(50)
            sorted_freq = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:5]
            for k, v in sorted_freq:
                st.progress(v/100)
                st.caption(f"S·ªë {k}: {v}%")
        with col_s2:
            st.write("**‚ùÑÔ∏è Top 5 S·ªë L·∫°nh Nh·∫•t (Gap cao - S·∫Øp v·ªÅ):**")
            gaps = temp_analyzer.get_gap_analysis()[:5]
            for k, v in gaps:
                st.progress(min(v/30, 1.0))
                st.caption(f"S·ªë {k}: Ch∆∞a v·ªÅ {v} k·ª≥")