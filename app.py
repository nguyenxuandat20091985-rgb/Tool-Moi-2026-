import streamlit as st
import google.generativeai as genai
import re
import json
import os
from collections import Counter, defaultdict
from datetime import datetime
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import time
import hashlib
import random
from typing import List, Dict, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# ================= Cáº¤U HÃŒNH Há»† THá»NG =================
API_KEY = "AIzaSyChq-KF-DXqPQUpxDsVIvx5D4_jRH1ERqM"
DB_FILE = "titan_memory_v21.json"
PREDICTIONS_FILE = "titan_predictions_v21.json"
PATTERNS_FILE = "titan_patterns_v21.json"
STATS_FILE = "titan_stats_v21.json"
CRAWLER_FILE = "titan_crawler_v21.json"

# Cáº¥u hÃ¬nh crawler
SOURCES = [
    "https://www.minhngoc.net.vn/ket-qua-xo-so.html",
    "https://ketqua1.net/",
    "https://xosodaiphat.com/",
    # ThÃªm cÃ¡c nguá»“n khÃ¡c
]

def setup_neural():
    try:
        genai.configure(api_key=API_KEY)
        return genai.GenerativeModel('gemini-1.5-flash')
    except: 
        return None

neural_engine = setup_neural()

# ================= Há»† THá»NG LÆ¯U TRá»® =================
def load_json(file_path, default=None):
    if os.path.exists(file_path):
        with open(file_path, "r") as f:
            try: return json.load(f)
            except: return default if default else []
    return default if default else []

def save_json(file_path, data, max_items=1000):
    with open(file_path, "w") as f:
        if isinstance(data, list):
            json.dump(data[-max_items:], f)
        else:
            json.dump(data, f)

# Khá»Ÿi táº¡o session state
if "history" not in st.session_state:
    st.session_state.history = load_json(DB_FILE, [])
if "predictions" not in st.session_state:
    st.session_state.predictions = load_json(PREDICTIONS_FILE, [])
if "patterns_db" not in st.session_state:
    st.session_state.patterns_db = load_json(PATTERNS_FILE, {})
if "stats_db" not in st.session_state:
    st.session_state.stats_db = load_json(STATS_FILE, {})
if "crawler_data" not in st.session_state:
    st.session_state.crawler_data = load_json(CRAWLER_FILE, {})
if "accuracy_history" not in st.session_state:
    st.session_state.accuracy_history = []

# ================= Há»† THá»NG CRAWLER Tá»° Äá»˜NG =================
class AutoCrawler:
    def __init__(self):
        self.sources = SOURCES
        self.last_crawl = st.session_state.crawler_data.get('last_crawl', {})
        self.cached_data = st.session_state.crawler_data.get('data', [])
    
    def crawl_all_sources(self):
        """Thu tháº­p dá»¯ liá»‡u tá»« nhiá»u nguá»“n"""
        all_numbers = []
        sources_data = {}
        
        for source in self.sources:
            try:
                numbers = self.crawl_source(source)
                if numbers:
                    all_numbers.extend(numbers)
                    sources_data[source] = {
                        'numbers': numbers[-50:],
                        'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'count': len(numbers)
                    }
                time.sleep(1)  # TrÃ¡nh bá»‹ cháº·n
            except Exception as e:
                print(f"Lá»—i crawl {source}: {e}")
        
        # LÆ°u cache
        st.session_state.crawler_data = {
            'last_crawl': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'data': all_numbers[-500:],
            'sources': sources_data
        }
        save_json(CRAWLER_FILE, st.session_state.crawler_data)
        
        return all_numbers
    
    def crawl_source(self, url):
        """Crawl dá»¯ liá»‡u tá»« 1 nguá»“n"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # TÃ¬m cÃ¡c sá»‘ 5 chá»¯ sá»‘
            numbers = []
            text = soup.get_text()
            # Pattern tÃ¬m sá»‘ 5 chá»¯ sá»‘
            found_numbers = re.findall(r'\b\d{5}\b', text)
            
            # Lá»c vÃ  chuáº©n hÃ³a
            for num in found_numbers:
                if len(num) == 5 and num.isdigit():
                    numbers.append(num)
            
            return list(set(numbers))[-100:]  # Tráº£ vá» 100 sá»‘ gáº§n nháº¥t
        except:
            return []
    
    def get_online_trend(self):
        """Láº¥y xu hÆ°á»›ng tá»« cÃ¡c nguá»“n online"""
        if not self.cached_data:
            return {}
        
        all_nums = "".join(self.cached_data[-200:])
        if not all_nums:
            return {}
        
        counts = Counter(all_nums)
        total = len(all_nums)
        
        return {
            'hot_online': [num for num, _ in counts.most_common(5)],
            'cold_online': [num for num, _ in counts.most_common()[-5:]],
            'frequencies': {num: count/total for num, count in counts.items()}
        }

# ================= Há»† THá»NG PHÃT HIá»†N QUY LUáº¬T =================
class PatternDetector:
    def __init__(self, history):
        self.history = history[-500:] if len(history) > 500 else history
        self.patterns_db = st.session_state.patterns_db
    
    def find_number_pairs(self):
        """PhÃ¡t hiá»‡n cÃ¡c sá»‘ hay Ä‘i cÃ¹ng nhau"""
        if len(self.history) < 20:
            return {}
        
        pairs = defaultdict(int)
        pair_positions = defaultdict(list)
        
        # XÃ©t tá»«ng cáº·p sá»‘ trong dÃ£y 5 sá»‘
        for num_str in self.history[-200:]:
            digits = list(num_str)
            for i in range(5):
                for j in range(i+1, 5):
                    pair = f"{digits[i]}{digits[j]}"
                    pairs[pair] += 1
                    pair_positions[pair].append((i, j))
        
        # TÃ­nh xÃ¡c suáº¥t vÃ  lá»c cáº·p cÃ³ Ã½ nghÄ©a
        total_pairs = sum(pairs.values())
        significant_pairs = {}
        
        for pair, count in pairs.items():
            probability = count / total_pairs
            if probability > 0.03:  # NgÆ°á»¡ng 3%
                significant_pairs[pair] = {
                    'count': count,
                    'probability': probability,
                    'positions': pair_positions[pair][-5:],
                    'strength': 'CAO' if probability > 0.05 else 'TRUNG BÃŒNH'
                }
        
        return dict(sorted(significant_pairs.items(), 
                          key=lambda x: x[1]['probability'], 
                          reverse=True))
    
    def find_triplet_patterns(self):
        """PhÃ¡t hiá»‡n bá»™ 3 sá»‘ hay ra cÃ¹ng nhau"""
        if len(self.history) < 30:
            return {}
        
        triplets = defaultdict(int)
        
        for num_str in self.history[-200:]:
            digits = sorted(list(num_str))  # Sáº¯p xáº¿p Ä‘á»ƒ dá»… so sÃ¡nh
            for i in range(3):
                for j in range(i+1, 4):
                    for k in range(j+1, 5):
                        triplet = f"{digits[i]}{digits[j]}{digits[k]}"
                        triplets[triplet] += 1
        
        # Lá»c bá»™ 3 Ä‘áº·c biá»‡t
        special_triplets = {}
        for triplet, count in triplets.items():
            if count > 5:  # Xuáº¥t hiá»‡n Ã­t nháº¥t 5 láº§n
                special_triplets[triplet] = {
                    'count': count,
                    'frequency': count / len(self.history[-200:])
                }
        
        return dict(sorted(special_triplets.items(), 
                          key=lambda x: x[1]['count'], 
                          reverse=True)[:20])
    
    def detect_house_tricks(self):
        """PhÃ¡t hiá»‡n nhÃ  cÃ¡i lá»«a cáº§u"""
        tricks = {
            'dao_cau': False,
            'bay_mau': False,
            'sáº­p_bá»‡t': False,
            'thay_doi_xac_suat': False,
            'warning_level': 'GREEN',
            'details': []
        }
        
        if len(self.history) < 30:
            return tricks
        
        # 1. Kiá»ƒm tra Ä‘áº£o cáº§u Ä‘á»™t ngá»™t
        last_20 = "".join(self.history[-20:])
        prev_20 = "".join(self.history[-40:-20])
        
        unique_last = len(set(last_20))
        unique_prev = len(set(prev_20))
        
        if unique_last > unique_prev + 2:
            tricks['dao_cau'] = True
            tricks['details'].append("Äáº£o cáº§u Ä‘á»™t ngá»™t - Xuáº¥t hiá»‡n nhiá»u sá»‘ láº¡")
        
        # 2. Kiá»ƒm tra báº«y mÃ u (sá»‘ hay ra bá»—ng nhiÃªn biáº¿n máº¥t)
        hot_numbers = Counter(prev_20).most_common(3)
        for num, _ in hot_numbers:
            if num not in last_20:
                tricks['bay_mau'] = True
                tricks['details'].append(f"Sá»‘ hot {num} Ä‘á»™t nhiÃªn biáº¿n máº¥t - CÃ³ thá»ƒ báº«y")
        
        # 3. Kiá»ƒm tra sáº­p bá»‡t
        if len(self.history) > 10:
            current_streak = 1
            for i in range(len(self.history)-2, -1, -1):
                if self.history[i] == self.history[-1]:
                    current_streak += 1
                else:
                    break
            
            if current_streak >= 4:
                # Kiá»ƒm tra xem cÃ³ dáº¥u hiá»‡u sáº­p bá»‡t khÃ´ng
                next_after_streak = self.history[-(current_streak+1):-current_streak] if len(self.history) > current_streak else []
                if next_after_streak and len(set(next_after_streak)) > 3:
                    tricks['sáº­p_bá»‡t'] = True
                    tricks['details'].append(f"Cáº§u bá»‡t {current_streak} ká»³ cÃ³ dáº¥u hiá»‡u sáº­p")
        
        # 4. XÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ cáº£nh bÃ¡o
        warning_score = 0
        if tricks['dao_cau']: warning_score += 2
        if tricks['bay_mau']: warning_score += 2
        if tricks['sáº­p_bá»‡t']: warning_score += 3
        
        if warning_score >= 5:
            tricks['warning_level'] = 'RED'
        elif warning_score >= 3:
            tricks['warning_level'] = 'ORANGE'
        elif warning_score >= 1:
            tricks['warning_level'] = 'YELLOW'
        
        return tricks
    
    def find_cycles(self):
        """TÃ¬m chu ká»³ láº·p láº¡i cá»§a cÃ¡c sá»‘"""
        cycles = {}
        
        for length in [3, 4, 5, 6, 7, 8, 9, 10]:
            if len(self.history) < length * 3:
                continue
            
            # Chuyá»ƒn Ä‘á»•i history thÃ nh string Ä‘á»ƒ dá»… xá»­ lÃ½
            history_str = "".join(self.history)
            
            # TÃ¬m cÃ¡c pattern láº·p láº¡i
            patterns = {}
            for i in range(len(history_str) - length):
                pattern = history_str[i:i+length]
                if pattern in patterns:
                    patterns[pattern] += 1
                else:
                    patterns[pattern] = 1
            
            # Lá»c pattern cÃ³ táº§n suáº¥t cao
            significant = {p: c for p, c in patterns.items() if c > 2}
            if significant:
                cycles[f"cycle_{length}"] = {
                    'length': length,
                    'patterns': dict(sorted(significant.items(), 
                                           key=lambda x: x[1], 
                                           reverse=True)[:3])
                }
        
        return cycles

# ================= Há»† THá»NG SO SÃNH ÄA NGUá»’N =================
class MultiAISystem:
    def __init__(self):
        self.models = {
            'gemini': neural_engine,
            # CÃ³ thá»ƒ thÃªm cÃ¡c AI khÃ¡c á»Ÿ Ä‘Ã¢y
        }
        self.weights = {
            'gemini': 0.4,
            'pattern': 0.3,
            'statistical': 0.2,
            'crawler': 0.1
        }
    
    def ensemble_prediction(self, history, pattern_data, crawler_data):
        """Káº¿t há»£p dá»± Ä‘oÃ¡n tá»« nhiá»u nguá»“n"""
        predictions = {}
        
        # 1. Dá»± Ä‘oÃ¡n tá»« Gemini
        if self.models['gemini']:
            gemini_pred = self.get_gemini_prediction(history, pattern_data)
            if gemini_pred:
                predictions['gemini'] = gemini_pred
        
        # 2. Dá»± Ä‘oÃ¡n tá»« pattern
        pattern_pred = self.get_pattern_prediction(pattern_data)
        if pattern_pred:
            predictions['pattern'] = pattern_pred
        
        # 3. Dá»± Ä‘oÃ¡n thá»‘ng kÃª
        stat_pred = self.get_statistical_prediction(history)
        if stat_pred:
            predictions['statistical'] = stat_pred
        
        # 4. Dá»± Ä‘oÃ¡n tá»« crawler
        if crawler_data:
            crawler_pred = self.get_crawler_prediction(crawler_data)
            if crawler_pred:
                predictions['crawler'] = crawler_pred
        
        # Káº¿t há»£p cÃ³ trá»ng sá»‘
        return self.weighted_combination(predictions)
    
    def get_gemini_prediction(self, history, pattern_data):
        """Láº¥y dá»± Ä‘oÃ¡n tá»« Gemini"""
        try:
            prompt = f"""
            Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch sá»‘ 5D vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao.
            
            Dá»® LIá»†U PHÃ‚N TÃCH CHUYÃŠN SÃ‚U:
            - Lá»‹ch sá»­ 200 ká»³ gáº§n nháº¥t: {history[-200:]}
            - CÃ¡c cáº·p sá»‘ hay Ä‘i cÃ¹ng: {pattern_data.get('pairs', {})}
            - Bá»™ 3 sá»‘ Ä‘áº·c biá»‡t: {pattern_data.get('triplets', {})}
            - Chu ká»³ phÃ¡t hiá»‡n: {pattern_data.get('cycles', {})}
            - Cáº£nh bÃ¡o nhÃ  cÃ¡i: {pattern_data.get('tricks', {})}
            
            NHIá»†M Vá»¤:
            1. PhÃ¢n tÃ­ch quy luáº­t thá»±c sá»± cá»§a nhÃ  cÃ¡i
            2. Dá»± Ä‘oÃ¡n 4 sá»‘ cÃ³ xÃ¡c suáº¥t cao nháº¥t (KHÃ”NG ÄÆ¯á»¢C SAI)
            3. Dá»± Ä‘oÃ¡n 3 sá»‘ dá»± phÃ²ng
            4. Cáº£nh bÃ¡o náº¿u phÃ¡t hiá»‡n báº«y
            
            YÃŠU Cáº¦U Äáº¶C BIá»†T:
            - Pháº£i Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c >85%
            - Náº¿u khÃ´ng cháº¯c cháº¯n, Æ°u tiÃªn an toÃ n
            - PhÃ¡t hiá»‡n má»i dáº¥u hiá»‡u báº¥t thÆ°á»ng
            
            TRáº¢ Vá»€ JSON:
            {{
                "dan4": ["4 sá»‘ chÃ­nh xÃ¡c nháº¥t"],
                "dan3": ["3 sá»‘ dá»± phÃ²ng"],
                "quy_luat": "quy luáº­t nhÃ  cÃ¡i Ä‘ang dÃ¹ng",
                "canh_bao": "cáº£nh bÃ¡o náº¿u cÃ³",
                "do_tin_cay": 0-100,
                "ly_do": "phÃ¢n tÃ­ch chi tiáº¿t"
            }}
            """
            
            response = self.models['gemini'].generate_content(prompt)
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        return None
    
    def get_pattern_prediction(self, pattern_data):
        """Dá»± Ä‘oÃ¡n dá»±a trÃªn pattern"""
        if not pattern_data:
            return None
        
        pairs = pattern_data.get('pairs', {})
        triplets = pattern_data.get('triplets', {})
        
        # Dá»±a vÃ o cÃ¡c cáº·p sá»‘ máº¡nh nháº¥t Ä‘á»ƒ dá»± Ä‘oÃ¡n
        strong_pairs = [p for p, data in pairs.items() 
                       if data.get('strength') == 'CAO']
        
        if strong_pairs:
            return {
                'dan4': list(strong_pairs[0])[:4],
                'dan3': list(strong_pairs[0])[4:7] if len(strong_pairs[0]) > 4 else [],
                'do_tin_cay': 75,
                'nguon': 'pattern'
            }
        return None
    
    def get_statistical_prediction(self, history):
        """Dá»± Ä‘oÃ¡n dá»±a trÃªn thá»‘ng kÃª"""
        if len(history) < 50:
            return None
        
        all_nums = "".join(history[-100:])
        counts = Counter(all_nums)
        
        # TÃ­nh xÃ¡c suáº¥t cÃ³ Ä‘iá»u chá»‰nh
        probs = {}
        total = len(all_nums)
        for num in '0123456789':
            base_prob = counts.get(num, 0) / total
            
            # Äiá»u chá»‰nh theo xu hÆ°á»›ng gáº§n
            recent = "".join(history[-20:])
            recent_count = recent.count(num)
            recent_prob = recent_count / 20 if recent_count > 0 else 0
            
            # Káº¿t há»£p
            probs[num] = base_prob * 0.4 + recent_prob * 0.6
        
        sorted_nums = sorted(probs.items(), key=lambda x: x[1], reverse=True)
        
        return {
            'dan4': [num for num, _ in sorted_nums[:4]],
            'dan3': [num for num, _ in sorted_nums[4:7]],
            'do_tin_cay': 70,
            'nguon': 'statistical'
        }
    
    def get_crawler_prediction(self, crawler_data):
        """Dá»± Ä‘oÃ¡n dá»±a trÃªn dá»¯ liá»‡u crawler"""
        if not crawler_data or 'hot_online' not in crawler_data:
            return None
        
        hot = crawler_data['hot_online']
        return {
            'dan4': hot[:4],
            'dan3': hot[4:7] if len(hot) > 4 else [],
            'do_tin_cay': 65,
            'nguon': 'crawler'
        }
    
    def weighted_combination(self, predictions):
        """Káº¿t há»£p cÃ¡c dá»± Ä‘oÃ¡n vá»›i trá»ng sá»‘"""
        if not predictions:
            return None
        
        # Äáº¿m sá»‘ phiáº¿u cho má»—i sá»‘
        votes = defaultdict(float)
        all_reasons = []
        warnings = []
        
        for source, pred in predictions.items():
            weight = self.weights.get(source, 0.2)
            
            # Cá»™ng phiáº¿u cho dan4
            for num in pred.get('dan4', []):
                votes[num] += weight * 1.5  # Trá»ng sá»‘ cao hÆ¡n cho dan4
            
            # Cá»™ng phiáº¿u cho dan3
            for num in pred.get('dan3', []):
                votes[num] += weight
            
            # Thu tháº­p lÃ½ do
            if 'ly_do' in pred:
                all_reasons.append(f"{source}: {pred['ly_do']}")
            if 'canh_bao' in pred and pred['canh_bao']:
                warnings.append(pred['canh_bao'])
        
        # Sáº¯p xáº¿p theo sá»‘ phiáº¿u
        sorted_votes = sorted(votes.items(), key=lambda x: x[1], reverse=True)
        
        # TÃ­nh Ä‘á»™ tin cáº­y tá»•ng há»£p
        total_confidence = sum(p.get('do_tin_cay', 0) * self.weights.get(s, 0.2) 
                              for s, p in predictions.items()) / len(predictions)
        
        return {
            'dan4': [num for num, _ in sorted_votes[:4]],
            'dan3': [num for num, _ in sorted_votes[4:7]],
            'do_tin_cay': min(total_confidence * 1.2, 98),  # Boost nháº¹
            'ly_do': "\n".join(all_reasons[:3]),
            'canh_bao': " | ".join(warnings) if warnings else "",
            'votes': dict(sorted_votes[:10])
        }

# ================= UI DESIGN =================
st.set_page_config(page_title="TITAN v21.0 PRO MAX", layout="centered")
st.markdown("""
    <style>
    .stApp { background: #010409; color: #c9d1d9; }
    .status-active { color: #238636; font-weight: bold; border-left: 3px solid #238636; padding-left: 10px; }
    .prediction-card {
        background: #0d1117; border: 2px solid #30363d;
        border-radius: 12px; padding: 25px; margin-top: 15px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.5);
    }
    .num-display { 
        font-size: 60px; font-weight: 900; color: #58a6ff; 
        text-align: center; letter-spacing: 10px; text-shadow: 0 0 25px #58a6ff;
    }
    .logic-box { 
        font-size: 14px; color: #8b949e; background: #161b22; 
        padding: 15px; border-radius: 8px; margin-bottom: 20px;
        border-left: 4px solid #58a6ff;
    }
    .warning-red {
        background: #f8514920; border-left: 4px solid #f85149;
        padding: 15px; border-radius: 8px; margin: 10px 0;
    }
    .warning-orange {
        background: #f0883e20; border-left: 4px solid #f0883e;
        padding: 15px; border-radius: 8px; margin: 10px 0;
    }
    .warning-yellow {
        background: #f2cc6020; border-left: 4px solid #f2cc60;
        padding: 15px; border-radius: 8px; margin: 10px 0;
    }
    .pair-badge {
        background: #1f6feb; color: white; padding: 4px 12px;
        border-radius: 20px; font-size: 13px; display: inline-block;
        margin: 3px; font-weight: bold;
    }
    .stats-box {
        background: #161b22; border-radius: 10px; padding: 15px;
        margin: 10px 0; border: 1px solid #30363d;
    }
    .accuracy-meter {
        height: 10px; background: #30363d; border-radius: 5px;
        margin: 10px 0;
    }
    .accuracy-fill {
        height: 10px; background: linear-gradient(90deg, #238636, #58a6ff);
        border-radius: 5px;
    }
    </style>
""", unsafe_allow_html=True)

# Header
st.markdown("<h1 style='text-align: center; color: #58a6ff;'>ğŸ§¬ TITAN v21.0 PRO MAX</h1>", unsafe_allow_html=True)

# Khá»Ÿi táº¡o cÃ¡c há»‡ thá»‘ng
crawler = AutoCrawler()

# Hiá»ƒn thá»‹ tráº¡ng thÃ¡i
col_status1, col_status2, col_status3 = st.columns(3)
with col_status1:
    st.markdown(f"<p class='status-active'>ğŸ“Š Dá»® LIá»†U: {len(st.session_state.history)} Ká»²</p>", unsafe_allow_html=True)
with col_status2:
    accuracy = len([p for p in st.session_state.predictions if p.get('result', False)]) / max(len(st.session_state.predictions), 1) * 100
    st.markdown(f"<p class='status-active'>ğŸ¯ Äá»˜ CHÃNH XÃC: {accuracy:.1f}%</p>", unsafe_allow_html=True)
with col_status3:
    st.markdown(f"<p class='status-active'>ğŸŒ NGUá»’N: {len(SOURCES)}</p>", unsafe_allow_html=True)

# ================= AUTO CRAWLER =================
with st.expander("ğŸŒ Há»† THá»NG THU THáº¬P Dá»® LIá»†U Tá»° Äá»˜NG", expanded=False):
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”„ CRAWL Dá»® LIá»†U NGAY", use_container_width=True):
            with st.spinner("Äang thu tháº­p dá»¯ liá»‡u tá»« cÃ¡c nguá»“n..."):
                new_data = crawler.crawl_all_sources()
                if new_data:
                    st.success(f"âœ… ÄÃ£ thu tháº­p {len(new_data)} sá»‘ má»›i!")
                    # ThÃªm vÃ o history
                    st.session_state.history.extend(new_data)
                    save_json(DB_FILE, st.session_state.history)
                    st.rerun()
                else:
                    st.error("âŒ KhÃ´ng thu tháº­p Ä‘Æ°á»£c dá»¯ liá»‡u")
    
    with col2:
        st.markdown(f"**Láº§n crawl cuá»‘i:** {st.session_state.crawler_data.get('last_crawl', 'ChÆ°a cÃ³')}")
    
    # Hiá»ƒn thá»‹ dá»¯ liá»‡u tá»« cÃ¡c nguá»“n
    if st.session_state.crawler_data.get('sources'):
        st.markdown("### ğŸ“Š Dá»® LIá»†U Tá»ª CÃC NGUá»’N")
        for source, data in st.session_state.crawler_data['sources'].items():
            st.markdown(f"""
            <div style='background: #161b22; padding: 10px; border-radius: 5px; margin: 5px 0;'>
                <b>{source[:50]}...</b><br>
                <small>Sá»‘ lÆ°á»£ng: {data['count']} | {data['time']}</small>
            </div>
            """, unsafe_allow_html=True)

# ================= PHÃ‚N TÃCH NÃ‚NG CAO =================
if st.session_state.history:
    detector = PatternDetector(st.session_state.history)
    
    # PhÃ¡t hiá»‡n cÃ¡c cáº·p sá»‘ hay Ä‘i cÃ¹ng
    pairs = detector.find_number_pairs()
    triplets = detector.find_triplet_patterns()
    tricks = detector.detect_house_tricks()
    cycles = detector.find_cycles()
    
    # Láº¥y xu hÆ°á»›ng online
    online_trend = crawler.get_online_trend()
    
    # Tabs phÃ¢n tÃ­ch
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ¯ Dá»° ÄOÃN", 
        "ğŸ”„ Cáº¶P Sá»", 
        "âš ï¸ PHÃT HIá»†N BáºªY",
        "ğŸ“ˆ CHU Ká»²",
        "ğŸŒ ONLINE"
    ])
    
    with tab1:
        st.markdown("### ğŸ¯ Dá»° ÄOÃN ÄA NGUá»’N")
        
        # NÃºt dá»± Ä‘oÃ¡n
        if st.button("ğŸš€ Dá»° ÄOÃN SIÃŠU CHÃNH XÃC", use_container_width=True):
            with st.spinner("Äang phÃ¢n tÃ­ch tá»« nhiá»u nguá»“n..."):
                # Chuáº©n bá»‹ dá»¯ liá»‡u cho multi AI
                pattern_data = {
                    'pairs': pairs,
                    'triplets': triplets,
                    'tricks': tricks,
                    'cycles': cycles
                }
                
                # Multi AI system
                ai_system = MultiAISystem()
                final_pred = ai_system.ensemble_prediction(
                    st.session_state.history, 
                    pattern_data,
                    online_trend
                )
                
                if final_pred:
                    # LÆ°u dá»± Ä‘oÃ¡n
                    pred_record = {
                        'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'dan4': final_pred['dan4'],
                        'dan3': final_pred['dan3'],
                        'do_tin_cay': final_pred['do_tin_cay'],
                        'ly_do': final_pred.get('ly_do', ''),
                        'canh_bao': final_pred.get('canh_bao', ''),
                        'votes': final_pred.get('votes', {})
                    }
                    st.session_state.predictions.append(pred_record)
                    save_json(PREDICTIONS_FILE, st.session_state.predictions)
                    
                    st.session_state.last_result = final_pred
                    st.rerun()
    
    with tab2:
        st.markdown("### ğŸ”¥ CÃC Cáº¶P Sá» HAY ÄI CÃ™NG NHAU")
        
        if pairs:
            cols = st.columns(3)
            for i, (pair, data) in enumerate(list(pairs.items())[:12]):
                with cols[i % 3]:
                    strength_color = "#238636" if data['strength'] == 'CAO' else "#f2cc60"
                    st.markdown(f"""
                    <div style='background: #161b22; padding: 15px; border-radius: 8px; margin: 5px; text-align: center;'>
                        <div style='font-size: 24px; font-weight: bold; color: {strength_color};'>
                            {pair[0]} - {pair[1]}
                        </div>
                        <div style='font-size: 12px;'>
                            XS: {(data['probability']*100):.1f}%<br>
                            Äá»™ máº¡nh: <span style='color: {strength_color};'>{data['strength']}</span>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
        else:
            st.info("ChÆ°a Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch cáº·p sá»‘")
        
        st.markdown("### ğŸ¯ Bá»˜ 3 Sá» Äáº¶C BIá»†T")
        if triplets:
            for triplet, data in list(triplets.items())[:10]:
                st.markdown(f"""
                <div style='background: #161b22; padding: 8px; border-radius: 5px; margin: 3px; display: inline-block;'>
                    <b>{triplet}</b> ({data['count']} láº§n)
                </div>
                """, unsafe_allow_html=True)
    
    with tab3:
        st.markdown("### âš ï¸ PHÃT HIá»†N BáºªY NHÃ€ CÃI")
        
        # Hiá»ƒn thá»‹ má»©c Ä‘á»™ cáº£nh bÃ¡o
        warning_level = tricks.get('warning_level', 'GREEN')
        if warning_level == 'RED':
            st.markdown("""
            <div class='warning-red'>
                <b>ğŸš¨ Cáº¢NH BÃO Äá» - NGUY HIá»‚M CAO</b><br>
                NhÃ  cÃ¡i Ä‘ang thay Ä‘á»•i hoÃ n toÃ n quy luáº­t. Äá»€ NGHá»Š Dá»ªNG Láº I!
            </div>
            """, unsafe_allow_html=True)
        elif warning_level == 'ORANGE':
            st.markdown("""
            <div class='warning-orange'>
                <b>âš ï¸ Cáº¢NH BÃO CAM - Rá»¦I RO CAO</b><br>
                PhÃ¡t hiá»‡n dáº¥u hiá»‡u báº¥t thÆ°á»ng. Cáº¨N TRá»ŒNG KHI VÃ€O TIá»€N!
            </div>
            """, unsafe_allow_html=True)
        elif warning_level == 'YELLOW':
            st.markdown("""
            <div class='warning-yellow'>
                <b>âš ï¸ Cáº¢NH BÃO VÃ€NG - THáº¬N TRá»ŒNG</b><br>
            </div>
            """, unsafe_allow_html=True)
        
        # Chi tiáº¿t cáº£nh bÃ¡o
        if tricks['details']:
            st.markdown("**ğŸ“‹ Chi tiáº¿t phÃ¡t hiá»‡n:**")
            for detail in tricks['details']:
                st.markdown(f"- {detail}")
        
        # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown(f"**Äáº£o cáº§u:** {'âœ…' if tricks['dao_cau'] else 'âŒ'}")
        with col2:
            st.markdown(f"**Báº«y mÃ u:** {'âœ…' if tricks['bay_mau'] else 'âŒ'}")
        with col3:
            st.markdown(f"**Sáº­p bá»‡t:** {'âœ…' if tricks['sáº­p_bá»‡t'] else 'âŒ'}")
    
    with tab4:
        st.markdown("### ğŸ“ˆ CHU Ká»² Láº¶P Láº I")
        
        if cycles:
            for cycle_name, cycle_data in cycles.items():
                with st.expander(f"Chu ká»³ {cycle_data['length']} sá»‘", expanded=False):
                    for pattern, count in cycle_data['patterns'].items():
                        st.markdown(f"""
                        <div style='background: #161b22; padding: 10px; border-radius: 5px; margin: 5px 0;'>
                            <code>{pattern}</code> - {count} láº§n láº·p
                        </div>
                        """, unsafe_allow_html=True)
        else:
            st.info("ChÆ°a phÃ¡t hiá»‡n chu ká»³ Ä‘Ã¡ng ká»ƒ")
    
    with tab5:
        st.markdown("### ğŸŒ XU HÆ¯á»šNG Tá»ª CÃC NGUá»’N ONLINE")
        
        if online_trend:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ğŸ”¥ Sá»‘ hot online:**")
                hot_html = ""
                for num in online_trend['hot_online']:
                    hot_html += f"<span class='pair-badge'>{num}</span> "
                st.markdown(hot_html, unsafe_allow_html=True)
            
            with col2:
                st.markdown("**â„ï¸ Sá»‘ nguá»™i online:**")
                cold_html = ""
                for num in online_trend['cold_online']:
                    cold_html += f"<span class='pair-badge' style='background: #8b949e;'>{num}</span> "
                st.markdown(cold_html, unsafe_allow_html=True)
            
            # Biá»ƒu Ä‘á»“ táº§n suáº¥t
            st.markdown("**ğŸ“Š PhÃ¢n bá»‘ táº§n suáº¥t online:**")
            for num, prob in sorted(online_trend['frequencies'].items(), 
                                    key=lambda x: x[1], reverse=True)[:10]:
                st.markdown(f"""
                <div>
                    Sá»‘ {num}: {prob*100:.1f}%
                    <div class='accuracy-meter'>
                        <div class='accuracy-fill' style='width: {prob*100}%'></div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("ChÆ°a cÃ³ dá»¯ liá»‡u online. HÃ£y crawl dá»¯ liá»‡u trÆ°á»›c!")

# ================= INPUT DATA =================
st.markdown("### ğŸ“¥ NHáº¬P Dá»® LIá»†U THá»¦ CÃ”NG")
raw_input = st.text_area("DÃ¡n cÃ¡c dÃ£y 5 sá»‘ (má»—i dÃ£y 1 dÃ²ng):", height=100, 
                         placeholder="32880\n21808\n69962\n...")

col1, col2, col3 = st.columns([2,1,1])
with col1:
    if st.button("ğŸ“¥ THÃŠM Dá»® LIá»†U", use_container_width=True):
        new_data = re.findall(r"\d{5}", raw_input)
        if new_data:
            st.session_state.history.extend(new_data)
            save_json(DB_FILE, st.session_state.history)
            st.success(f"âœ… ÄÃ£ thÃªm {len(new_data)} ká»³ má»›i!")
            st.rerun()

with col2:
    if st.button("ğŸ—‘ï¸ RESET", use_container_width=True):
        st.session_state.history = []
        if os.path.exists(DB_FILE): os.remove(DB_FILE)
        st.rerun()

with col3:
    if st.button("ğŸ“œ Lá»ŠCH Sá»¬", use_container_width=True):
        st.session_state.show_history = not st.session_state.get('show_history', False)
        st.rerun()

# ================= HIá»‚N THá»Š Lá»ŠCH Sá»¬ =================
if st.session_state.get('show_history', False):
    with st.expander("ğŸ“œ Lá»ŠCH Sá»¬ Dá»° ÄOÃN (100 Gáº¦N NHáº¤T)", expanded=True):
        if st.session_state.predictions:
            for i, pred in enumerate(reversed(st.session_state.predictions[-30:])):
                conf_color = "#238636" if pred.get('do_tin_cay', 0) > 85 else "#f2cc60"
                st.markdown(f"""
                <div style='background: #161b22; padding: 15px; border-radius: 8px; margin: 8px 0; border-left: 4px solid {conf_color};'>
                    <div style='display: flex; justify-content: space-between;'>
                        <small>ğŸ• {pred['time']}</small>
                        <small style='color: {conf_color};'>Äá»™ tin cáº­y: {pred.get('do_tin_cay', 0)}%</small>
                    </div>
                    <div style='font-size: 28px; letter-spacing: 8px; margin: 8px 0;'>
                        <span style='color: #58a6ff;'>{''.join(pred['dan4'])}</span>
                        <span style='color: #f2cc60;'>{''.join(pred['dan3'])}</span>
                    </div>
                    <small>ğŸ’¡ {pred.get('ly_do', '')[:150]}</small>
                    {f"<br><small>âš ï¸ {pred['canh_bao']}</small>" if pred.get('canh_bao') else ""}
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("ChÆ°a cÃ³ lá»‹ch sá»­ dá»± Ä‘oÃ¡n")

# ================= HIá»‚N THá»Š Káº¾T QUáº¢ Dá»° ÄOÃN =================
if "last_result" in st.session_state:
    res = st.session_state.last_result
    
    st.markdown("<div class='prediction-card'>", unsafe_allow_html=True)
    
    # Hiá»ƒn thá»‹ Ä‘á»™ tin cáº­y
    confidence = res.get('do_tin_cay', 85)
    conf_color = "#238636" if confidence > 85 else "#f2cc60" if confidence > 70 else "#f85149"
    
    st.markdown(f"""
    <div style='display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;'>
        <span style='color: #8b949e;'>ğŸ¯ Káº¾T QUáº¢ Dá»° ÄOÃN SIÃŠU CHÃNH XÃC</span>
        <span style='background: {conf_color}20; color: {conf_color}; padding: 8px 20px; border-radius: 25px; font-weight: bold; font-size: 18px;'>
            {confidence}% TIN Cáº¬Y
        </span>
    </div>
    """, unsafe_allow_html=True)
    
    # Hiá»ƒn thá»‹ cáº£nh bÃ¡o
    if res.get('canh_bao'):
        warning_level = tricks.get('warning_level', 'YELLOW')
        if warning_level == 'RED':
            st.error(f"ğŸš¨ {res['canh_bao']}")
        elif warning_level == 'ORANGE':
            st.warning(f"âš ï¸ {res['canh_bao']}")
        else:
            st.info(f"â„¹ï¸ {res['canh_bao']}")
    
    # Hiá»ƒn thá»‹ phÃ¢n tÃ­ch
    if res.get('ly_do'):
        st.markdown(f"""
        <div class='logic-box'>
            <b>ğŸ§  PHÃ‚N TÃCH ÄA NGUá»’N:</b><br>
            {res['ly_do']}
        </div>
        """, unsafe_allow_html=True)
    
    # Hiá»ƒn thá»‹ 4 sá»‘ chÃ­nh
    st.markdown("<p style='text-align:center; font-size:16px; color:#888;'>ğŸ¯ 4 Sá» CHá»¦ Lá»°C (ÄÃNH CHÃNH)</p>", unsafe_allow_html=True)
    st.markdown(f"<div class='num-display'>{''.join(map(str, res['dan4']))}</div>", unsafe_allow_html=True)
    
    # Hiá»ƒn thá»‹ 3 sá»‘ lÃ³t
    st.markdown("<p style='text-align:center; font-size:16px; color:#888; margin-top:25px;'>ğŸ›¡ï¸ 3 Sá» LÃ“T (ÄÃNH KÃˆM, Báº¢O HIá»‚M)</p>", unsafe_allow_html=True)
    st.markdown(f"<div class='num-display' style='color:#f2cc60; text-shadow: 0 0 25px #f2cc60;'>{''.join(map(str, res['dan3']))}</div>", unsafe_allow_html=True)
    
    # NÃºt copy
    copy_val = "".join(map(str, res['dan4'])) + "".join(map(str, res['dan3']))
    st.text_input("ğŸ“‹ DÃ€N 7 Sá» HOÃ€N CHá»ˆNH:", copy_val, key="final_copy")
    
    # Hiá»ƒn thá»‹ voting weights náº¿u cÃ³
    if res.get('votes'):
        st.markdown("### ğŸ“Š PHÃ‚N Bá» PHIáº¾U Báº¦U Tá»ª CÃC NGUá»’N")
        votes = res['votes']
        max_vote = max(votes.values()) if votes else 1
        for num, vote in sorted(votes.items(), key=lambda x: x[1], reverse=True):
            st.markdown(f"""
            <div>
                Sá»‘ {num}: {vote:.2f}
                <div class='accuracy-meter'>
                    <div class='accuracy-fill' style='width: {(vote/max_vote)*100}%'></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

# Footer
st.markdown("""
<br>
<div style='text-align:center; font-size:12px; color:#444; border-top: 1px solid #30363d; padding-top: 20px;'>
    ğŸ§¬ TITAN v21.0 PRO MAX - Há»‡ thá»‘ng phÃ¢n tÃ­ch Ä‘a nguá»“n thÃ´ng minh<br>
    ğŸ” PhÃ¡t hiá»‡n cáº·p sá»‘ | PhÃ¡t hiá»‡n báº«y | So sÃ¡nh Ä‘a nguá»“n | Auto Crawler | Multi AI
</div>
""", unsafe_allow_html=True)