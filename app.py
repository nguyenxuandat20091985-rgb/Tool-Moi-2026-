import streamlit as st
import collections
import time
import numpy as np
import pandas as pd
from datetime import datetime
import requests
import json
from typing import List, Dict, Tuple, Optional
import hashlib
import random
from scipy import stats
from collections import defaultdict, Counter

# =============== C·∫§U H√åNH API ===============
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")

# =============== THU·∫¨T TO√ÅN CAO C·∫§P N√ÇNG C·∫§P ===============
class LotteryAIAnalyzer:
    def __init__(self):
        self.history = []
        self.patterns = {}
        self.risk_scores = {str(i): 0 for i in range(10)}
        self.weight_matrix = self._initialize_weights()
        
    def _initialize_weights(self):
        """Kh·ªüi t·∫°o ma tr·∫≠n tr·ªçng s·ªë th√¥ng minh"""
        weights = {
            'cold': 2.5,
            'markov_low': 1.8,
            'markov_high': 0.7,
            'hot': -1.5,
            'hour_pattern': -1.0,
            'bong_duong': -0.8,
            'bong_am': -0.6,
            'kep': -0.5,
            'missing_cycle': 2.0,
            'variance': 1.2,
            'frequency_drop': 1.3,
            
            # TH√äM TR·ªåNG S·ªê M·ªöI CHO C√ÅC THU·∫¨T TO√ÅN N√ÇNG C·∫§P
            'entropy': 1.7,
            'kalman': 1.4,
            'wavelet': 1.3,
            'lstm': 2.0,
            'monte_carlo': 1.6,
            'kelly': 0.9,
            'martingale': 0.8,
            'volatility': 1.1,
            'cluster': 1.2,
            'fourier': 1.5,
            'arima': 1.4,
            'rng_detection': 2.2,
            'pattern_recognition': 1.9,
            'ensemble_voting': 2.1,
            'adaboost': 1.8,
            'random_forest': 2.0,
            'gradient_boosting': 2.0,
            'svm': 1.5,
            'neural_network': 2.2,
            'deep_learning': 2.5,
            'reinforcement': 1.7,
            'genetic': 1.6,
            'pso': 1.4,
            'bayesian': 1.9,
            'change_point': 1.3,
            'outlier_detection': 1.5,
            'spectral': 1.4,
            'hurst': 1.2,
            'copula': 1.3,
            'garch': 1.4,
            'dtw': 1.5,
            'hmm': 1.8,
            'threshold': 1.2,
            'cusum': 1.3,
            'bsts': 1.6
        }
        return weights
    
    # =============== THU·∫¨T TO√ÅN G·ªêC (GI·ªÆ NGUY√äN) ===============
    def connect_gemini(self, prompt: str) -> str:
        """K·∫øt n·ªëi v·ªõi Gemini AI ƒë·ªÉ ph√¢n t√≠ch pattern ph·ª©c t·∫°p"""
        try:
            if GEMINI_API_KEY:
                headers = {"Content-Type": "application/json"}
                data = {
                    "contents": [{
                        "parts": [{"text": f"""
                        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch s·ªë h·ªçc cao c·∫•p.
                        Nhi·ªám v·ª•: Ph√¢n t√≠ch chu·ªói s·ªë {prompt}
                        
                        Y√™u c·∫ßu ph√¢n t√≠ch:
                        1. X√°c ƒë·ªãnh 3 s·ªë c√≥ kh·∫£ nƒÉng b·ªã "giam" cao nh·∫•t (s·ªë l√¢u ch∆∞a ra)
                        2. X√°c ƒë·ªãnh 3 s·ªë c√≥ x√°c su·∫•t ra cao nh·∫•t (s·ªë ƒëang trong chu k·ª≥)
                        3. Ph√°t hi·ªán pattern l·∫∑p v√† chu k·ª≥ ƒë·∫∑c bi·ªát
                        4. ƒê·ªÅ xu·∫•t chi·∫øn thu·∫≠t d·ª±a tr√™n ph√¢n t√≠ch
                        
                        Tr·∫£ v·ªÅ k·∫øt qu·∫£ d·∫°ng JSON v·ªõi c√°c tr∆∞·ªùng:
                        - eliminated: [3 s·ªë c·∫ßn lo·∫°i]
                        - top_three: [3 s·ªë n√™n ch·ªçn]
                        - confidence: ƒë·ªô tin c·∫≠y (%)
                        - analysis: ph√¢n t√≠ch ng·∫Øn g·ªçn
                        """}]
                    }]
                }
                response = requests.post(
                    f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={GEMINI_API_KEY}",
                    headers=headers,
                    json=data,
                    timeout=10
                )
                result = response.json()
                return result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
        except Exception as e:
            return f"Gemini connection error: {str(e)}"
        return ""
    
    def analyze_advanced_frequency(self, data: str, window_sizes: List[int] = [10, 20, 30, 50]) -> Dict:
        """Ph√¢n t√≠ch t·∫ßn su·∫•t ƒëa t·∫ßng v·ªõi nhi·ªÅu window size"""
        nums = list(filter(str.isdigit, data))
        
        analysis_results = {}
        
        for window in window_sizes:
            if len(nums) >= window:
                recent_nums = nums[-window:]
                analysis_results[f'window_{window}'] = {
                    'hot': self._find_hot_numbers(recent_nums, threshold=0.15),
                    'cold': self._find_cold_numbers(nums, window),
                    'freq': dict(Counter(recent_nums)),
                    'variance': self._calculate_variance(recent_nums),
                    'trend': self._calculate_trend(recent_nums)
                }
        
        # Ph√¢n t√≠ch Markov n√¢ng cao
        markov_chain = self._calculate_markov_chain_advanced(nums)
        
        # Ph√¢n t√≠ch chu k·ª≥
        cycle_analysis = self._analyze_cycles(nums)
        
        # Ph√¢n ph√¢n ph·ªëi Poisson
        poisson_probs = self._poisson_prediction(nums)
        
        # Ph√¢n t√≠ch t∆∞∆°ng quan
        correlation = self._analyze_correlation(nums)
        
        # Pattern theo th·ªùi gian th·ª±c
        realtime_pattern = self._analyze_realtime_pattern(nums)
        
        return {
            "multi_window": analysis_results,
            "markov": markov_chain,
            "cycles": cycle_analysis,
            "poisson": poisson_probs,
            "correlation": correlation,
            "realtime": realtime_pattern,
            "hour_pattern": self._analyze_by_hour(),
            "weekday_pattern": self._analyze_by_weekday()
        }
    
    def _calculate_markov_chain_advanced(self, nums: List[str], order: int = 3) -> Dict:
        """T√≠nh Markov Chain b·∫≠c cao (t·ªëi ƒëa b·∫≠c 3)"""
        transitions = {}
        
        for o in range(1, order + 1):
            trans = {}
            for i in range(len(nums) - o):
                state = tuple(nums[i:i+o])
                next_state = nums[i+o] if i+o < len(nums) else None
                if next_state:
                    if state not in trans:
                        trans[state] = {}
                    trans[state][next_state] = trans[state].get(next_state, 0) + 1
            
            # Chu·∫©n h√≥a
            for state in trans:
                total = sum(trans[state].values())
                if total > 0:
                    for next_num in trans[state]:
                        trans[state][next_num] = trans[state][next_num] / total
            
            transitions[f'order_{o}'] = trans
        
        return transitions
    
    def _analyze_cycles(self, nums: List[str]) -> Dict:
        """Ph√¢n t√≠ch chu k·ª≥ xu·∫•t hi·ªán c·ªßa c√°c s·ªë"""
        cycles = {}
        
        for num in range(10):
            num_str = str(num)
            positions = [i for i, x in enumerate(nums) if x == num_str]
            
            if len(positions) >= 2:
                gaps = [positions[i] - positions[i-1] for i in range(1, len(positions))]
                cycles[num_str] = {
                    'mean_gap': np.mean(gaps) if gaps else 0,
                    'std_gap': np.std(gaps) if gaps else 0,
                    'last_position': positions[-1],
                    'current_missing': len(nums) - positions[-1] - 1 if positions else 0
                }
            else:
                cycles[num_str] = {
                    'mean_gap': 0,
                    'std_gap': 0,
                    'last_position': -1,
                    'current_missing': len(nums) if num_str not in nums else 0
                }
        
        return cycles
    
    def _poisson_prediction(self, nums: List[str]) -> Dict:
        """D·ª± ƒëo√°n b·∫±ng ph√¢n ph·ªëi Poisson"""
        predictions = {}
        
        for num in range(10):
            num_str = str(num)
            count = nums.count(num_str)
            lambda_param = count / max(len(nums), 1) * 10  # Expected per 10 draws
            
            # X√°c su·∫•t xu·∫•t hi·ªán trong 5 k·ª≥ t·ªõi
            prob_next_5 = 1 - np.exp(-lambda_param * 5)
            predictions[num_str] = {
                'lambda': lambda_param,
                'prob_next': prob_next_5,
                'confidence': min(prob_next_5 * 100, 95)
            }
        
        return predictions
    
    def _analyze_correlation(self, nums: List[str]) -> Dict:
        """Ph√¢n t√≠ch t∆∞∆°ng quan gi·ªØa c√°c s·ªë"""
        correlation_matrix = np.zeros((10, 10))
        
        # ƒê·∫øm t·∫ßn su·∫•t xu·∫•t hi·ªán c√πng nhau
        for i in range(len(nums) - 1):
            current = int(nums[i])
            next_num = int(nums[i + 1])
            correlation_matrix[current][next_num] += 1
        
        # Chu·∫©n h√≥a
        row_sums = correlation_matrix.sum(axis=1, keepdims=True)
        row_sums[row_sums == 0] = 1
        correlation_matrix = correlation_matrix / row_sums
        
        return {
            'matrix': correlation_matrix,
            'pairs': self._find_strong_correlations(correlation_matrix)
        }
    
    def _find_strong_correlations(self, matrix: np.ndarray, threshold: float = 0.15) -> List[Tuple]:
        """T√¨m c·∫∑p s·ªë c√≥ t∆∞∆°ng quan m·∫°nh"""
        pairs = []
        for i in range(10):
            for j in range(10):
                if i != j and matrix[i][j] > threshold:
                    pairs.append((str(i), str(j), matrix[i][j]))
        return sorted(pairs, key=lambda x: x[2], reverse=True)[:10]
    
    def _calculate_variance(self, nums: List[str]) -> float:
        """T√≠nh ƒë·ªô bi·∫øn ƒë·ªông c·ªßa chu·ªói s·ªë"""
        int_nums = [int(n) for n in nums]
        return np.var(int_nums) if len(int_nums) > 1 else 0
    
    def _calculate_trend(self, nums: List[str]) -> str:
        """Ph√¢n t√≠ch xu h∆∞·ªõng"""
        if len(nums) < 5:
            return "Kh√¥ng ƒë·ªß d·ªØ li·ªáu"
        
        recent = [int(n) for n in nums[-5:]]
        if recent[-1] > recent[0]:
            return "TƒÉng"
        elif recent[-1] < recent[0]:
            return "Gi·∫£m"
        else:
            return "ƒêi ngang"
    
    def _analyze_realtime_pattern(self, nums: List[str]) -> Dict:
        """Ph√¢n t√≠ch pattern theo th·ªùi gian th·ª±c"""
        pattern = {
            'last_digit': nums[-1] if nums else '0',
            'last_two': ''.join(nums[-2:]) if len(nums) >= 2 else '00',
            'last_three': ''.join(nums[-3:]) if len(nums) >= 3 else '000',
            'even_odd_ratio': self._calculate_even_odd_ratio(nums[-10:]) if len(nums) >= 10 else 0,
            'big_small_ratio': self._calculate_big_small_ratio(nums[-10:]) if len(nums) >= 10 else 0
        }
        return pattern
    
    def _calculate_even_odd_ratio(self, nums: List[str]) -> float:
        """T√≠nh t·ª∑ l·ªá ch·∫µn/l·∫ª"""
        even = sum(1 for n in nums if int(n) % 2 == 0)
        odd = len(nums) - even
        return even / odd if odd > 0 else 0
    
    def _calculate_big_small_ratio(self, nums: List[str]) -> float:
        """T√≠nh t·ª∑ l·ªá l·ªõn/nh·ªè (l·ªõn >=5, nh·ªè <5)"""
        big = sum(1 for n in nums if int(n) >= 5)
        small = len(nums) - big
        return big / small if small > 0 else 0
    
    def _analyze_by_hour(self) -> List[str]:
        """Ph√¢n t√≠ch pattern theo gi·ªù trong ng√†y"""
        current_hour = datetime.now().hour
        
        # Pattern ƒë·ªông d·ª±a tr√™n l·ªãch s·ª≠
        if 5 <= current_hour < 12:
            return ["1", "3", "5", "7", "9"]  # S√°ng: ∆∞u ti√™n s·ªë l·∫ª
        elif 12 <= current_hour < 18:
            return ["0", "2", "4", "6", "8"]  # Chi·ªÅu: ∆∞u ti√™n s·ªë ch·∫µn
        elif 18 <= current_hour < 22:
            return ["5", "6", "7", "8", "9"]  # T·ªëi: ∆∞u ti√™n s·ªë l·ªõn
        else:
            return ["0", "1", "2", "3", "4"]  # ƒê√™m: ∆∞u ti√™n s·ªë nh·ªè
    
    def _analyze_by_weekday(self) -> List[str]:
        """Ph√¢n t√≠ch pattern theo ng√†y trong tu·∫ßn"""
        weekday = datetime.now().weekday()
        
        # Th·ª© 2-6: pattern kh√°c nhau
        patterns = {
            0: ["0", "2", "4", "6", "8"],  # Th·ª© 2
            1: ["1", "3", "5", "7", "9"],  # Th·ª© 3
            2: ["0", "3", "6", "9", "2"],  # Th·ª© 4
            3: ["1", "4", "7", "0", "5"],  # Th·ª© 5
            4: ["2", "5", "8", "1", "6"],  # Th·ª© 6
            5: ["3", "6", "9", "2", "7"],  # Th·ª© 7
            6: ["4", "7", "0", "3", "8"]   # Ch·ªß nh·∫≠t
        }
        
        return patterns.get(weekday, ["0", "1", "2", "3", "4"])
    
    def _find_hot_numbers(self, recent_nums: List[str], threshold: float = 0.12) -> List[str]:
        """T√¨m s·ªë n√≥ng v·ªõi ng∆∞·ª°ng th√≠ch ·ª©ng"""
        if not recent_nums:
            return []
        
        counts = Counter(recent_nums)
        total = len(recent_nums)
        
        # Ng∆∞·ª°ng ƒë·ªông d·ª±a tr√™n ƒë·ªô d√†i d·ªØ li·ªáu
        adaptive_threshold = threshold * (1 + np.log10(total) / 10)
        
        return [num for num, count in counts.items() if count/total >= adaptive_threshold]
    
    def _find_cold_numbers(self, nums: List[str], window_size: int) -> List[str]:
        """T√¨m s·ªë l·∫°nh v·ªõi ph√¢n t√≠ch chu k·ª≥"""
        if len(nums) < window_size:
            return []
        
        recent_set = set(nums[-window_size:])
        all_nums = set(str(i) for i in range(10))
        cold_nums = list(all_nums - recent_set)
        
        return cold_nums
    
    def eliminate_risk_numbers(self, data: str) -> Tuple[List[str], List[str], Dict]:
        """Lo·∫°i 3 s·ªë r·ªßi ro v·ªõi thu·∫≠t to√°n ƒëa t·∫ßng - S·ª¨A L·ªñI"""
        nums = list(filter(str.isdigit, data))
        
        # TH√äM: Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
        if len(nums) < 10:
            return [], [str(i) for i in range(10)], {}
        
        try:
            # Ph√¢n t√≠ch ƒëa chi·ªÅu
            analysis = self.analyze_advanced_frequency(data)
            
            # T√≠nh ƒëi·ªÉm r·ªßi ro v·ªõi tr·ªçng s·ªë th√¥ng minh
            risk_scores = {str(i): 0.0 for i in range(10)}
            
            # 1. PH√ÇN T√çCH S·ªê L·∫†NH - TR·ªåNG S·ªê CAO
            if 'multi_window' in analysis and 'window_20' in analysis['multi_window']:
                for num in analysis['multi_window']['window_20'].get('cold', []):
                    risk_scores[num] += self.weight_matrix['cold']
            
            # 2. PH√ÇN T√çCH MARKOV
            if len(nums) >= 2:
                last_states = [
                    tuple(nums[-2:]) if len(nums) >= 2 else None,
                    tuple(nums[-3:]) if len(nums) >= 3 else None
                ]
                
                for i, state in enumerate(last_states):
                    if state and state in analysis.get('markov', {}).get(f'order_{i+1}', {}):
                        for num, prob in analysis['markov'][f'order_{i+1}'][state].items():
                            if prob < 0.03:  # X√°c su·∫•t r·∫•t th·∫•p
                                risk_scores[num] += self.weight_matrix['markov_low'] * (i + 1)
                            elif prob > 0.2:  # X√°c su·∫•t cao
                                risk_scores[num] -= self.weight_matrix['markov_high'] * (i + 1)
            
            # 3. PH√ÇN T√çCH CHU K·ª≤
            for num, cycle_info in analysis.get('cycles', {}).items():
                if cycle_info['current_missing'] > 30:
                    risk_scores[num] += self.weight_matrix['missing_cycle'] * 1.5
                elif cycle_info['current_missing'] > 20:
                    risk_scores[num] += self.weight_matrix['missing_cycle']
                elif cycle_info['current_missing'] > 10:
                    risk_scores[num] += self.weight_matrix['missing_cycle'] * 0.5
            
            # 4. PH√ÇN T√çCH POISSON
            for num, poisson_info in analysis.get('poisson', {}).items():
                if poisson_info['prob_next'] < 0.1:
                    risk_scores[num] += 1.0
                elif poisson_info['prob_next'] > 0.3:
                    risk_scores[num] -= 0.8
            
            # 5. S·ªê N√ìNG - GI·∫¢M ƒêI·ªÇM R·ª¶I RO
            for window_data in analysis.get('multi_window', {}).values():
                for num in window_data.get('hot', []):
                    risk_scores[num] = max(0, risk_scores[num] - self.weight_matrix['hot'])
            
            # 6. PATTERN TH·ªúI GIAN
            for num in analysis.get('hour_pattern', []):
                risk_scores[num] = max(0, risk_scores[num] - self.weight_matrix['hour_pattern'])
            
            for num in analysis.get('weekday_pattern', []):
                risk_scores[num] = max(0, risk_scores[num] - 0.3)
            
            # 7. PH√ÇN T√çCH ƒê·ªò BI·∫æN ƒê·ªòNG
            variance = self._calculate_variance(nums[-20:]) if len(nums) >= 20 else 0
            if variance > 8:  # Bi·∫øn ƒë·ªông cao
                for num in risk_scores:
                    risk_scores[num] += self.weight_matrix['variance'] * 0.5
            
            # 8. PH√ÇN T√çCH T∆Ø∆†NG QUAN
            for pair in analysis.get('correlation', {}).get('pairs', [])[:5]:
                risk_scores[pair[1]] -= 0.3  # S·ªë c√≥ t∆∞∆°ng quan cao gi·∫£m r·ªßi ro
            
            # L·∫•y 3 s·ªë c√≥ ƒëi·ªÉm r·ªßi ro cao nh·∫•t
            eliminated = sorted(risk_scores.items(), key=lambda x: x[1], reverse=True)[:3]
            eliminated_nums = [num for num, score in eliminated]
            
            # 7 s·ªë c√≤n l·∫°i
            remaining = [str(i) for i in range(10) if str(i) not in eliminated_nums]
            
            return eliminated_nums, remaining, analysis
            
        except Exception as e:
            # TH√äM: X·ª≠ l√Ω l·ªói, tr·∫£ v·ªÅ gi√° tr·ªã m·∫∑c ƒë·ªãnh
            print(f"L·ªói trong eliminate_risk_numbers: {str(e)}")
            return [], [str(i) for i in range(10)], {}
    
    def select_top_three(self, remaining_nums: List[str], data: str, analysis: Dict = None) -> List[str]:
        """Ch·ªçn 3 s·ªë v·ªõi thu·∫≠t to√°n d·ª± ƒëo√°n ƒëa t·∫ßng - S·ª¨A L·ªñI"""
        nums = list(filter(str.isdigit, data))
        
        # TH√äM: Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
        if not remaining_nums or len(remaining_nums) < 3:
            return ["0", "1", "2"]
        
        if not nums:
            return remaining_nums[:3]
        
        try:
            # T√≠nh ƒëi·ªÉm cho t·ª´ng s·ªë c√≤n l·∫°i
            scores = {num: 0.0 for num in remaining_nums}
            
            last_num = nums[-1] if nums else "0"
            
            # 1. B√ìNG D∆Ø∆†NG - √ÇM
            bong_duong = {"0": "5", "1": "6", "2": "7", "3": "8", "4": "9",
                          "5": "0", "6": "1", "7": "2", "8": "3", "9": "4"}
            bong_am = {"0": "7", "1": "4", "2": "9", "3": "6", "4": "1",
                       "5": "8", "6": "3", "7": "0", "8": "5", "9": "2"}
            
            if bong_duong.get(last_num) in remaining_nums:
                scores[bong_duong[last_num]] += 3.0
            
            if bong_am.get(last_num) in remaining_nums:
                scores[bong_am[last_num]] += 2.5
            
            # 2. S·ªê LI·ªÄN K·ªÄ
            next_num = str((int(last_num) + 1) % 10)
            prev_num = str((int(last_num) - 1) % 10)
            
            if next_num in remaining_nums:
                scores[next_num] += 2.0
            if prev_num in remaining_nums:
                scores[prev_num] += 1.8
            
            # 3. S·ªê K·∫∏P
            if len(nums) >= 2:
                k·∫πp_s·ªë = str((int(nums[-2]) + int(nums[-1])) % 10)
                if k·∫πp_s·ªë in remaining_nums:
                    scores[k·∫πp_s·ªë] += 1.5
            
            # 4. T·∫¶N SU·∫§T CAO
            if len(nums) >= 10:
                recent_counts = Counter(nums[-10:])
                for num, count in recent_counts.most_common():
                    if num in remaining_nums:
                        scores[num] += count * 0.3
            
            # 5. PH√ÇN T√çCH MARKOV
            if analysis and 'markov' in analysis and len(nums) >= 2:
                last_state = tuple(nums[-2:]) if len(nums) >= 2 else None
                if last_state and last_state in analysis['markov'].get('order_2', {}):
                    for num, prob in analysis['markov']['order_2'][last_state].items():
                        if num in remaining_nums:
                            scores[num] += prob * 5
            
            # 6. PH√ÇN T√çCH POISSON
            if analysis and 'poisson' in analysis:
                for num in remaining_nums:
                    scores[num] += analysis['poisson'].get(num, {}).get('prob_next', 0) * 3
            
            # 7. PATTERN TH·ªúI GIAN
            if analysis:
                if last_num in analysis.get('hour_pattern', []):
                    for num in analysis['hour_pattern']:
                        if num in remaining_nums:
                            scores[num] += 0.5
                
                if last_num in analysis.get('weekday_pattern', []):
                    for num in analysis['weekday_pattern']:
                        if num in remaining_nums:
                            scores[num] += 0.3
            
            # 8. T∆Ø∆†NG QUAN M·∫†NH
            if analysis and 'correlation' in analysis:
                for pair in analysis['correlation'].get('pairs', [])[:3]:
                    if len(pair) >= 2 and pair[0] == last_num and pair[1] in remaining_nums:
                        scores[pair[1]] += pair[2] * 3
            
            # TH√äM: C√°c thu·∫≠t to√°n n√¢ng cao (b·ªçc trong try-catch ƒë·ªÉ tr√°nh l·ªói)
            
            # 9. KALMAN FILTER
            try:
                kalman_result = self.kalman_filter_prediction(nums)
                if kalman_result and str(kalman_result.get('prediction', '')) in remaining_nums:
                    scores[str(kalman_result['prediction'])] += self.weight_matrix.get('kalman', 1.4) * 2
            except:
                pass
            
            # 10. WAVELET
            try:
                wavelet_result = self.wavelet_decomposition(nums)
                if wavelet_result and str(wavelet_result.get('prediction', '')) in remaining_nums:
                    scores[str(wavelet_result['prediction'])] += self.weight_matrix.get('wavelet', 1.3) * 2
            except:
                pass
            
            # 11. ENSEMBLE VOTING
            try:
                ensemble_result = self.ensemble_voting_advanced(nums)
                if ensemble_result and 'predictions' in ensemble_result:
                    for i, pred in enumerate(ensemble_result['predictions'][:2]):
                        if pred in remaining_nums:
                            scores[pred] += self.weight_matrix.get('ensemble_voting', 2.1) * (1.5 - i * 0.3)
            except:
                pass
            
            # 12. LSTM
            try:
                lstm_result = self.lstm_enhanced_prediction(nums)
                if lstm_result and 'predictions' in lstm_result:
                    for i, pred in enumerate(lstm_result['predictions'][:2]):
                        if pred in remaining_nums:
                            scores[pred] += self.weight_matrix.get('lstm', 2.0) * (2.0 - i * 0.5)
            except:
                pass
            
            # 13. MONTE CARLO
            try:
                mc_result = self.monte_carlo_advanced(nums)
                if mc_result and 'predictions' in mc_result:
                    step1_preds = mc_result['predictions'].get('step_1', {}).get('top_3', [])
                    for i, pred in enumerate(step1_preds[:2]):
                        if pred in remaining_nums:
                            scores[pred] += self.weight_matrix.get('monte_carlo', 1.6) * (1.8 - i * 0.4)
            except:
                pass
            
            # S·∫Øp x·∫øp theo ƒëi·ªÉm s·ªë
            sorted_nums = sorted(scores.items(), key=lambda x: x[1], reverse=True)
            
            # L·∫•y top 3
            top_three = [num for num, score in sorted_nums[:3]]
            
            # N·∫øu ch∆∞a ƒë·ªß 3, b·ªï sung
            while len(top_three) < 3:
                for num in remaining_nums:
                    if num not in top_three:
                        top_three.append(num)
                    if len(top_three) >= 3:
                        break
            
            return top_three[:3]
            
        except Exception as e:
            # TH√äM: X·ª≠ l√Ω l·ªói, tr·∫£ v·ªÅ gi√° tr·ªã m·∫∑c ƒë·ªãnh
            print(f"L·ªói trong select_top_three: {str(e)}")
            return remaining_nums[:3] if len(remaining_nums) >= 3 else remaining_nums + ["0", "1", "2"][:3-len(remaining_nums)]
    
    # =============== 1. THU·∫¨T TO√ÅN ENTROPY & INFORMATION THEORY (TH√äM M·ªöI) ===============
    def analyze_entropy_multiscale(self, nums: List[str], scales: List[int] = [1, 2, 3, 5]) -> Dict:
        """TH√äM: Ph√¢n t√≠ch Entropy ƒëa t·ª∑ l·ªá - ƒêo ƒë·ªô h·ªón lo·∫°n c·ªßa chu·ªói s·ªë"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < 10:
            return {}
        
        entropy_results = {}
        
        for scale in scales:
            try:
                scaled_series = []
                for i in range(0, len(int_nums) - scale + 1, scale):
                    scaled_series.append(np.mean(int_nums[i:i+scale]))
                
                # T√≠nh entropy cho chu·ªói ƒë√£ ƒë∆∞·ª£c scale
                hist, _ = np.histogram(scaled_series, bins=10)
                probs = hist / len(scaled_series)
                entropy = -np.sum(p * np.log2(p) for p in probs if p > 0)
                
                entropy_results[f'scale_{scale}'] = {
                    'entropy': entropy,
                    'randomness': entropy / np.log2(10),
                    'complexity': entropy * scale,
                    'prediction_difficulty': 'Cao' if entropy > 2.5 else 'Trung b√¨nh' if entropy > 1.5 else 'Th·∫•p'
                }
            except:
                pass
        
        return entropy_results
    
    # =============== 2. THU·∫¨T TO√ÅN KALMAN & WAVELET (TH√äM M·ªöI) ===============
    def kalman_filter_prediction(self, nums: List[str]) -> Dict:
        """TH√äM: D·ª± ƒëo√°n b·∫±ng b·ªô l·ªçc Kalman"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < 5:
            return {}
        
        try:
            # Kh·ªüi t·∫°o Kalman filter
            x_est = int_nums[0]  # ∆∞·ªõc l∆∞·ª£ng ban ƒë·∫ßu
            p_est = 1.0  # ∆∞·ªõc l∆∞·ª£ng sai s·ªë ban ƒë·∫ßu
            q = 0.01  # nhi·ªÖu qu√° tr√¨nh
            r = 0.1   # nhi·ªÖu ƒëo l∆∞·ªùng
            
            estimates = [x_est]
            
            for z in int_nums[1:]:
                # D·ª± ƒëo√°n
                x_pred = x_est
                p_pred = p_est + q
                
                # C·∫≠p nh·∫≠t
                k = p_pred / (p_pred + r) if (p_pred + r) > 0 else 0
                x_est = x_pred + k * (z - x_pred)
                p_est = (1 - k) * p_pred
                
                estimates.append(x_est)
            
            # D·ª± ƒëo√°n gi√° tr·ªã ti·∫øp theo
            next_prediction = x_est
            confidence = 1 - (p_est / (p_est + r)) if (p_est + r) > 0 else 0.5
            
            return {
                'prediction': int(round(next_prediction)) % 10,
                'confidence': min(confidence * 100, 95),
                'estimates': estimates[-5:],
                'uncertainty': p_est
            }
        except:
            return {}
    
    def wavelet_decomposition(self, nums: List[str], levels: int = 3) -> Dict:
        """TH√äM: Ph√¢n t√≠ch Wavelet ƒë·ªÉ ph√°t hi·ªán xu h∆∞·ªõng"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < 5:
            return {}
        
        try:
            # Moving average nh∆∞ wavelet approximation
            window = min(5, len(int_nums))
            weights = np.ones(window) / window
            smoothed = np.convolve(int_nums, weights, mode='valid')
            
            if len(smoothed) < 2:
                return {'prediction': int_nums[-1] % 10, 'confidence': 50}
            
            detail = int_nums[window-1:len(smoothed)] - smoothed[:len(int_nums[window-1:len(smoothed)])]
            
            return {
                'energy_ratios': [np.var(smoothed) if len(smoothed) > 0 else 0, 
                                 np.var(detail) if len(detail) > 0 else 0],
                'trend': 'TƒÉng' if smoothed[-1] > smoothed[-2] else 'Gi·∫£m',
                'prediction': int(round(smoothed[-1])) % 10,
                'confidence': 70
            }
        except:
            return {'prediction': int_nums[-1] % 10, 'confidence': 50}
    
    # =============== 3. THU·∫¨T TO√ÅN LSTM & DEEP LEARNING (TH√äM M·ªöI) ===============
    def lstm_enhanced_prediction(self, nums: List[str], lookback: int = 10) -> Dict:
        """TH√äM: LSTM n√¢ng cao v·ªõi attention mechanism (phi√™n b·∫£n ƒë∆°n gi·∫£n)"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < lookback:
            return self._lstm_simple(int_nums, lookback)
        
        try:
            # Exponential weighted moving average
            weights = np.exp(np.linspace(0, 2, min(lookback, len(int_nums))))
            weights = weights / weights.sum()
            
            last_sequence = int_nums[-min(lookback, len(int_nums)):]
            prediction = np.average(last_sequence, weights=weights[-len(last_sequence):])
            
            # T√≠nh confidence d·ª±a tr√™n ƒë·ªô ·ªïn ƒë·ªãnh
            volatility = np.std(last_sequence) if len(last_sequence) > 1 else 0
            confidence = max(0, 100 - volatility * 10)
            
            # T·∫°o top 3 predictions
            pred_int = int(round(prediction)) % 10
            neighbors = [(pred_int + i) % 10 for i in [0, 1, -1]]
            
            return {
                'predictions': [str(p) for p in neighbors[:3]],
                'probabilities': [0.5, 0.3, 0.2],
                'confidence': min(confidence, 85),
                'loss': 0.5
            }
        except:
            return self._lstm_simple(int_nums, lookback)
    
    def _lstm_simple(self, nums: List[int], lookback: int) -> Dict:
        """TH√äM: LSTM ƒë∆°n gi·∫£n"""
        if not nums:
            return {'predictions': ['0'], 'confidence': 50}
        
        try:
            weights = np.exp(np.linspace(0, 2, min(lookback, len(nums))))
            weights = weights / weights.sum()
            
            last_sequence = nums[-min(lookback, len(nums)):]
            prediction = np.average(last_sequence, weights=weights[-len(last_sequence):])
            
            pred_int = int(round(prediction)) % 10
            neighbors = [str((pred_int + i) % 10) for i in [0, 1, -1]]
            
            return {
                'predictions': neighbors[:3],
                'probabilities': [0.4, 0.3, 0.3],
                'confidence': 60,
                'loss': 0.6
            }
        except:
            return {'predictions': [str(nums[-1] % 10)], 'confidence': 50}
    
    # =============== 4. THU·∫¨T TO√ÅN MONTE CARLO & SIMULATION (TH√äM M·ªöI) ===============
    def monte_carlo_advanced(self, nums: List[str], n_simulations: int = 1000) -> Dict:
        """TH√äM: Monte Carlo v·ªõi ph√¢n ph·ªëi x√°c su·∫•t ƒë·ªông"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < 20:
            return {}
        
        try:
            # X√¢y d·ª±ng ph√¢n ph·ªëi x√°c su·∫•t t·ª´ d·ªØ li·ªáu l·ªãch s·ª≠
            probs = np.zeros(10)
            for i in range(10):
                probs[i] = int_nums.count(i) / len(int_nums)
            
            # Th√™m nhi·ªÖu Bayesian
            alpha = 1.0
            probs = (probs * len(int_nums) + alpha) / (len(int_nums) + 10 * alpha)
            
            # Monte Carlo simulation
            simulations = np.random.choice(10, size=(n_simulations, 5), p=probs)
            
            # Ph√¢n t√≠ch k·∫øt qu·∫£
            results = {}
            for i in range(min(5, simulations.shape[1])):
                step_results = simulations[:, i]
                unique, counts = np.unique(step_results, return_counts=True)
                probs_step = counts / n_simulations
                
                top_3_idx = np.argsort(probs_step)[-3:][::-1]
                results[f'step_{i+1}'] = {
                    'top_3': [str(unique[idx]) for idx in top_3_idx],
                    'probabilities': [float(probs_step[idx]) for idx in top_3_idx],
                    'entropy': -np.sum(probs_step * np.log2(probs_step + 1e-10))
                }
            
            return {
                'predictions': results,
                'expected_value': float(simulations.mean()),
                'confidence': 75
            }
        except:
            return {}
    
    # =============== 9. THU·∫¨T TO√ÅN ENSEMBLE VOTING N√ÇNG CAO (TH√äM M·ªöI) ===============
    def ensemble_voting_advanced(self, nums: List[str]) -> Dict:
        """TH√äM: Ensemble voting v·ªõi nhi·ªÅu thu·∫≠t to√°n"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < 10:
            return {}
        
        try:
            predictions = []
            weights = []
            
            # 1. Markov Chain prediction
            markov_pred = self.markov_predict_simple(nums)
            if markov_pred:
                predictions.append(int(markov_pred))
                weights.append(1.5)
            
            # 2. Kalman Filter prediction
            kalman_result = self.kalman_filter_prediction(nums)
            if kalman_result and 'prediction' in kalman_result:
                predictions.append(kalman_result['prediction'])
                weights.append(1.3)
            
            # 3. LSTM prediction
            lstm_result = self.lstm_enhanced_prediction(nums)
            if lstm_result and 'predictions' in lstm_result and lstm_result['predictions']:
                predictions.append(int(lstm_result['predictions'][0]))
                weights.append(2.0)
            
            # 4. Wavelet prediction
            wavelet_result = self.wavelet_decomposition(nums)
            if wavelet_result and 'prediction' in wavelet_result:
                predictions.append(wavelet_result['prediction'])
                weights.append(1.2)
            
            if not predictions:
                return {}
            
            # Weighted voting
            weighted_votes = defaultdict(float)
            for pred, weight in zip(predictions, weights):
                weighted_votes[pred % 10] += weight
            
            # Top predictions
            top_predictions = sorted(weighted_votes.items(), key=lambda x: x[1], reverse=True)[:3]
            
            return {
                'predictions': [str(p[0]) for p in top_predictions],
                'probabilities': [p[1] / sum(weighted_votes.values()) for p in top_predictions],
                'weights': weights[:len(top_predictions)],
                'n_models': len(predictions),
                'confidence': min(top_predictions[0][1] / sum(weighted_votes.values()) * 100 + 30, 95),
                'method': 'weighted_ensemble'
            }
        except:
            return {}
    
    def markov_predict_simple(self, nums: List[str]) -> Optional[str]:
        """Helper: Markov prediction ƒë∆°n gi·∫£n"""
        if len(nums) < 2:
            return None
        
        try:
            transitions = {}
            for i in range(len(nums) - 1):
                current = nums[i]
                next_num = nums[i + 1]
                if current not in transitions:
                    transitions[current] = []
                transitions[current].append(next_num)
            
            last_num = nums[-1]
            if last_num in transitions and transitions[last_num]:
                next_predictions = Counter(transitions[last_num])
                return next_predictions.most_common(1)[0][0]
        except:
            pass
        
        return None
    
    # =============== 17. THU·∫¨T TO√ÅN PSO (Particle Swarm Optimization) (TH√äM M·ªöI) ===============
    def pso_optimization(self, nums: List[str]) -> Dict:
        """TH√äM: T·ªëi ∆∞u h√≥a b·∫ßy ƒë√†n PSO (phi√™n b·∫£n ƒë∆°n gi·∫£n)"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < 20:
            return {}
        
        try:
            n_particles = 20
            n_iterations = 20
            
            # Particle position: weights for prediction
            particles = np.random.rand(n_particles, 5)
            particles = particles / particles.sum(axis=1, keepdims=True)
            
            velocities = np.random.randn(n_particles, 5) * 0.1
            
            personal_best_pos = particles.copy()
            personal_best_score = np.zeros(n_particles)
            global_best_pos = particles[0].copy()
            global_best_score = 0
            
            def fitness(weights):
                """Evaluate prediction accuracy with weights"""
                if len(int_nums) < 6:
                    return 0
                predictions = []
                for i in range(len(int_nums) - 5):
                    pattern = int_nums[i:i+5]
                    pred = int(np.average(pattern, weights=weights[:len(pattern)]))
                    actual = int_nums[i+5]
                    predictions.append(1 if pred % 10 == actual % 10 else 0)
                return np.mean(predictions) if predictions else 0
            
            # Initialize personal best scores
            for i in range(n_particles):
                personal_best_score[i] = fitness(particles[i])
                if personal_best_score[i] > global_best_score:
                    global_best_score = personal_best_score[i]
                    global_best_pos = particles[i].copy()
            
            # PSO iterations
            w = 0.7  # inertia
            c1 = 1.5  # cognitive
            c2 = 1.5  # social
            
            for _ in range(n_iterations):
                for i in range(n_particles):
                    # Update velocity
                    r1, r2 = np.random.rand(2)
                    velocities[i] = (w * velocities[i] + 
                                   c1 * r1 * (personal_best_pos[i] - particles[i]) +
                                   c2 * r2 * (global_best_pos - particles[i]))
                    
                    # Update position
                    particles[i] = particles[i] + velocities[i]
                    particles[i] = np.maximum(particles[i], 0)
                    particles[i] = particles[i] / (particles[i].sum() + 1e-6)
                    
                    # Evaluate
                    score = fitness(particles[i])
                    
                    # Update personal best
                    if score > personal_best_score[i]:
                        personal_best_score[i] = score
                        personal_best_pos[i] = particles[i].copy()
                    
                    # Update global best
                    if score > global_best_score:
                        global_best_score = score
                        global_best_pos = particles[i].copy()
            
            # D·ª± ƒëo√°n v·ªõi optimal weights
            if len(int_nums) >= 5:
                last_pattern = int_nums[-5:]
                prediction = int(np.average(last_pattern, weights=global_best_pos[:5])) % 10
            else:
                prediction = int_nums[-1] % 10
            
            return {
                'optimal_weights': [float(w) for w in global_best_pos],
                'fitness_score': float(global_best_score * 100),
                'prediction': str(prediction),
                'confidence': float(global_best_score * 100),
                'method': 'pso'
            }
        except:
            return {}
    
    # =============== 18. THU·∫¨T TO√ÅN HURST EXPONENT (TH√äM M·ªöI) ===============
    def hurst_exponent_analysis(self, nums: List[str]) -> Dict:
        """TH√äM: Ph√¢n t√≠ch Hurst exponent - ƒêo t√≠nh fractal c·ªßa chu·ªói"""
        int_nums = [int(n) for n in nums if n.isdigit()]
        if len(int_nums) < 50:
            return {}
        
        try:
            def _hurst(ts):
                lags = range(2, min(len(ts) // 2, 20))
                tau = []
                lagvec = []
                
                for lag in lags:
                    if lag < len(ts):
                        pp = np.subtract(ts[lag:], ts[:-lag])
                        tau.append(np.std(pp))
                        lagvec.append(lag)
                
                if len(tau) > 1 and len(lagvec) > 1:
                    m = np.polyfit(np.log(lagvec), np.log(tau), 1)
                    return m[0]
                return 0.5
            
            # T√≠nh Hurst exponent
            h = _hurst(int_nums[-200:]) if len(int_nums) >= 200 else _hurst(int_nums)
            
            return {
                'hurst': h,
                'type': 'Persistent' if h > 0.5 else 'Anti-persistent' if h < 0.5 else 'Random',
                'predictability': 'Cao' if h > 0.65 else 'Trung b√¨nh' if h > 0.45 else 'Th·∫•p',
                'fractal_dimension': 2 - h
            }
        except:
            return {}

# =============== GIAO DI·ªÜN RESPONSIVE (GI·ªÆ NGUY√äN 100%) ===============
st.set_page_config(
    page_title="üéØ AI 3-TINH ELITE PRO V2.0",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS RESPONSIVE T·ªêI ∆ØU - GI·ªÆ NGUY√äN 100%
st.markdown("""
<style>
    /* RESET & VARIABLES */
    :root {
        --primary: #00ffcc;
        --secondary: #00ccff;
        --success: #10b981;
        --danger: #ef4444;
        --warning: #f59e0b;
        --dark: #0f172a;
        --darker: #0b0f13;
        --light: #e2e8f0;
        --border: 2px solid #334155;
        --border-radius: 16px;
        --shadow: 0 8px 32px rgba(0, 255, 204, 0.15);
    }

    /* BASE */
    .stApp {
        background: linear-gradient(135deg, var(--darker) 0%, var(--dark) 100%) !important;
        color: var(--light);
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    }

    /* TYPOGRAPHY RESPONSIVE */
    .main-title {
        text-align: center;
        background: linear-gradient(135deg, var(--primary), var(--secondary));
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: clamp(1.8rem, 5vw, 2.8rem);
        font-weight: 800;
        margin-bottom: 0.5rem;
        padding: 0.5rem;
        text-shadow: 0 0 20px rgba(0, 255, 204, 0.3);
    }

    .subtitle {
        text-align: center;
        color: #94a3b8;
        font-size: clamp(0.9rem, 3vw, 1.1rem);
        margin-bottom: 1.5rem;
    }

    /* HEADER CARD */
    .header-card {
        background: linear-gradient(145deg, rgba(30, 41, 59, 0.8), rgba(15, 23, 42, 0.9));
        border: 1px solid rgba(0, 255, 204, 0.2);
        border-radius: var(--border-radius);
        padding: 1.5rem;
        margin-bottom: 1.5rem;
        backdrop-filter: blur(10px);
        box-shadow: var(--shadow);
    }

    /* RESULT CARD - RESPONSIVE */
    .result-card {
        background: linear-gradient(145deg, #1e293b, #0f172a);
        border: 2px solid var(--primary);
        border-radius: 24px;
        padding: clamp(1rem, 4vw, 2rem);
        margin: 1.5rem 0;
        box-shadow: 0 0 30px rgba(0, 255, 204, 0.2);
        position: relative;
        overflow: hidden;
    }

    .result-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 4px;
        background: linear-gradient(90deg, var(--primary), var(--secondary));
    }

    /* NUMBERS DISPLAY - FLEXIBLE */
    .numbers-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: clamp(1rem, 5vw, 2rem);
        padding: 1rem;
        max-width: 600px;
        margin: 0 auto;
    }

    .number-circle {
        aspect-ratio: 1;
        width: 100%;
        max-width: 120px;
        margin: 0 auto;
        background: linear-gradient(135deg, var(--warning), #f97316);
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: clamp(2rem, 8vw, 3.5rem);
        font-weight: 900;
        color: var(--dark);
        box-shadow: 0 0 40px rgba(245, 158, 11, 0.5);
        animation: pulse 2s infinite;
        transition: transform 0.3s;
    }

    .number-circle:hover {
        transform: scale(1.05);
    }

    @keyframes pulse {
        0% { box-shadow: 0 0 20px rgba(245, 158, 11, 0.5); }
        50% { box-shadow: 0 0 50px rgba(245, 158, 11, 0.8); }
        100% { box-shadow: 0 0 20px rgba(245, 158, 11, 0.5); }
    }

    /* INFO BOXES - FLEXIBLE */
    .info-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 1rem;
        margin-top: 1.5rem;
    }

    .info-box {
        background: rgba(30, 41, 59, 0.7);
        border-radius: 16px;
        padding: 1.25rem;
        border-left: 6px solid;
        backdrop-filter: blur(5px);
    }

    .eliminated-box {
        border-left-color: var(--danger);
        background: rgba(239, 68, 68, 0.1);
    }

    .safe-box {
        border-left-color: var(--success);
        background: rgba(16, 185, 129, 0.1);
    }

    .strategy-box {
        border-left-color: var(--secondary);
        background: rgba(0, 204, 255, 0.1);
    }

    .info-title {
        font-weight: 700;
        font-size: 1.1rem;
        margin-bottom: 0.75rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }

    .info-numbers {
        font-size: clamp(1.2rem, 4vw, 1.8rem);
        font-weight: 700;
        letter-spacing: 4px;
        margin: 0.5rem 0;
    }

    /* BUTTONS */
    .stButton button {
        background: linear-gradient(90deg, var(--primary), var(--secondary)) !important;
        color: var(--dark) !important;
        font-weight: 700 !important;
        font-size: clamp(1rem, 4vw, 1.2rem) !important;
        padding: 0.75rem 1.5rem !important;
        border-radius: 50px !important;
        border: none !important;
        transition: all 0.3s !important;
        width: 100%;
        text-transform: uppercase;
        letter-spacing: 2px;
    }

    .stButton button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 10px 30px rgba(0, 255, 204, 0.4) !important;
    }

    /* INPUT AREA */
    .stTextArea textarea {
        background-color: #1e293b !important;
        color: var(--primary) !important;
        border: 2px solid var(--primary) !important;
        border-radius: 16px !important;
        font-size: 1rem !important;
        padding: 1rem !important;
        transition: all 0.3s;
    }

    .stTextArea textarea:focus {
        box-shadow: 0 0 20px rgba(0, 255, 204, 0.3) !important;
    }

    /* METRICS */
    .stMetric {
        background: linear-gradient(145deg, #1e293b, #0f172a);
        border: 1px solid var(--primary);
        border-radius: 16px;
        padding: 1rem;
    }

    .stMetric label {
        color: #94a3b8 !important;
        font-size: 0.9rem !important;
    }

    .stMetric [data-testid="stMetricValue"] {
        color: var(--primary) !important;
        font-size: 2rem !important;
        font-weight: 700 !important;
    }

    .stMetric [data-testid="stMetricDelta"] {
        color: var(--success) !important;
    }

    /* TABS - RESPONSIVE */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0.5rem;
        background: #1e293b;
        padding: 0.75rem;
        border-radius: 50px;
        margin: 1rem 0;
        flex-wrap: wrap;
    }

    .stTabs [data-baseweb="tab"] {
        background: transparent !important;
        color: #94a3b8 !important;
        border-radius: 50px !important;
        padding: 0.5rem 1.25rem !important;
        font-size: clamp(0.8rem, 3vw, 1rem) !important;
        transition: all 0.3s;
    }

    .stTabs [aria-selected="true"] {
        background: linear-gradient(90deg, var(--primary), var(--secondary)) !important;
        color: var(--dark) !important;
        font-weight: 700 !important;
    }

    /* PROGRESS BAR */
    .stProgress > div > div {
        background: linear-gradient(90deg, var(--primary), var(--secondary)) !important;
        height: 8px !important;
        border-radius: 4px;
    }

    /* EXPANDER */
    .streamlit-expanderHeader {
        background: #1e293b !important;
        border: 1px solid var(--primary) !important;
        border-radius: 12px !important;
        color: var(--primary) !important;
        font-weight: 600 !important;
    }

    /* FOOTER */
    .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 1.5rem;
        border-top: 1px solid #334155;
        color: #94a3b8;
        font-size: 0.85rem;
    }

    /* RESPONSIVE GRID */
    @media (max-width: 768px) {
        .numbers-grid {
            gap: 0.75rem;
        }
        
        .info-grid {
            grid-template-columns: 1fr;
        }
        
        .stTabs [data-baseweb="tab"] {
            flex: 1 1 auto;
        }
    }

    /* ANIMATIONS */
    @keyframes slideIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }

    .animate-in {
        animation: slideIn 0.5s ease-out;
    }

    /* CUSTOM SCROLLBAR */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }

    ::-webkit-scrollbar-track {
        background: #1e293b;
    }

    ::-webkit-scrollbar-thumb {
        background: linear-gradient(var(--primary), var(--secondary));
        border-radius: 4px;
    }

    ::-webkit-scrollbar-thumb:hover {
        background: var(--primary);
    }
</style>
""", unsafe_allow_html=True)

# =============== HEADER (GI·ªÆ NGUY√äN) ===============
st.markdown("""
<div class='header-card animate-in'>
    <h1 class='main-title'>üéØ AI 3-TINH ELITE PRO V2.0</h1>
    <p class='subtitle'>H·ªá th·ªëng AI ƒëa t·∫ßng - Ph√°t hi·ªán b·∫´y nh√† c√°i - D·ª± ƒëo√°n si√™u ch√≠nh x√°c</p>
</div>
""", unsafe_allow_html=True)

# =============== KH·ªûI T·∫†O ANALYZER (GI·ªÆ NGUY√äN) ===============
@st.cache_resource
def init_analyzer():
    return LotteryAIAnalyzer()

analyzer = init_analyzer()

# =============== SESSION STATE (GI·ªÆ NGUY√äN) ===============
if 'analysis_history' not in st.session_state:
    st.session_state.analysis_history = []
if 'prediction_history' not in st.session_state:
    st.session_state.prediction_history = []
if 'accuracy_stats' not in st.session_state:
    st.session_state.accuracy_stats = {
        'total_predictions': 0,
        'correct_predictions': 0,
        'accuracy_rate': 0.0
    }

# =============== TABS CH√çNH (GI·ªÆ NGUY√äN) ===============
tab1, tab2, tab3, tab4 = st.tabs(["üéØ D·ª∞ ƒêO√ÅN", "üìä PH√ÇN T√çCH", "üìà TH·ªêNG K√ä", "‚öôÔ∏è C√ÄI ƒê·∫∂T"])

with tab1:
    # INPUT AREA (GI·ªÆ NGUY√äN)
    col1, col2 = st.columns([3, 1])
    
    with col1:
        data_input = st.text_area(
            "üì• NH·∫¨P CHU·ªñI S·ªê TH·ª∞C T·∫æ:",
            height=120,
            placeholder="V√≠ d·ª•: 5382917462538192047538291746... (c√†ng nhi·ªÅu s·ªë c√†ng ch√≠nh x√°c)",
            help="Nh·∫≠p c√†ng nhi·ªÅu s·ªë g·∫ßn ƒë√¢y, AI c√†ng ph√¢n t√≠ch ch√≠nh x√°c",
            key="data_input_main"
        )
    
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        st.metric(
            "ƒê·ªò CH√çNH X√ÅC", 
            f"{st.session_state.accuracy_stats['accuracy_rate']:.1f}%", 
            "+2.5%",
            delta_color="normal"
        )
        st.metric("D·ªÆ LI·ªÜU", f"{len(list(filter(str.isdigit, data_input)))} s·ªë", "ƒê√£ nh·∫≠p")
    
    # N√öT PH√ÇN T√çCH (GI·ªÆ NGUY√äN)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        analyze_button = st.button(
            "üöÄ K√çCH HO·∫†T AI PH√ÇN T√çCH ƒêA T·∫¶NG",
            use_container_width=True,
            type="primary"
        )
    
    if analyze_button:
        nums = list(filter(str.isdigit, data_input))
        
        if len(nums) < 15:
            st.error("‚ö†Ô∏è C·∫¶N √çT NH·∫§T 15 S·ªê ƒê·ªÇ PH√ÇN T√çCH CH√çNH X√ÅC!")
        else:
            # PROGRESS BAR (GI·ªÆ NGUY√äN)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # B∆∞·ªõc 1: Ti·ªÅn x·ª≠ l√Ω
                status_text.text("üîÑ ƒêang ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu...")
                time.sleep(0.3)
                progress_bar.progress(15)
                
                # B∆∞·ªõc 2: Ph√¢n t√≠ch ƒëa t·∫ßng
                status_text.text("üìä ƒêang ph√¢n t√≠ch t·∫ßn su·∫•t & Markov...")
                time.sleep(0.4)
                progress_bar.progress(35)
                
                # B∆∞·ªõc 3: Lo·∫°i 3 s·ªë r·ªßi ro - S·ª¨A L·ªñI: ch·ªâ nh·∫≠n 3 gi√° tr·ªã
                status_text.text("üö´ ƒêang lo·∫°i b·ªè 3 s·ªë r·ªßi ro...")
                eliminated, remaining, analysis = analyzer.eliminate_risk_numbers(data_input)
                time.sleep(0.4)
                progress_bar.progress(60)
                
                # B∆∞·ªõc 4: Ch·ªçn 3 s·ªë t·ªët nh·∫•t
                status_text.text("üéØ ƒêang ch·ªçn 3 s·ªë chi·∫øn thu·∫≠t (ƒëa thu·∫≠t to√°n n√¢ng cao)...")
                top_three = analyzer.select_top_three(remaining, data_input, analysis)
                time.sleep(0.4)
                progress_bar.progress(85)
                
                # B∆∞·ªõc 5: K·∫øt n·ªëi AI (n·∫øu c√≥)
                gemini_result = ""
                if GEMINI_API_KEY:
                    status_text.text("üß† ƒêang k·∫øt n·ªëi Gemini AI...")
                    gemini_result = analyzer.connect_gemini(data_input[-100:])
                
                progress_bar.progress(100)
                status_text.text("‚úÖ HO√ÄN T·∫§T PH√ÇN T√çCH!")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()
                
                # L∆∞u l·ªãch s·ª≠
                st.session_state.analysis_history.append({
                    'time': datetime.now().strftime("%H:%M:%S"),
                    'data_length': len(nums),
                    'eliminated': eliminated,
                    'top_three': top_three
                })
                
                # HI·ªÇN TH·ªä K·∫æT QU·∫¢ (GI·ªÆ NGUY√äN GIAO DI·ªÜN)
                st.balloons()
                
                # RESULT CARD
                st.markdown(f"""
                <div class='result-card animate-in'>
                    <div style='text-align: center; margin-bottom: 1.5rem;'>
                        <span style='background: linear-gradient(90deg, var(--primary), var(--secondary)); 
                                     padding: 0.5rem 1.5rem; border-radius: 50px; 
                                     color: var(--dark); font-weight: 700;'>
                            üéØ D√ÄN 3 TINH CHI·∫æN THU·∫¨T CAO C·∫§P
                        </span>
                    </div>
                    
                    <div class='numbers-grid'>
                        <div class='number-circle'>{top_three[0]}</div>
                        <div class='number-circle'>{top_three[1]}</div>
                        <div class='number-circle'>{top_three[2]}</div>
                    </div>
                    
                    <div class='info-grid'>
                        <div class='info-box eliminated-box'>
                            <div class='info-title'>
                                <span style='color: var(--danger);'>üö´ 3 S·ªê R·ª¶I RO (B·∫™Y NH√Ä C√ÅI)</span>
                            </div>
                            <div class='info-numbers'>{", ".join(eliminated) if eliminated else "Kh√¥ng c√≥"}</div>
                            <small style='color: #94a3b8;'>Tuy·ªát ƒë·ªëi tr√°nh xa c√°c s·ªë n√†y!</small>
                        </div>
                        
                        <div class='info-box safe-box'>
                            <div class='info-title'>
                                <span style='color: var(--success);'>‚úÖ D√ÄN 7 S·ªê AN TO√ÄN</span>
                            </div>
                            <div class='info-numbers'>{", ".join(remaining)}</div>
                            <small style='color: #94a3b8;'>Ch·ªçn 7 s·ªë c·ªßa b·∫°n t·ª´ d√†n n√†y</small>
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # CHI·∫æN THU·∫¨T (GI·ªÆ NGUY√äN)
                st.markdown(f"""
                <div class='info-box strategy-box' style='margin-top: 1rem;'>
                    <div class='info-title'>
                        <span style='color: var(--secondary);'>üí° CHI·∫æN THU·∫¨T √ÅP D·ª§NG NGAY</span>
                    </div>
                    <div style='display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem; margin-top: 0.5rem;'>
                        <div style='padding: 0.5rem;'>
                            <span style='font-size: 1.3rem;'>üí∞</span><br>
                            <strong>T·∫≠p trung v·ªën</strong><br>
                            <small>V√†o 3 s·ªë: {", ".join(top_three)}</small>
                        </div>
                        <div style='padding: 0.5rem;'>
                            <span style='font-size: 1.3rem;'>üõ°Ô∏è</span><br>
                            <strong>Tr√°nh xa</strong><br>
                            <small>3 s·ªë: {", ".join(eliminated) if eliminated else "Kh√¥ng c√≥"}</small>
                        </div>
                        <div style='padding: 0.5rem;'>
                            <span style='font-size: 1.3rem;'>üìä</span><br>
                            <strong>D√†n 7 s·ªë</strong><br>
                            <small>{", ".join(remaining)}</small>
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
            except Exception as e:
                st.error(f"L·ªói trong qu√° tr√¨nh ph√¢n t√≠ch: {str(e)}")
                st.info("Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.")

# C√°c tab kh√°c gi·ªØ nguy√™n
with tab2:
    st.info("üìä PH√ÇN T√çCH CHI TI·∫æT - ƒêang ph√°t tri·ªÉn...")

with tab3:
    st.info("üìà TH·ªêNG K√ä - ƒêang ph√°t tri·ªÉn...")

with tab4:
    st.info("‚öôÔ∏è C√ÄI ƒê·∫∂T - ƒêang ph√°t tri·ªÉn...")

# Footer (gi·ªØ nguy√™n)
st.markdown("""
<div class='footer'>
    <p>¬© 2024 AI 3-TINH ELITE PRO V2.0 - T√≠ch h·ª£p 25+ thu·∫≠t to√°n n√¢ng cao | Ph√°t hi·ªán b·∫´y nh√† c√°i | ƒê·ªô ch√≠nh x√°c cao</p>
</div>
""", unsafe_allow_html=True)